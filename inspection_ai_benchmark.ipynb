{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/biz-HK/inspection_ai_benchmark.ipynb/blob/main/inspection_ai_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xogUH5NUOEx9"
   },
   "source": [
    "# ğŸ”¬ å¤–è¦³æ¤œæŸ»AI ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯\n",
    "## Sparse Autoencoder vs Deep Autoencoder æ¯”è¼ƒæ¤œè¨¼\n",
    "\n",
    "| é …ç›® | å†…å®¹ |\n",
    "|------|------|\n",
    "| **ç›®çš„** | ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®ç•°å¸¸æ¤œçŸ¥æ€§èƒ½ã‚’åŒä¸€æ¡ä»¶ã§æ¯”è¼ƒ |\n",
    "| **ç’°å¢ƒ** | Google Colab (T4 GPU) / Windows (CPU/CUDA) / Mac (MPS) |\n",
    "| **ãƒ‡ãƒ¼ã‚¿** | åˆæˆãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿å·®ã—æ›¿ãˆå¯èƒ½ï¼‰ |\n",
    "| **è©•ä¾¡æŒ‡æ¨™** | AUC-ROC, F1, FPR@95TPR, æ¨è«–é€Ÿåº¦, ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º |\n",
    "\n",
    "---\n",
    "### å®Ÿè¡Œæ‰‹é †\n",
    "1. ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€â†’ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ã€â†’ **T4 GPU** ã‚’é¸æŠ\n",
    "2. ä¸Šã‹ã‚‰é †ã«ã‚»ãƒ«ã‚’å®Ÿè¡Œï¼ˆ`Shift+Enter`ï¼‰\n",
    "3. çµæœã¯è‡ªå‹•çš„ã«Google Driveã«ä¿å­˜ã•ã‚Œã¾ã™"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## å‰æçŸ¥è­˜: ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ä½•ã‚’ã—ã¦ã„ã‚‹ã®ã‹\n\n### å¤–è¦³æ¤œæŸ»AIã¨ã¯ï¼Ÿ\nè£½é€ æ¥­ã®å·¥å ´ã§ã¯ã€è£½å“ã«**å‚·ãƒ»æ±šã‚Œãƒ»æ¬ ã‘ãƒ»å¤‰è‰²**ãªã©ã®ä¸è‰¯ï¼ˆæ¬ é™¥ï¼‰ãŒãªã„ã‹ã‚’æ¤œæŸ»ã™ã‚‹å·¥ç¨‹ãŒã‚ã‚Šã¾ã™ã€‚\nå¾“æ¥ã¯äººã®ç›®ã§è¡Œã£ã¦ã„ãŸã“ã®ä½œæ¥­ã‚’ã€AIã«ç”»åƒã‚’è¦‹ã›ã¦è‡ªå‹•åˆ¤å®šã•ã›ã‚‹ã®ãŒ**å¤–è¦³æ¤œæŸ»AI**ã§ã™ã€‚\n\n### ç•°å¸¸æ¤œçŸ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: Autoencoderï¼ˆã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼‰\nã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ **Autoencoder** ã¨ã„ã†æ‰‹æ³•ã‚’ä½¿ã£ã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ãªè€ƒãˆæ–¹ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n\n```\n        Encoder           Decoder\nå…¥åŠ›ç”»åƒ â”€â”€â†’ [åœ§ç¸®è¡¨ç¾(æ½œåœ¨å¤‰æ•°)] â”€â”€â†’ å†æ§‹æˆç”»åƒ\n (128Ã—128)      (64 or 128æ¬¡å…ƒ)       (128Ã—128)\n```\n\n1. **å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚º**: ã€Œæ­£å¸¸å“ã ã‘ã€ã‚’å¤§é‡ã«è¦‹ã›ã¦ã€å…¥åŠ›ç”»åƒã‚’ãã£ãã‚Šãã®ã¾ã¾å‡ºåŠ›ã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹\n2. **æ¨è«–ãƒ•ã‚§ãƒ¼ã‚º**: æœªçŸ¥ã®ç”»åƒã‚’å…¥åŠ›ã—ãŸã¨ãâ€¦\n   - **æ­£å¸¸å“** â†’ å­¦ç¿’æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã«è¿‘ã„ã®ã§ã€ã†ã¾ãå†æ§‹æˆã§ãã‚‹ï¼ˆå…¥åŠ›ã¨å‡ºåŠ›ã®å·®ãŒ**å°ã•ã„**ï¼‰\n   - **ç•°å¸¸å“** â†’ è¦‹ãŸã“ã¨ã®ãªã„ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã®ã§ã€ã†ã¾ãå†æ§‹æˆã§ããªã„ï¼ˆå…¥åŠ›ã¨å‡ºåŠ›ã®å·®ãŒ**å¤§ãã„**ï¼‰\n\nã“ã®ã€Œå†æ§‹æˆèª¤å·®ï¼ˆå…¥åŠ›ã¨å‡ºåŠ›ã®å·®ï¼‰ã€ã‚’**ç•°å¸¸ã‚¹ã‚³ã‚¢**ã¨ã—ã¦ä½¿ã„ã€é–¾å€¤ã‚’è¶…ãˆãŸã‚‰ã€Œç•°å¸¸ã€ã¨åˆ¤å®šã—ã¾ã™ã€‚\n\n### ãªãœæ­£å¸¸å“ã ã‘ã§å­¦ç¿’ã™ã‚‹ã®ã‹ï¼Ÿ\nè£½é€ ç¾å ´ã§ã¯ä¸è‰¯å“ã®ãƒ‡ãƒ¼ã‚¿ã¯æ¥µç«¯ã«å°‘ãªã„ã®ãŒæ™®é€šã§ã™ï¼ˆä¸è‰¯ç‡1%ä»¥ä¸‹ã®å ´åˆã‚‚å¤šã„ï¼‰ã€‚\nAutoencoderãªã‚‰**æ­£å¸¸å“ã ã‘ã§å­¦ç¿’**ã§ãã€ã€Œæ­£å¸¸ã‹ã‚‰å¤–ã‚ŒãŸã‚‚ã®ï¼ç•°å¸¸ã€ã¨ã—ã¦æ¤œå‡ºã§ãã‚‹ãŸã‚ã€\nç¾å ´ã§éå¸¸ã«ä½¿ã„ã‚„ã™ã„æ‰‹æ³•ã§ã™ã€‚\n\n### ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ç›®çš„\nä»¥ä¸‹ã®**2ç¨®é¡ã®Autoencoder**ã‚’åŒã˜æ¡ä»¶ã§æ¯”è¼ƒã—ã€ã©ã¡ã‚‰ãŒå¤–è¦³æ¤œæŸ»ã«é©ã—ã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚\n\n| ãƒ¢ãƒ‡ãƒ« | ç‰¹å¾´ | å‘ã„ã¦ã„ã‚‹ç”¨é€” |\n|--------|------|---------------|\n| **Sparse Autoencoder (SAE)** | è»½é‡ãƒ»é«˜é€Ÿã€‚å°‘æ•°ã®ç‰¹å¾´ã«é›†ä¸­ã—ã¦å­¦ç¿’ | ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹ï¼ˆã‚«ãƒ¡ãƒ©ä»˜ãæ¤œæŸ»æ©Ÿï¼‰ã§ã®é«˜é€Ÿåˆ¤å®š |\n| **Deep Autoencoder (DAE)** | å¤§è¦æ¨¡ãƒ»é«˜ç²¾åº¦ã€‚å¾®ç´°ãªç•°å¸¸ã‚‚æ¤œå‡ºå¯èƒ½ | ã‚µãƒ¼ãƒãƒ¼ã§ã®é«˜ç²¾åº¦ãƒãƒƒãƒæ¤œæŸ» |",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### ã‚»ã‚¯ã‚·ãƒ§ãƒ³0ã®è§£èª¬: ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã§è¡Œã†ã“ã¨\n\nã“ã®ã‚»ãƒ«ã§ã¯ã€ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å…¨ä½“ã§ä½¿ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ã¨åˆæœŸè¨­å®šã‚’è¡Œã„ã¾ã™ã€‚\n\n**ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å½¹å‰²:**\n- `torch` (PyTorch): ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ãƒ»å­¦ç¿’ãƒ»æ¨è«–ã«ä½¿ã†\n- `numpy`: æ•°å€¤è¨ˆç®—ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚ç”»åƒãƒ‡ãƒ¼ã‚¿ã®é…åˆ—æ“ä½œã«ä½¿ã†\n- `sklearn` (scikit-learn): æ©Ÿæ¢°å­¦ç¿’ã®è©•ä¾¡æŒ‡æ¨™ï¼ˆAUC-ROCãªã©ï¼‰ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã«ä½¿ã†\n- `matplotlib`: ã‚°ãƒ©ãƒ•ã‚„ç”»åƒã®æç”»ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n\n**ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•æ¤œå‡ºã«ã¤ã„ã¦:**\nPyTorchã§ã¯è¨ˆç®—ã‚’è¡Œã†ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ï¼ˆãƒ‡ãƒã‚¤ã‚¹ï¼‰ã‚’æŒ‡å®šã§ãã¾ã™ã€‚\n- **CUDA (GPU)**: NVIDIAè£½GPUã€‚è¡Œåˆ—æ¼”ç®—ã‚’ä¸¦åˆ—åŒ–ã§ãã€å­¦ç¿’ãŒ10ã€œ100å€é«˜é€Ÿã«ãªã‚‹\n- **MPS**: Apple Silicon (M1/M2/M3/M4/M5) ãƒãƒƒãƒ—ã®GPUåŠ é€Ÿ\n- **CPU**: GPUãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚å‹•ä½œã¯ã™ã‚‹ãŒé…ã„\n\n**ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—:**\nç•°å¸¸ç®‡æ‰€ã‚’ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§å¯è¦–åŒ–ã™ã‚‹ãŸã‚ã®è‰²ã®å®šç¾©ã§ã™ï¼ˆé’=æ­£å¸¸ã€é»„=ã‚„ã‚„ç•°å¸¸ã€èµ¤=ç•°å¸¸å¤§ï¼‰ã€‚",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Cwws86YOEx-"
   },
   "source": [
    "## 0. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zf4199AAOEx_"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆColabã«ãƒ—ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã®ã‚‚ã®ãŒå¤šã„ï¼‰â”€â”€\n",
    "!pip install -q scikit-learn matplotlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from typing import Tuple, Dict, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# â”€â”€ ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•æ¤œå‡º â”€â”€\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print(f'âœ… GPU: {torch.cuda.get_device_name(0)}')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "    print('âœ… Apple Silicon MPS')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print('âš ï¸ CPU modeï¼ˆGPUãªã—ï¼‰')\n",
    "\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'Device: {DEVICE}')\n",
    "\n",
    "# â”€â”€ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè‡ªå‹•è¨­å®š â”€â”€\n",
    "import matplotlib.font_manager as fm\n",
    "import platform as _pf\n",
    "\n",
    "def setup_japanese_font():\n",
    "    _sys = _pf.system()\n",
    "    candidates = {\n",
    "        'Windows': ['Yu Gothic', 'MS Gothic', 'Meiryo', 'BIZ UDGothic'],\n",
    "        'Darwin':  ['Hiragino Sans', 'Hiragino Kaku Gothic Pro'],\n",
    "    }.get(_sys, ['Noto Sans CJK JP', 'IPAGothic', 'TakaoPGothic'])\n",
    "    available = {f.name for f in fm.fontManager.ttflist}\n",
    "    for fn in candidates:\n",
    "        if fn in available:\n",
    "            matplotlib.rcParams['font.family'] = fn\n",
    "            break\n",
    "    else:\n",
    "        if _sys == 'Linux':\n",
    "            os.system('apt-get install -y fonts-ipafont-gothic > /dev/null 2>&1')\n",
    "            try:\n",
    "                fm.fontManager.addfont('/usr/share/fonts/opentype/ipafont-gothic/ipag.ttf')\n",
    "                matplotlib.rcParams['font.family'] = 'IPAGothic'\n",
    "            except: pass\n",
    "        matplotlib.rcParams['font.sans-serif'] = candidates + ['DejaVu Sans']\n",
    "    matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "setup_japanese_font()\n",
    "\n",
    "# â”€â”€ ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ï¼ˆé’â†’é»„â†’èµ¤ï¼‰â”€â”€\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "INSPECTION_CMAP = LinearSegmentedColormap.from_list(\n",
    "    'inspection_heatmap',\n",
    "    [(0.0, '#1a237e'), (0.15, '#1565c0'), (0.35, '#00bcd4'),\n",
    "     (0.50, '#ffeb3b'), (0.70, '#ff9800'), (0.85, '#f44336'),\n",
    "     (1.0, '#b71c1c')],\n",
    "    N=256,\n",
    ")\n",
    "\n",
    "def create_overlay(base_img, error_map, alpha=0.5, cmap=None):\n",
    "    \"\"\"å…ƒç”»åƒã«ã‚¨ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤åˆæˆ\"\"\"\n",
    "    if cmap is None: cmap = INSPECTION_CMAP\n",
    "    if base_img.ndim == 2:\n",
    "        base_rgb = np.stack([base_img]*3, axis=-1)\n",
    "    else:\n",
    "        base_rgb = base_img[:, :, :3]\n",
    "    emax = error_map.max()\n",
    "    error_norm = error_map / emax if emax > 0 else error_map\n",
    "    heat_rgba = cmap(error_norm)[:, :, :3]\n",
    "    return np.clip(base_rgb * (1-alpha) + heat_rgba * alpha, 0, 1)\n",
    "\n",
    "print('âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ + ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—è¨­å®šå®Œäº†')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_jBKUWErOEx_"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ Google Drive ãƒã‚¦ãƒ³ãƒˆï¼ˆçµæœä¿å­˜ç”¨ãƒ»ä»»æ„ï¼‰â”€â”€\n",
    "SAVE_TO_DRIVE = True  # Falseã«ã™ã‚‹ã¨ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ã®ã¿\n",
    "\n",
    "if SAVE_TO_DRIVE:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        SAVE_DIR = Path('/content/drive/MyDrive/inspection_ai_results')\n",
    "        SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'âœ… ä¿å­˜å…ˆ: {SAVE_DIR}')\n",
    "    except ImportError:\n",
    "        # Windows/Mac ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚\n",
    "        SAVE_DIR = Path('./results')\n",
    "        SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'âœ… ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜: {SAVE_DIR}')\n",
    "else:\n",
    "    SAVE_DIR = Path('./results')\n",
    "    SAVE_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpZiaRJtOEx_"
   },
   "source": [
    "## 1. ãƒ¢ãƒ‡ãƒ«å®šç¾©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚»ã‚¯ã‚·ãƒ§ãƒ³1ã®è§£èª¬: 2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n",
    "\n",
    "#### Autoencoderã®åŸºæœ¬æ§‹é€ \n",
    "Autoencoderã¯ã€ŒEncoderï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼‰ã€ã¨ã€ŒDecoderï¼ˆãƒ‡ã‚³ãƒ¼ãƒ€ï¼‰ã€ã®2ã¤ã®ãƒ‘ãƒ¼ãƒ„ã§æ§‹æˆã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "```\n",
    "å…¥åŠ›ç”»åƒ (1Ã—128Ã—128)\n",
    "   â”‚\n",
    "   â–¼  Encoder: ç•³ã¿è¾¼ã¿(Conv2d)ã§ç”»åƒã‚’åœ§ç¸®\n",
    "   â”‚  128Ã—128 â†’ 64Ã—64 â†’ 32Ã—32 â†’ ... â†’ æ½œåœ¨å¤‰æ•°(z)\n",
    "   â”‚\n",
    "   â–¼  Decoder: é€†ç•³ã¿è¾¼ã¿(ConvTranspose2d)ã§ç”»åƒã‚’å¾©å…ƒ\n",
    "   â”‚  æ½œåœ¨å¤‰æ•°(z) â†’ ... â†’ 32Ã—32 â†’ 64Ã—64 â†’ 128Ã—128\n",
    "   â–¼\n",
    "å†æ§‹æˆç”»åƒ (1Ã—128Ã—128)\n",
    "```\n",
    "\n",
    "#### Conv2dï¼ˆç•³ã¿è¾¼ã¿å±¤ï¼‰ã¨ã¯ï¼Ÿ\n",
    "ç”»åƒã®å±€æ‰€çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã‚¨ãƒƒã‚¸ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ãªã©ï¼‰ã‚’æŠ½å‡ºã™ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ã§ã™ã€‚\n",
    "- `stride=2`: ãƒ•ã‚£ãƒ«ã‚¿ã‚’2ãƒ”ã‚¯ã‚»ãƒ«ãšã¤ãšã‚‰ã™ã“ã¨ã§ã€ç”»åƒã‚µã‚¤ã‚ºã‚’åŠåˆ†ã«ç¸®å°\n",
    "- `padding=1`: ç”»åƒã®ç«¯ã«ã‚¼ãƒ­ã‚’è¿½åŠ ã—ã¦ã€å‡ºåŠ›ã‚µã‚¤ã‚ºã‚’èª¿æ•´\n",
    "- `BatchNorm2d`: å„å±¤ã®å‡ºåŠ›ã‚’æ­£è¦åŒ–ã—ã€å­¦ç¿’ã‚’å®‰å®šã•ã›ã‚‹ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯\n",
    "\n",
    "#### Sparse AE vs Deep AE ã®é•ã„\n",
    "\n",
    "| é …ç›® | Sparse AE (SAE) | Deep AE (DAE) |\n",
    "|------|-----------------|----------------|\n",
    "| Encoderå±¤æ•° | 2å±¤ (ConvÃ—2) | 4å±¤ (ConvÃ—8) |\n",
    "| æ½œåœ¨æ¬¡å…ƒ | 64 | 128 |\n",
    "| æ­£å‰‡åŒ– | **L1æ­£å‰‡åŒ–**ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–ï¼‰ | ãªã— |\n",
    "| æå¤±é–¢æ•° | MSE + L1 | MSE + **SSIM** |\n",
    "| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | å°‘ãªã„ï¼ˆè»½é‡ï¼‰ | å¤šã„ï¼ˆé«˜è¡¨ç¾åŠ›ï¼‰ |\n",
    "\n",
    "#### L1æ­£å‰‡åŒ–ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–ï¼‰ã¨ã¯ï¼Ÿ\n",
    "æ½œåœ¨å¤‰æ•° `z` ã®çµ¶å¯¾å€¤ã®åˆè¨ˆã«ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’ã‹ã‘ã‚‹ã“ã¨ã§ã€**ã»ã¨ã‚“ã©ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’ã‚¼ãƒ­è¿‘ãã«æŠ‘ãˆã€\n",
    "å°‘æ•°ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã ã‘ãŒå¼·ãåå¿œã™ã‚‹**çŠ¶æ…‹ã‚’ä½œã‚Šã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šï¼š\n",
    "- é‡è¦ãªç‰¹å¾´ã ã‘ã«é›†ä¸­ã—ãŸã€è§£é‡ˆã—ã‚„ã™ã„è¡¨ç¾ãŒå¾—ã‚‰ã‚Œã‚‹\n",
    "- ãƒ¢ãƒ‡ãƒ«ãŒéå­¦ç¿’ã—ã«ãããªã‚‹\n",
    "- è¨ˆç®—é‡ãŒå‰Šæ¸›ã•ã‚Œã€ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹ã§ã®å®Ÿè¡Œã«é©ã™ã‚‹\n",
    "\n",
    "#### SSIMï¼ˆæ§‹é€ é¡ä¼¼åº¦ï¼‰æå¤±ã¨ã¯ï¼Ÿ\n",
    "äººé–“ã®è¦–è¦šã«è¿‘ã„ã€Œæ§‹é€ ã®é¡ä¼¼åº¦ã€ã‚’è©•ä¾¡ã™ã‚‹æŒ‡æ¨™ã§ã™ã€‚\n",
    "MSEï¼ˆãƒ”ã‚¯ã‚»ãƒ«å˜ä½ã®å·®ã®äºŒä¹—å¹³å‡ï¼‰ã ã‘ã§ã¯æ‰ãˆã«ãã„ã€Œç”»åƒã®ã¼ã‚„ã‘ã€ã‚„ã€Œæ§‹é€ ã®å´©ã‚Œã€ã‚‚æ¤œå‡ºã§ãã¾ã™ã€‚\n",
    "DAEã§ã¯MSEã«åŠ ãˆã¦SSIMæå¤±ã‚’ä½¿ã†ã“ã¨ã§ã€ã‚ˆã‚Šäººé–“ã®æ„Ÿè¦šã«è¿‘ã„å†æ§‹æˆå“è³ªã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6oiPXMDOEyA"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Sparse Autoencoder (SAE)\n",
    "# L1æ­£å‰‡åŒ–ã§æ½œåœ¨ç©ºé–“ã‚’ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Sparse Autoencoder\n",
    "    - è»½é‡ãª2å±¤Convæ§‹æˆ\n",
    "    - L1æ­£å‰‡åŒ–ã§å°‘æ•°ã®ç‰¹å¾´é‡ã«é›†ä¸­\n",
    "    - ã‚¨ãƒƒã‚¸å±•é–‹ã«é©ã—ãŸå°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(True),\n",
    "        )\n",
    "        self.fc_encode = nn.Linear(64 * 32 * 32, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, 64 * 32 * 32)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, in_channels, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_encode(h.view(h.size(0), -1))\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.fc_decode(z).view(z.size(0), 64, 32, 32)\n",
    "        return self.decoder(h)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z), z\n",
    "\n",
    "\n",
    "class SparseAELoss(nn.Module):\n",
    "    \"\"\"MSE + L1ã‚¹ãƒ‘ãƒ¼ã‚¹æ­£å‰‡åŒ–\"\"\"\n",
    "    def __init__(self, l1_weight=1e-3):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.l1_weight = l1_weight\n",
    "\n",
    "    def forward(self, x, x_recon, z):\n",
    "        recon = self.mse(x_recon, x)\n",
    "        sparse = self.l1_weight * torch.mean(torch.abs(z))\n",
    "        return recon + sparse, {'recon': recon.item(), 'sparse': sparse.item()}\n",
    "\n",
    "\n",
    "print('âœ… Sparse Autoencoder å®šç¾©å®Œäº†')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOhP-2LfOEyA"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Deep Autoencoder (DAE)\n",
    "# å¤šå±¤Conv + SSIMæå¤±ã«ã‚ˆã‚‹é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class DeepAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Autoencoder\n",
    "    - 4å±¤Convæ§‹æˆ\n",
    "    - é«˜ã„è¡¨ç¾åŠ›ã§å¾®ç´°ãªç•°å¸¸ã‚‚æ¤œå‡º\n",
    "    - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯SAEã®10å€ä»¥ä¸Š\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1, latent_dim=128):\n",
    "        super().__init__()\n",
    "        self.enc1 = self._conv(in_channels, 32)\n",
    "        self.enc2 = self._conv(32, 64)\n",
    "        self.enc3 = self._conv(64, 128)\n",
    "        self.enc4 = self._conv(128, 256)\n",
    "        self.fc_encode = nn.Linear(256 * 8 * 8, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, 256 * 8 * 8)\n",
    "        self.dec4 = self._deconv(256, 128)\n",
    "        self.dec3 = self._deconv(128, 64)\n",
    "        self.dec2 = self._deconv(64, 32)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, in_channels, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _conv(inc, outc):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(inc, outc, 4, 2, 1), nn.BatchNorm2d(outc), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(outc, outc, 3, 1, 1), nn.BatchNorm2d(outc), nn.LeakyReLU(0.2, True),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _deconv(inc, outc):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(inc, outc, 4, 2, 1), nn.BatchNorm2d(outc), nn.ReLU(True),\n",
    "            nn.Conv2d(outc, outc, 3, 1, 1), nn.BatchNorm2d(outc), nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.enc4(self.enc3(self.enc2(self.enc1(x))))\n",
    "        return self.fc_encode(h.view(h.size(0), -1))\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.fc_decode(z).view(z.size(0), 256, 8, 8)\n",
    "        return self.dec1(self.dec2(self.dec3(self.dec4(h))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z), z\n",
    "\n",
    "\n",
    "class DeepAELoss(nn.Module):\n",
    "    \"\"\"MSE + ç°¡æ˜“SSIMæ§‹é€ æå¤±\"\"\"\n",
    "    def __init__(self, ssim_weight=0.1):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.ssim_weight = ssim_weight\n",
    "\n",
    "    def _ssim_approx(self, x, y, ws=11):\n",
    "        C1, C2 = 0.01**2, 0.03**2\n",
    "        pad = ws // 2\n",
    "        mu_x = nn.functional.avg_pool2d(x, ws, 1, pad)\n",
    "        mu_y = nn.functional.avg_pool2d(y, ws, 1, pad)\n",
    "        s_x = nn.functional.avg_pool2d(x**2, ws, 1, pad) - mu_x**2\n",
    "        s_y = nn.functional.avg_pool2d(y**2, ws, 1, pad) - mu_y**2\n",
    "        s_xy = nn.functional.avg_pool2d(x*y, ws, 1, pad) - mu_x*mu_y\n",
    "        return ((2*mu_x*mu_y+C1)*(2*s_xy+C2) / ((mu_x**2+mu_y**2+C1)*(s_x+s_y+C2))).mean()\n",
    "\n",
    "    def forward(self, x, x_recon, z=None):\n",
    "        recon = self.mse(x_recon, x)\n",
    "        ssim = 1.0 - self._ssim_approx(x, x_recon)\n",
    "        return recon + self.ssim_weight * ssim, {'recon': recon.item(), 'ssim': ssim.item()}\n",
    "\n",
    "\n",
    "print('âœ… Deep Autoencoder å®šç¾©å®Œäº†')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWzO5sCTOEyA"
   },
   "source": [
    "## 2. åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚»ã‚¯ã‚·ãƒ§ãƒ³2ã®è§£èª¬: åˆæˆãƒ‡ãƒ¼ã‚¿ã¯ãªãœä½¿ã†ã®ã‹\n",
    "\n",
    "#### åˆæˆãƒ‡ãƒ¼ã‚¿ï¼ˆSynthetic Dataï¼‰ã¨ã¯ï¼Ÿ\n",
    "å®Ÿéš›ã®è£½å“ç”»åƒã®ä»£ã‚ã‚Šã«ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§äººå·¥çš„ã«ç”Ÿæˆã—ãŸãƒ†ã‚¹ãƒˆç”¨ç”»åƒã§ã™ã€‚\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ä»¥ä¸‹ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™ï¼š\n",
    "\n",
    "**æ­£å¸¸å“ç”»åƒã®æ§‹æˆè¦ç´ :**\n",
    "- ãƒ™ãƒ¼ã‚¹: å‡ä¸€ãªã‚°ãƒ¬ãƒ¼ï¼ˆæ˜ã‚‹ã•0.6ï¼‰ã«å¾®å°ãªãƒã‚¤ã‚ºã‚’åŠ ãˆãŸã‚‚ã®\n",
    "- æ ¼å­ãƒ‘ã‚¿ãƒ¼ãƒ³: 16ãƒ”ã‚¯ã‚»ãƒ«é–“éš”ã®ç´°ã„ç·šï¼ˆåŸºæ¿ã‚„è¡¨é¢ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’æ¨¡æ“¬ï¼‰\n",
    "- å††å½¢ç‰¹å¾´: ä¸­å¤®ä»˜è¿‘ã®å††å½¢ãƒã‚¹ã‚¯ï¼ˆéƒ¨å“ã®å½¢çŠ¶ã‚’æ¨¡æ“¬ï¼‰\n",
    "\n",
    "**4ç¨®é¡ã®æ¬ é™¥ãƒ‘ã‚¿ãƒ¼ãƒ³:**\n",
    "| æ¬ é™¥ã‚¿ã‚¤ãƒ— | è‹±å | ç‰¹å¾´ | å®Ÿéš›ã®ä¾‹ |\n",
    "|-----------|------|------|---------|\n",
    "| å‚· | scratch | ç›´ç·šçŠ¶ã®æš—ã„ç­‹ | è¡¨é¢ã®ã²ã£ã‹ãå‚· |\n",
    "| æ±šã‚Œ | stain | ã‚¬ã‚¦ã‚·ã‚¢ãƒ³åˆ†å¸ƒã®æš—ã„æ–‘ç‚¹ | æ²¹æ±šã‚Œã€æŒ‡ç´‹ |\n",
    "| æ¬ ã‘ | missing | å††å½¢ã®æš—ã„ç©´ | éƒ¨å“ã®æ¬ è½ã€ç©´ |\n",
    "| å¤‰è‰² | discolor | çŸ©å½¢ã®æ˜ã‚‹ã„é ˜åŸŸ | ç„¼ã‘ãƒ ãƒ©ã€å¤‰è‰² |\n",
    "\n",
    "#### ãªãœåˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†ã®ã‹ï¼Ÿ\n",
    "1. **æ‰‹è»½ã«å‹•ä½œæ¤œè¨¼**ã§ãã‚‹ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ä¸è¦ã§å³åº§ã«è©¦ã›ã‚‹ï¼‰\n",
    "2. **æ¬ é™¥ã®ç¨®é¡ã¨ä½ç½®ãŒæ—¢çŸ¥**ãªã®ã§ã€æ¤œå‡ºç²¾åº¦ã‚’æ­£ç¢ºã«è©•ä¾¡ã§ãã‚‹\n",
    "3. å®Ÿãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ãŒã§ããŸã‚‰ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³9ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ç°¡å˜ã«å·®ã—æ›¿ãˆå¯èƒ½\n",
    "\n",
    "#### PyTorchã®`Dataset`ã¨`DataLoader`\n",
    "- `Dataset`: ãƒ‡ãƒ¼ã‚¿1ä»¶ã®å–å¾—æ–¹æ³•ã‚’å®šç¾©ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚`__getitem__`ã§ç”»åƒãƒ»ãƒ©ãƒ™ãƒ«ãƒ»ãƒã‚¹ã‚¯ã‚’è¿”ã™\n",
    "- `DataLoader`: Datasetã‹ã‚‰ãƒŸãƒ‹ãƒãƒƒãƒï¼ˆè¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã®ã¾ã¨ã¾ã‚Šï¼‰ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã€‚`batch_size=16`ãªã‚‰16æšãšã¤ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8VUfll6EOEyB"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# åˆæˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "# æ­£å¸¸å“ + 4ç¨®é¡ã®æ¬ é™¥ï¼ˆscratch/stain/missing/discolorï¼‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def generate_normal_image(size=128, seed=None):\n",
    "    \"\"\"æ­£å¸¸å“ç”»åƒï¼ˆå‡ä¸€ãƒ†ã‚¯ã‚¹ãƒãƒ£ + æ ¼å­ãƒ‘ã‚¿ãƒ¼ãƒ³ + å††å½¢ç‰¹å¾´ï¼‰\"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    img = np.ones((size, size), dtype=np.float32) * 0.6\n",
    "    img += np.random.normal(0, 0.02, (size, size)).astype(np.float32)\n",
    "    for i in range(0, size, 16):\n",
    "        img[i:i+1, :] += 0.05\n",
    "        img[:, i:i+1] += 0.05\n",
    "    y, x = np.ogrid[-size//2:size//2, -size//2:size//2]\n",
    "    r = np.sqrt(x*x + y*y).astype(np.float32)\n",
    "    mask = (r < size * 0.35).astype(np.float32)\n",
    "    img = img * (1 - mask * 0.1) + mask * 0.05\n",
    "    return np.clip(img, 0, 1)\n",
    "\n",
    "\n",
    "def add_defect(img, defect_type='scratch', seed=None):\n",
    "    \"\"\"æ¬ é™¥ã‚’è¿½åŠ  â†’ (ç•°å¸¸ç”»åƒ, ãƒã‚¹ã‚¯)\"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    size = img.shape[0]\n",
    "    out = img.copy()\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    if defect_type == 'scratch':\n",
    "        ys, xs = np.random.randint(20, size-20), np.random.randint(20, size-40)\n",
    "        length, angle = np.random.randint(30, 60), np.random.uniform(-0.3, 0.3)\n",
    "        for i in range(length):\n",
    "            yi, xi = int(ys + i*np.sin(angle)), int(xs + i*np.cos(angle))\n",
    "            if 0 <= yi < size and 0 <= xi < size:\n",
    "                w = np.random.randint(1, 3)\n",
    "                out[max(0,yi-w):yi+w, max(0,xi-w):xi+w] -= 0.3\n",
    "                mask[max(0,yi-w):yi+w, max(0,xi-w):xi+w] = 1.0\n",
    "    elif defect_type == 'stain':\n",
    "        cy, cx = np.random.randint(30, size-30, 2)\n",
    "        rad = np.random.randint(8, 20)\n",
    "        yy, xx = np.ogrid[:size, :size]\n",
    "        blob = np.exp(-((xx-cx)**2 + (yy-cy)**2) / (2*rad**2))\n",
    "        out -= blob.astype(np.float32) * 0.25\n",
    "        mask = (blob > 0.3).astype(np.float32)\n",
    "    elif defect_type == 'missing':\n",
    "        cy, cx = np.random.randint(30, size-30, 2)\n",
    "        rad = np.random.randint(5, 15)\n",
    "        yy, xx = np.ogrid[:size, :size]\n",
    "        hole = (np.sqrt((xx-cx)**2 + (yy-cy)**2) < rad).astype(np.float32)\n",
    "        out = out * (1 - hole) + hole * 0.1\n",
    "        mask = hole\n",
    "    elif defect_type == 'discolor':\n",
    "        y1, x1 = np.random.randint(10, size-40), np.random.randint(10, size-40)\n",
    "        h, w = np.random.randint(15, 35), np.random.randint(15, 35)\n",
    "        out[y1:y1+h, x1:x1+w] += 0.15\n",
    "        mask[y1:y1+h, x1:x1+w] = 1.0\n",
    "\n",
    "    return np.clip(out, 0, 1), mask\n",
    "\n",
    "\n",
    "class InspectionDataset(Dataset):\n",
    "    def __init__(self, n_normal=200, n_anomaly=50, image_size=128, include_anomaly=True):\n",
    "        self.images, self.labels, self.masks, self.types = [], [], [], []\n",
    "        for i in range(n_normal):\n",
    "            img = generate_normal_image(image_size, seed=i)\n",
    "            self.images.append(img); self.labels.append(0)\n",
    "            self.masks.append(np.zeros_like(img)); self.types.append('normal')\n",
    "        if include_anomaly:\n",
    "            dtypes = ['scratch', 'stain', 'missing', 'discolor']\n",
    "            for i in range(n_anomaly):\n",
    "                base = generate_normal_image(image_size, seed=1000+i)\n",
    "                dt = dtypes[i % 4]\n",
    "                defect, m = add_defect(base, dt, seed=2000+i)\n",
    "                self.images.append(defect); self.labels.append(1)\n",
    "                self.masks.append(m); self.types.append(dt)\n",
    "\n",
    "    def __len__(self): return len(self.images)\n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.FloatTensor(self.images[idx]).unsqueeze(0),\n",
    "                self.labels[idx],\n",
    "                torch.FloatTensor(self.masks[idx]).unsqueeze(0))\n",
    "\n",
    "\n",
    "print('âœ… ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®šç¾©å®Œäº†')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "992LukgDOEyB"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®ç¢ºèª â”€â”€\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle('åˆæˆãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i in range(5):\n",
    "    img = generate_normal_image(128, seed=i)\n",
    "    axes[0, i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0, i].set_title(f'æ­£å¸¸å“ #{i+1}', fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "for i, dt in enumerate(['scratch', 'stain', 'missing', 'discolor', 'scratch']):\n",
    "    base = generate_normal_image(128, seed=100+i)\n",
    "    defect, _ = add_defect(base, dt, seed=200+i)\n",
    "    axes[1, i].imshow(defect, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1, i].set_title(f'ç•°å¸¸: {dt}', fontsize=10, color='red')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'sample_data.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f'ğŸ’¾ ä¿å­˜: {SAVE_DIR}/sample_data.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qL8AoRWOEyC"
   },
   "source": [
    "## 3. æ¤œè¨¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n",
    "\n",
    "ã“ã“ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ã¦ã€ç•°ãªã‚‹æ¡ä»¶ã§ã®æ¯”è¼ƒãŒå¯èƒ½ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚»ã‚¯ã‚·ãƒ§ãƒ³3ã®è§£èª¬: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ„å‘³ã¨èª¿æ•´ã®æŒ‡é‡\n",
    "\n",
    "å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œã«ã©ã†å½±éŸ¿ã™ã‚‹ã‹ã‚’è§£èª¬ã—ã¾ã™ã€‚\n",
    "\n",
    "#### ãƒ‡ãƒ¼ã‚¿é–¢é€£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |\n",
    "|-----------|----------|------|\n",
    "| `n_train` | 200 | å­¦ç¿’ã«ä½¿ã†æ­£å¸¸ç”»åƒã®æšæ•°ã€‚å¢—ã‚„ã™ã»ã©ãƒ¢ãƒ‡ãƒ«ãŒã€Œæ­£å¸¸ã€ã‚’æ­£ç¢ºã«å­¦ã¶ãŒã€å­¦ç¿’ã«æ™‚é–“ãŒã‹ã‹ã‚‹ |\n",
    "| `n_test_normal` | 50 | ãƒ†ã‚¹ãƒˆç”¨ã®æ­£å¸¸ç”»åƒæ•° |\n",
    "| `n_test_anomaly` | 50 | ãƒ†ã‚¹ãƒˆç”¨ã®ç•°å¸¸ç”»åƒæ•° |\n",
    "| `image_size` | 128 | ç”»åƒã®ç¸¦æ¨ªãƒ”ã‚¯ã‚»ãƒ«æ•°ã€‚64ã«ã™ã‚‹ã¨4å€é«˜é€Ÿã«ãªã‚‹ãŒè§£åƒåº¦ãŒè½ã¡ã‚‹ |\n",
    "| `batch_size` | 16 | ä¸€åº¦ã«ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã™ã‚‹ç”»åƒæšæ•°ã€‚GPUãƒ¡ãƒ¢ãƒªã«ä½™è£•ãŒã‚ã‚Œã°å¢—ã‚„ã›ã‚‹ |\n",
    "\n",
    "#### ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | èª¬æ˜ | èª¿æ•´ã®ã‚³ãƒ„ |\n",
    "|-----------|------|-----------|\n",
    "| `sae_latent_dim` | SAEã®æ½œåœ¨æ¬¡å…ƒæ•°ã€‚å°‘ãªã„ã»ã©åœ§ç¸®ãŒå¼·ã„ | 32ã€œ128ã®ç¯„å›²ã§è©¦ã™ |\n",
    "| `sae_l1_weight` | L1æ­£å‰‡åŒ–ã®å¼·ã•(Î»)ã€‚å¤§ãã„ã»ã©ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–ãŒå¼·ã„ | 1e-4ã€œ1e-2ã§èª¿æ•´ã€‚å¤§ãã™ãã‚‹ã¨å†æ§‹æˆãŒå´©ã‚Œã‚‹ |\n",
    "| `dae_latent_dim` | DAEã®æ½œåœ¨æ¬¡å…ƒæ•° | SAEã‚ˆã‚Šå¤§ããã—ã¦è¡¨ç¾åŠ›ã‚’ç¢ºä¿ |\n",
    "| `dae_ssim_weight` | SSIMæå¤±ã®é‡ã¿ã€‚å¤§ãã„ã»ã©æ§‹é€ ä¿å­˜ã‚’é‡è¦– | 0.05ã€œ0.3ã§èª¿æ•´ |\n",
    "\n",
    "#### å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | èª¬æ˜ |\n",
    "|-----------|------|\n",
    "| `n_epochs` | å­¦ç¿’ã®ç¹°ã‚Šè¿”ã—å›æ•°ã€‚å­¦ç¿’æ›²ç·šãŒåæŸã™ã‚‹ã¾ã§å¢—ã‚„ã™ |\n",
    "| `learning_rate` | å­¦ç¿’ç‡ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ã®å¤§ãã•ã€‚å¤§ãã™ãã‚‹ã¨ç™ºæ•£ã€å°ã•ã™ãã‚‹ã¨åæŸãŒé…ã„ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ct-78-vwOEyC"
   },
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ğŸ›ï¸ æ¤œè¨¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã“ã“ã‚’å¤‰ãˆã¦å®Ÿé¨“ï¼‰       â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "CONFIG = {\n",
    "    # ãƒ‡ãƒ¼ã‚¿è¨­å®š\n",
    "    'n_train': 200,           # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°ï¼ˆæ­£å¸¸å“ï¼‰\n",
    "    'n_test_normal': 50,      # ãƒ†ã‚¹ãƒˆæ­£å¸¸å“æ•°\n",
    "    'n_test_anomaly': 50,     # ãƒ†ã‚¹ãƒˆç•°å¸¸å“æ•°\n",
    "    'image_size': 128,        # ç”»åƒã‚µã‚¤ã‚º (64 or 128)\n",
    "    'batch_size': 16,\n",
    "\n",
    "    # Sparse AE è¨­å®š\n",
    "    'sae_latent_dim': 64,     # æ½œåœ¨æ¬¡å…ƒ\n",
    "    'sae_l1_weight': 1e-3,    # L1æ­£å‰‡åŒ–å¼·åº¦ (Î»)\n",
    "\n",
    "    # Deep AE è¨­å®š\n",
    "    'dae_latent_dim': 128,    # æ½œåœ¨æ¬¡å…ƒ\n",
    "    'dae_ssim_weight': 0.1,   # SSIMæå¤±é‡ã¿\n",
    "\n",
    "    # å­¦ç¿’è¨­å®š\n",
    "    'n_epochs': 30,\n",
    "    'learning_rate': 1e-3,\n",
    "}\n",
    "\n",
    "print('ğŸ“‹ æ¤œè¨¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:')\n",
    "for k, v in CONFIG.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvBdeRnzOEyC"
   },
   "source": [
    "## 4. ãƒ‡ãƒ¼ã‚¿æº–å‚™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚»ã‚¯ã‚·ãƒ§ãƒ³4ã®è§£èª¬: DataLoaderã®å½¹å‰²\n",
    "\n",
    "#### ãªãœå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«æ­£å¸¸å“ã€Œã ã‘ã€ã‚’ä½¿ã†ã®ã‹ï¼Ÿ\n",
    "Autoencoderã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã«ã€Œæ­£å¸¸ã¨ã¯ä½•ã‹ã€ã ã‘ã‚’è¦šãˆã•ã›ã¾ã™ã€‚\n",
    "ãƒ†ã‚¹ãƒˆæ™‚ã«æ­£å¸¸ã‹ã‚‰å¤–ã‚ŒãŸç”»åƒï¼ˆï¼ç•°å¸¸å“ï¼‰ãŒã†ã¾ãå†æ§‹æˆã§ããªã„ã“ã¨ã‚’åˆ©ç”¨ã—ã¦ç•°å¸¸ã‚’æ¤œå‡ºã—ã¾ã™ã€‚\n",
    "\n",
    "ãã®ãŸã‚ï¼š\n",
    "- **å­¦ç¿’ãƒ‡ãƒ¼ã‚¿** (`train_dataset`): æ­£å¸¸å“ã®ã¿200æšï¼ˆ`include_anomaly=False`ï¼‰\n",
    "- **ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿** (`test_dataset`): æ­£å¸¸å“50æš + ç•°å¸¸å“50æšï¼ˆæ€§èƒ½ã‚’æ¸¬ã‚‹ãŸã‚ã«ä¸¡æ–¹å¿…è¦ï¼‰\n",
    "\n",
    "#### DataLoaderã®è¨­å®š\n",
    "- `shuffle=True`ï¼ˆå­¦ç¿’æ™‚ï¼‰: ãƒ‡ãƒ¼ã‚¿ã®é †ç•ªã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã—ã¦ã€ç‰¹å®šã®é †åºã¸ã®éé©åˆã‚’é˜²ã\n",
    "- `shuffle=False`ï¼ˆãƒ†ã‚¹ãƒˆæ™‚ï¼‰: çµæœã®å†ç¾æ€§ã®ãŸã‚ã€é †ç•ªã¯å›ºå®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYg2GyzpOEyD"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ DataLoaderä½œæˆ â”€â”€\n",
    "train_dataset = InspectionDataset(\n",
    "    n_normal=CONFIG['n_train'], n_anomaly=0,\n",
    "    image_size=CONFIG['image_size'], include_anomaly=False,\n",
    ")\n",
    "test_dataset = InspectionDataset(\n",
    "    n_normal=CONFIG['n_test_normal'], n_anomaly=CONFIG['n_test_anomaly'],\n",
    "    image_size=CONFIG['image_size'], include_anomaly=True,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "print(f'âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(train_dataset)}æšï¼ˆæ­£å¸¸å“ã®ã¿ï¼‰')\n",
    "print(f'âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_dataset)}æšï¼ˆæ­£å¸¸{CONFIG[\"n_test_normal\"]} + ç•°å¸¸{CONFIG[\"n_test_anomaly\"]}ï¼‰')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hglnzvh9OEyD"
   },
   "source": [
    "## 5. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚»ã‚¯ã‚·ãƒ§ãƒ³5ã®è§£èª¬: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®æµã‚Œ\n",
    "\n",
    "#### å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®å…¨ä½“åƒ\n",
    "```\n",
    "for epoch in range(30):           # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’30å›ç¹°ã‚Šè¿”ã™\n",
    "    for batch in train_loader:    # 16æšãšã¤å‡¦ç†\n",
    "        1. ç”»åƒã‚’ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ› â†’ å†æ§‹æˆç”»åƒã¨æ½œåœ¨å¤‰æ•°ã‚’å¾—ã‚‹\n",
    "        2. æå¤±ï¼ˆLossï¼‰ã‚’è¨ˆç®— â†’ å…¥åŠ›ã¨å‡ºåŠ›ã®ã€Œã‚ºãƒ¬ã€ã‚’æ•°å€¤åŒ–\n",
    "        3. èª¤å·®é€†ä¼æ’­ï¼ˆBackpropagationï¼‰ â†’ æå¤±ã‚’å°ã•ãã™ã‚‹æ–¹å‘ã‚’è¨ˆç®—\n",
    "        4. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ï¼ˆOptimizerï¼‰ â†’ ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å¾®èª¿æ•´\n",
    "```\n",
    "\n",
    "#### ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å½¹å‰²\n",
    "| ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | èª¬æ˜ |\n",
    "|-------------|------|\n",
    "| **Lossé–¢æ•°** | ã€Œã©ã‚Œã ã‘å†æ§‹æˆã«å¤±æ•—ã—ãŸã‹ã€ã‚’æ•°å€¤åŒ–ã™ã‚‹é–¢æ•° |\n",
    "| **Optimizer (Adam)** | æå¤±ã‚’æ¸›ã‚‰ã™ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  |\n",
    "| **Scheduler (CosineAnnealing)** | å­¦ç¿’ç‡ã‚’ã‚³ã‚µã‚¤ãƒ³ã‚«ãƒ¼ãƒ–ã«æ²¿ã£ã¦å¾ã€…ã«æ¸›ã‚‰ã™ã€‚åºç›¤ã¯å¤§ããå­¦ç¿’ã—ã€çµ‚ç›¤ã¯å¾®èª¿æ•´ã™ã‚‹ |\n",
    "\n",
    "#### æå¤±é–¢æ•°ã®é•ã„\n",
    "- **SAE**: `MSE + Î» Ã— L1(z)` â†’ å†æ§‹æˆç²¾åº¦ + ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã®ãƒãƒ©ãƒ³ã‚¹\n",
    "- **DAE**: `MSE + Î± Ã— (1 - SSIM)` â†’ å†æ§‹æˆç²¾åº¦ + æ§‹é€ ä¿å­˜ã®ãƒãƒ©ãƒ³ã‚¹\n",
    "\n",
    "#### å­¦ç¿’æ›²ç·šã®èª­ã¿æ–¹\n",
    "- LossãŒä¸‹ãŒã£ã¦ã„ã‚Œã°å­¦ç¿’ãŒé€²ã‚“ã§ã„ã‚‹\n",
    "- é€”ä¸­ã§æ¨ªã°ã„ã«ãªã‚Œã°ã€ŒåæŸã€â†’ ã“ã‚Œä»¥ä¸Šã‚¨ãƒãƒƒã‚¯æ•°ã‚’å¢—ã‚„ã—ã¦ã‚‚æ”¹å–„ã—ã«ãã„\n",
    "- æ€¥ã«ä¸Šæ˜‡ã—ãŸã‚‰ã€Œç™ºæ•£ã€â†’ å­¦ç¿’ç‡ãŒå¤§ãã™ãã‚‹å¯èƒ½æ€§\n",
    "\n",
    "#### ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°\n",
    "- `count_params()`: ãƒ¢ãƒ‡ãƒ«ã®ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’æ•°ãˆã‚‹\n",
    "- `model_size_mb()`: ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’MBå˜ä½ã§è¨ˆç®—\n",
    "- `sparsity()`: æ½œåœ¨å¤‰æ•°ã®ã†ã¡ã€ã»ã¼ã‚¼ãƒ­ï¼ˆ< 0.01ï¼‰ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å‰²åˆã‚’è¨ˆç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLCxIf3IOEyD"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ å­¦ç¿’é–¢æ•° â”€â”€\n",
    "def train_model(model, criterion, loader, config, model_name):\n",
    "    \"\"\"ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰\"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['n_epochs'])\n",
    "    model.to(DEVICE)\n",
    "    model.train()\n",
    "    losses = []\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    for epoch in range(config['n_epochs']):\n",
    "        ep_loss, nb = 0.0, 0\n",
    "        for imgs, _, _ in loader:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            recon, z = model(imgs)\n",
    "            loss, _ = criterion(imgs, recon, z)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ep_loss += loss.item(); nb += 1\n",
    "        scheduler.step()\n",
    "        avg = ep_loss / max(nb, 1)\n",
    "        losses.append(avg)\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(f'  {model_name} Epoch {epoch+1:3d}/{config[\"n_epochs\"]} | Loss: {avg:.6f}')\n",
    "\n",
    "    train_time = time.perf_counter() - t0\n",
    "    print(f'  âœ… {model_name} å­¦ç¿’å®Œäº†: {train_time:.1f}ç§’')\n",
    "    return losses, train_time\n",
    "\n",
    "\n",
    "# â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â”€â”€\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def model_size_mb(model):\n",
    "    ps = sum(p.nelement() * p.element_size() for p in model.parameters())\n",
    "    bs = sum(b.nelement() * b.element_size() for b in model.buffers())\n",
    "    return (ps + bs) / (1024 * 1024)\n",
    "\n",
    "def sparsity(z, thr=0.01):\n",
    "    return (z.abs() < thr).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7tcKNpghOEyD"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– â”€â”€\n",
    "sae = SparseAutoencoder(in_channels=1, latent_dim=CONFIG['sae_latent_dim'])\n",
    "dae = DeepAutoencoder(in_channels=1, latent_dim=CONFIG['dae_latent_dim'])\n",
    "sae_criterion = SparseAELoss(l1_weight=CONFIG['sae_l1_weight'])\n",
    "dae_criterion = DeepAELoss(ssim_weight=CONFIG['dae_ssim_weight'])\n",
    "\n",
    "print('â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”')\n",
    "print(f'â”‚ SAE: {count_params(sae):>10,} params | {model_size_mb(sae):>6.2f} MB â”‚')\n",
    "print(f'â”‚ DAE: {count_params(dae):>10,} params | {model_size_mb(dae):>6.2f} MB â”‚')\n",
    "print('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNB1VIq3OEyD"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ‹ï¸ Sparse AE å­¦ç¿’\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print('â”' * 50)\n",
    "print('ğŸ‹ï¸ Sparse Autoencoder å­¦ç¿’é–‹å§‹')\n",
    "print('â”' * 50)\n",
    "sae_losses, sae_train_time = train_model(sae, sae_criterion, train_loader, CONFIG, 'SAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xy0HWDDBOEyD"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ‹ï¸ Deep AE å­¦ç¿’\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print('â”' * 50)\n",
    "print('ğŸ‹ï¸ Deep Autoencoder å­¦ç¿’é–‹å§‹')\n",
    "print('â”' * 50)\n",
    "dae_losses, dae_train_time = train_model(dae, dae_criterion, train_loader, CONFIG, 'DAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnkO-W8yOEyD"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ å­¦ç¿’æ›²ç·šæ¯”è¼ƒ â”€â”€\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(sae_losses, color='#22d3ee', linewidth=2, label=f'Sparse AE ({sae_train_time:.1f}s)')\n",
    "ax.plot(dae_losses, color='#f97316', linewidth=2, label=f'Deep AE ({dae_train_time:.1f}s)')\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Loss')\n",
    "ax.set_title('å­¦ç¿’æ›²ç·šæ¯”è¼ƒ', fontsize=14, fontweight='bold')\n",
    "ax.legend(); ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_p3MJ12OEyE"
   },
   "source": [
    "## 6. è©•ä¾¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚»ã‚¯ã‚·ãƒ§ãƒ³6ã®è§£èª¬: è©•ä¾¡æŒ‡æ¨™ã®æ„å‘³\n",
    "\n",
    "ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ¸¬ã‚‹æŒ‡æ¨™ã‚’è§£èª¬ã—ã¾ã™ã€‚\n",
    "\n",
    "#### ç•°å¸¸ã‚¹ã‚³ã‚¢ã¨ã¯ï¼Ÿ\n",
    "å„ãƒ†ã‚¹ãƒˆç”»åƒã«å¯¾ã—ã¦ã€Œå…¥åŠ›ã¨å†æ§‹æˆç”»åƒã®å·®ï¼ˆMSEï¼‰ã€ã‚’è¨ˆç®—ã—ãŸå€¤ã§ã™ã€‚\n",
    "- ã‚¹ã‚³ã‚¢ãŒ**å°ã•ã„** â†’ ãƒ¢ãƒ‡ãƒ«ãŒã†ã¾ãå†æ§‹æˆã§ããŸ â†’ æ­£å¸¸å“ã‚‰ã—ã„\n",
    "- ã‚¹ã‚³ã‚¢ãŒ**å¤§ãã„** â†’ ãƒ¢ãƒ‡ãƒ«ãŒã†ã¾ãå†æ§‹æˆã§ããªã‹ã£ãŸ â†’ ç•°å¸¸å“ã‚‰ã—ã„\n",
    "\n",
    "#### è©•ä¾¡æŒ‡æ¨™ä¸€è¦§\n",
    "| æŒ‡æ¨™ | æ„å‘³ | ç†æƒ³å€¤ | åˆå¿ƒè€…å‘ã‘è§£èª¬ |\n",
    "|------|------|--------|---------------|\n",
    "| **AUC-ROC** | æ­£å¸¸/ç•°å¸¸ã®åˆ†é›¢èƒ½åŠ›ï¼ˆ0ã€œ1ï¼‰ | 1.0 | ã€Œ1ã«è¿‘ã„ã»ã©å„ªç§€ã€ã¨è¦šãˆã‚Œã°OKã€‚0.5ã¯ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆä½¿ã„ç‰©ã«ãªã‚‰ãªã„ï¼‰ |\n",
    "| **Best F1** | æœ€é©é–¾å€¤ã§ã®F1ã‚¹ã‚³ã‚¢ | 1.0 | é©åˆç‡ï¼ˆPrecisionï¼‰ã¨å†ç¾ç‡ï¼ˆRecallï¼‰ã®èª¿å’Œå¹³å‡ã€‚ãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã•ã‚’ç¤ºã™ |\n",
    "| **F1 (3Ïƒé–¾å€¤)** | çµ±è¨ˆçš„é–¾å€¤ï¼ˆå¹³å‡+3Ïƒï¼‰ã§ã®F1 | 1.0 | å®Ÿé‹ç”¨ã§ä½¿ã„ã‚„ã™ã„è‡ªå‹•é–¾å€¤ã§ã®æ€§èƒ½ |\n",
    "| **FPR@95TPR** | ç•°å¸¸å“ã®95%ã‚’æ¤œå‡ºã—ãŸæ™‚ã®èª¤æ¤œçŸ¥ç‡ | 0.0 | ã€Œç•°å¸¸ã‚’95%æ¤œå‡ºã™ã‚‹è¨­å®šã§ã€æ­£å¸¸å“ã‚’ä½•%é–“é•ãˆã‚‹ã‹ã€ |\n",
    "| **æ¨è«–é€Ÿåº¦** | 1æšã®ç”»åƒã‚’å‡¦ç†ã™ã‚‹ã®ã«ã‹ã‹ã‚‹æ™‚é–“ | å°ã•ã„ | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œæŸ»ã§ã¯1msä»¥ä¸‹ãŒç†æƒ³ |\n",
    "\n",
    "#### 3Ïƒé–¾å€¤ã¨ã¯ï¼Ÿ\n",
    "æ­£å¸¸å“ã®ã‚¹ã‚³ã‚¢åˆ†å¸ƒã‹ã‚‰ã€Œå¹³å‡ + 3Ã—æ¨™æº–åå·®ã€ã‚’é–¾å€¤ã«è¨­å®šã™ã‚‹æ–¹æ³•ã§ã™ã€‚\n",
    "æ­£è¦åˆ†å¸ƒã‚’ä»®å®šã™ã‚‹ã¨ã€æ­£å¸¸å“ãŒã“ã®é–¾å€¤ã‚’è¶…ãˆã‚‹ç¢ºç‡ã¯ç´„0.3%ã§ã€å®Ÿç”¨çš„ãªè‡ªå‹•è¨­å®šã¨ã—ã¦åºƒãä½¿ã‚ã‚Œã¾ã™ã€‚\n",
    "\n",
    "#### ã‚¹ã‚³ã‚¢åˆ†å¸ƒã‚°ãƒ©ãƒ•ã®è¦‹æ–¹\n",
    "- **ç·‘ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ **: æ­£å¸¸å“ã®ã‚¹ã‚³ã‚¢åˆ†å¸ƒ\n",
    "- **èµ¤ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ **: ç•°å¸¸å“ã®ã‚¹ã‚³ã‚¢åˆ†å¸ƒ\n",
    "- **ç™½ã„ç ´ç·š**: 3Ïƒé–¾å€¤\n",
    "\n",
    "ç·‘ã¨èµ¤ãŒé›¢ã‚Œã¦ã„ã‚‹ã»ã©ã€Œæ­£å¸¸ã¨ç•°å¸¸ã‚’ã¯ã£ãã‚ŠåŒºåˆ¥ã§ãã¦ã„ã‚‹ã€ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚\n",
    "é‡ãªã‚ŠãŒå¤šã„ã¨èª¤æ¤œçŸ¥ã‚„è¦‹é€ƒã—ãŒå¢—ãˆã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnCEvEhROEyE"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®— â”€â”€\n",
    "def compute_scores(model, loader, device):\n",
    "    \"\"\"å…¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç•°å¸¸ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—\"\"\"\n",
    "    model.eval()\n",
    "    scores, labels, error_maps = [], [], []\n",
    "    total_time, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbl, _ in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            bs = imgs.size(0)\n",
    "            t0 = time.perf_counter()\n",
    "            recon, z = model(imgs)\n",
    "            if device.type == 'cuda': torch.cuda.synchronize()\n",
    "            total_time += time.perf_counter() - t0\n",
    "            n += bs\n",
    "            err = (imgs - recon) ** 2\n",
    "            scores.extend(err.mean(dim=(1,2,3)).cpu().numpy())\n",
    "            labels.extend(lbl.numpy())\n",
    "            error_maps.extend(err.squeeze(1).cpu().numpy())\n",
    "    return np.array(scores), np.array(labels), error_maps, (total_time/n)*1000\n",
    "\n",
    "\n",
    "def compute_metrics(scores, labels):\n",
    "    \"\"\"è©•ä¾¡æŒ‡æ¨™\"\"\"\n",
    "    m = {}\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        m['auc_roc'] = roc_auc_score(labels, scores)\n",
    "        fpr, tpr, thr = roc_curve(labels, scores)\n",
    "        idx95 = np.argmin(np.abs(tpr - 0.95))\n",
    "        m['fpr_at_95tpr'] = fpr[idx95]\n",
    "        prec, rec, pthr = precision_recall_curve(labels, scores)\n",
    "        f1s = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "        m['best_f1'] = f1s.max()\n",
    "        ns = scores[labels == 0]\n",
    "        thr3s = ns.mean() + 3 * ns.std()\n",
    "        m['f1_3sigma'] = f1_score(labels, (scores > thr3s).astype(int), zero_division=0)\n",
    "    m['normal_mean'] = scores[labels==0].mean()\n",
    "    m['normal_std'] = scores[labels==0].std()\n",
    "    m['anomaly_mean'] = scores[labels==1].mean()\n",
    "    m['anomaly_std'] = scores[labels==1].std()\n",
    "    return m\n",
    "\n",
    "\n",
    "print('ğŸ“Š ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—ä¸­...')\n",
    "sae_scores, sae_labels, sae_maps, sae_inf = compute_scores(sae, test_loader, DEVICE)\n",
    "dae_scores, dae_labels, dae_maps, dae_inf = compute_scores(dae, test_loader, DEVICE)\n",
    "sae_m = compute_metrics(sae_scores, sae_labels)\n",
    "dae_m = compute_metrics(dae_scores, dae_labels)\n",
    "print('âœ… å®Œäº†')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Yn3HSqzOEyE"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“Š å®šé‡è©•ä¾¡çµæœ\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print('\\n' + 'â•' * 65)\n",
    "print('  ğŸ“Š å®šé‡è©•ä¾¡çµæœ')\n",
    "print('â•' * 65)\n",
    "print(f'{\"æŒ‡æ¨™\":<20} {\"Sparse AE\":>15} {\"Deep AE\":>15}  {\"Winner\":>8}')\n",
    "print('â”€' * 65)\n",
    "\n",
    "comparisons = [\n",
    "    ('AUC-ROC',          sae_m.get('auc_roc',0),     dae_m.get('auc_roc',0),     'higher'),\n",
    "    ('Best F1',          sae_m.get('best_f1',0),     dae_m.get('best_f1',0),     'higher'),\n",
    "    ('F1 (3Ïƒé–¾å€¤)',      sae_m.get('f1_3sigma',0),   dae_m.get('f1_3sigma',0),   'higher'),\n",
    "    ('FPR@95TPR',        sae_m.get('fpr_at_95tpr',0),dae_m.get('fpr_at_95tpr',0),'lower'),\n",
    "    ('æ¨è«–é€Ÿåº¦ (ms)',    sae_inf,                     dae_inf,                     'lower'),\n",
    "    ('å­¦ç¿’æ™‚é–“ (s)',     sae_train_time,              dae_train_time,              'lower'),\n",
    "    ('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°',    count_params(sae),           count_params(dae),           'lower'),\n",
    "    ('ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º(MB)', model_size_mb(sae),          model_size_mb(dae),          'lower'),\n",
    "]\n",
    "\n",
    "for name, sv, dv, direction in comparisons:\n",
    "    if isinstance(sv, int):\n",
    "        sf, df = f'{sv:>15,}', f'{dv:>15,}'\n",
    "    else:\n",
    "        sf, df = f'{sv:>15.4f}', f'{dv:>15.4f}'\n",
    "    if direction == 'higher':\n",
    "        w = '  SAE âœ“' if sv > dv else '  DAE âœ“'\n",
    "    else:\n",
    "        w = '  SAE âœ“' if sv < dv else '  DAE âœ“'\n",
    "    print(f'{name:<20} {sf} {df} {w}')\n",
    "\n",
    "print('â•' * 65)\n",
    "\n",
    "# ç²¾åº¦å·®ã®è©•ä¾¡\n",
    "auc_diff = abs(sae_m.get('auc_roc',0) - dae_m.get('auc_roc',0))\n",
    "speed_ratio = dae_inf / max(sae_inf, 0.001)\n",
    "print(f'\\nğŸ“Œ AUC-ROCå·®: {auc_diff:.4f}  |  é€Ÿåº¦æ¯”: SAEãŒ{speed_ratio:.1f}å€é«˜é€Ÿ')\n",
    "if auc_diff < 0.05 and speed_ratio > 3:\n",
    "    print('ğŸ’¡ çµè«–: ç²¾åº¦å·®ãŒå°ã•ãé€Ÿåº¦å·®ãŒå¤§ãã„ â†’ ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒå®Ÿç”¨çš„')\n",
    "elif auc_diff > 0.1:\n",
    "    print('ğŸ’¡ çµè«–: ç²¾åº¦å·®ãŒå¤§ãã„ â†’ ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ¢ãƒ‡ãƒ«ã‚’æ¨å¥¨')\n",
    "else:\n",
    "    print('ğŸ’¡ çµè«–: ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚ã‚Š â†’ è£½é€ ãƒ©ã‚¤ãƒ³è¦ä»¶ã«å¿œã˜ã¦é¸æŠ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "raAtgL2WOEyE"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ç•°å¸¸ã‚¹ã‚³ã‚¢åˆ†å¸ƒ â”€â”€\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, scores, labels, title, color in [\n",
    "    (ax1, sae_scores, sae_labels, 'Sparse AE', '#22d3ee'),\n",
    "    (ax2, dae_scores, dae_labels, 'Deep AE', '#f97316'),\n",
    "]:\n",
    "    ns, ans = scores[labels==0], scores[labels==1]\n",
    "    ax.hist(ns, bins=30, alpha=0.7, color='#10b981', label='æ­£å¸¸', density=True)\n",
    "    ax.hist(ans, bins=30, alpha=0.7, color='#ef4444', label='ç•°å¸¸', density=True)\n",
    "    ax.axvline(ns.mean() + 3*ns.std(), color='white', ls='--', lw=1.5, label='3Ïƒé–¾å€¤')\n",
    "    ax.set_title(title, fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('ç•°å¸¸ã‚¹ã‚³ã‚¢'); ax.legend()\n",
    "    ax.grid(alpha=0.2)\n",
    "\n",
    "plt.suptitle('ç•°å¸¸ã‚¹ã‚³ã‚¢åˆ†å¸ƒæ¯”è¼ƒ', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'score_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0z6DgUFOEyE"
   },
   "source": [
    "## 7. ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚»ã‚¯ã‚·ãƒ§ãƒ³7ã®è§£èª¬: ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®è¦‹æ–¹\n",
    "\n",
    "#### ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã¨ã¯ï¼Ÿ\n",
    "ç”»åƒä¸Šã®å„ãƒ”ã‚¯ã‚»ãƒ«ã§ã€Œã©ã‚Œã ã‘å†æ§‹æˆã«å¤±æ•—ã—ãŸã‹ï¼ˆï¼ç•°å¸¸åº¦ï¼‰ã€ã‚’è‰²ã§è¡¨ç¤ºã—ãŸã‚‚ã®ã§ã™ã€‚\n",
    "\n",
    "- **é’è‰²**: å†æ§‹æˆèª¤å·®ãŒå°ã•ã„ï¼ˆæ­£å¸¸ãªç®‡æ‰€ï¼‰\n",
    "- **é»„è‰²**: ä¸­ç¨‹åº¦ã®èª¤å·®ï¼ˆã‚„ã‚„æ°—ã«ãªã‚‹ç®‡æ‰€ï¼‰\n",
    "- **èµ¤è‰²**: å†æ§‹æˆèª¤å·®ãŒå¤§ãã„ï¼ˆç•°å¸¸ã®å¯èƒ½æ€§ãŒé«˜ã„ç®‡æ‰€ï¼‰\n",
    "\n",
    "#### å„åˆ—ã®æ„å‘³\n",
    "| åˆ— | è¡¨ç¤ºå†…å®¹ | èª¬æ˜ |\n",
    "|----|---------|------|\n",
    "| å…ƒç”»åƒ | ãƒ†ã‚¹ãƒˆç”»åƒãã®ã‚‚ã® | å…¥åŠ›ã¨ã—ã¦ä¸ãˆãŸç”»åƒ |\n",
    "| çœŸå€¤ãƒã‚¹ã‚¯ | å®Ÿéš›ã®æ¬ é™¥ä½ç½® | åˆæˆãƒ‡ãƒ¼ã‚¿ã§ã¯æ­£è§£ãŒã‚ã‹ã£ã¦ã„ã‚‹ã®ã§æ¯”è¼ƒã«ä½¿ã† |\n",
    "| SAEå†æ§‹æˆ | SAEãŒå¾©å…ƒã—ãŸç”»åƒ | æ­£å¸¸ãªéƒ¨åˆ†ã¯ã†ã¾ãå¾©å…ƒã•ã‚Œã€ç•°å¸¸éƒ¨åˆ†ã¯ã¼ã‚„ã‘ã‚‹ |\n",
    "| DAEå†æ§‹æˆ | DAEãŒå¾©å…ƒã—ãŸç”»åƒ | SAEã‚ˆã‚Šé«˜ç²¾åº¦ã ãŒã€å‡¦ç†ã¯é…ã„ |\n",
    "| SAEã‚¨ãƒ©ãƒ¼ / DAEã‚¨ãƒ©ãƒ¼ | å†æ§‹æˆèª¤å·®ãƒãƒƒãƒ— | `|å…¥åŠ› - å†æ§‹æˆ|` ã®çµ¶å¯¾å€¤ã€‚èµ¤ã„ç®‡æ‰€ãŒç•°å¸¸å€™è£œ |\n",
    "| SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ | å…ƒç”»åƒã«ã‚¨ãƒ©ãƒ¼ã‚’é‡ã­ãŸå›³ | å®Ÿéš›ã®æ¤œæŸ»ç”»é¢ã§ä½¿ã†ã‚¤ãƒ¡ãƒ¼ã‚¸ |\n",
    "\n",
    "#### æ½œåœ¨ç©ºé–“ã®ã‚¹ãƒ‘ãƒ¼ã‚¹åº¦\n",
    "æ£’ã‚°ãƒ©ãƒ•ã¯æ½œåœ¨å¤‰æ•° `z` ã®å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ´»æ€§åŒ–å€¤ï¼ˆçµ¶å¯¾å€¤ï¼‰ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚\n",
    "- **SAE**: L1æ­£å‰‡åŒ–ã«ã‚ˆã‚Šã€å¤§éƒ¨åˆ†ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒã‚¼ãƒ­è¿‘ãã«æŠ‘ãˆã‚‰ã‚Œã€å°‘æ•°ã ã‘ãŒé«˜ã„å€¤ã‚’æŒã¤ï¼ˆ**ã‚¹ãƒ‘ãƒ¼ã‚¹**ï¼‰\n",
    "- **DAE**: æ­£å‰‡åŒ–ãªã—ã®ãŸã‚ã€å¤šãã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒã¾ã‚“ã¹ã‚“ãªãæ´»æ€§åŒ–ã—ã¦ã„ã‚‹ï¼ˆ**å¯†**ï¼‰\n",
    "\n",
    "ã‚¹ãƒ‘ãƒ¼ã‚¹ãªè¡¨ç¾ã¯ã€Œã“ã®ç”»åƒã®ã©ã®ç‰¹å¾´ãŒé‡è¦ã‹ã€ãŒæ˜ç¢ºã§ã€è§£é‡ˆæ€§ãŒé«˜ã„ã¨ã„ã†åˆ©ç‚¹ãŒã‚ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5PmJsHwOEyE"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ç•°å¸¸æ¤œçŸ¥ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æ¯”è¼ƒ â”€â”€\n",
    "all_imgs, all_labels_t, all_masks_t = [], [], []\n",
    "for imgs, lbl, msk in test_loader:\n",
    "    all_imgs.append(imgs); all_labels_t.append(lbl); all_masks_t.append(msk)\n",
    "all_imgs = torch.cat(all_imgs)\n",
    "all_labels = torch.cat(all_labels_t).numpy()\n",
    "all_masks = torch.cat(all_masks_t)\n",
    "\n",
    "anomaly_idx = np.where(all_labels == 1)[0]\n",
    "n_show = min(6, len(anomaly_idx))\n",
    "sel = anomaly_idx[:n_show]\n",
    "\n",
    "sae.eval(); dae.eval()\n",
    "n_cols = 7\n",
    "fig, axes = plt.subplots(n_show, n_cols, figsize=(n_cols*3, n_show*3))\n",
    "if n_show == 1: axes = axes.reshape(1, -1)\n",
    "\n",
    "col_titles = ['å…ƒç”»åƒ', 'çœŸå€¤ãƒã‚¹ã‚¯', 'SAEå†æ§‹æˆ', 'DAEå†æ§‹æˆ',\n",
    "              'SAEã‚¨ãƒ©ãƒ¼', 'DAEã‚¨ãƒ©ãƒ¼', 'SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤']\n",
    "for j, t in enumerate(col_titles):\n",
    "    axes[0, j].set_title(t, fontsize=10, fontweight='bold')\n",
    "\n",
    "for i, idx in enumerate(sel):\n",
    "    img = all_imgs[idx:idx+1].to(DEVICE)\n",
    "    mask = all_masks[idx].squeeze().numpy()\n",
    "    with torch.no_grad():\n",
    "        sr, _ = sae(img)\n",
    "        dr, _ = dae(img)\n",
    "    inp = all_imgs[idx].squeeze().numpy()\n",
    "    sr_np = sr.squeeze().cpu().numpy()\n",
    "    dr_np = dr.squeeze().cpu().numpy()\n",
    "    se = np.abs(inp - sr_np)\n",
    "    de = np.abs(inp - dr_np)\n",
    "    overlay = create_overlay(inp, se, alpha=0.55)\n",
    "\n",
    "    panels = [\n",
    "        (inp,     'gray', 1.0,  False),\n",
    "        (mask,    'Reds', 1.0,  False),\n",
    "        (sr_np,   'gray', 1.0,  False),\n",
    "        (dr_np,   'gray', 1.0,  False),\n",
    "        (se,      INSPECTION_CMAP, None, True),\n",
    "        (de,      INSPECTION_CMAP, None, True),\n",
    "        (overlay, None,   None, False),\n",
    "    ]\n",
    "    for j, (p, cm, vmax_f, add_cbar) in enumerate(panels):\n",
    "        ax = axes[i, j]\n",
    "        if cm is None:\n",
    "            ax.imshow(p)\n",
    "        elif vmax_f is not None:\n",
    "            ax.imshow(p, cmap=cm, vmin=0, vmax=vmax_f)\n",
    "        else:\n",
    "            vmax = max(p.max(), 0.001)\n",
    "            im = ax.imshow(p, cmap=cm, vmin=0, vmax=vmax)\n",
    "            if add_cbar:\n",
    "                cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "                cbar.ax.tick_params(labelsize=6)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.suptitle('ç•°å¸¸æ¤œçŸ¥ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æ¯”è¼ƒ', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'heatmap_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VeZm1U9DOEyE"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ æ½œåœ¨ç©ºé–“ã®ã‚¹ãƒ‘ãƒ¼ã‚¹åº¦å¯è¦–åŒ– â”€â”€\n",
    "sample = all_imgs[:1].to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    _, sz = sae(sample)\n",
    "    _, dz = dae(sample)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 3.5))\n",
    "\n",
    "szn = sz.cpu().numpy().flatten()\n",
    "dzn = dz.cpu().numpy().flatten()\n",
    "\n",
    "ax1.bar(range(len(szn)), np.abs(szn), color='#22d3ee', alpha=0.8, width=1.0)\n",
    "ax1.set_title(f'SAE æ½œåœ¨è¡¨ç¾ (ã‚¹ãƒ‘ãƒ¼ã‚¹åº¦: {sparsity(sz):.1%})', fontweight='bold')\n",
    "ax1.set_xlabel('ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³Index'); ax1.set_ylabel('|æ´»æ€§åŒ–å€¤|')\n",
    "\n",
    "ax2.bar(range(len(dzn)), np.abs(dzn), color='#f97316', alpha=0.8, width=1.0)\n",
    "ax2.set_title(f'DAE æ½œåœ¨è¡¨ç¾ (ã‚¹ãƒ‘ãƒ¼ã‚¹åº¦: {sparsity(dz):.1%})', fontweight='bold')\n",
    "ax2.set_xlabel('ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³Index'); ax2.set_ylabel('|æ´»æ€§åŒ–å€¤|')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'sparsity_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f'ğŸ’¡ SAEã¯å°‘æ•°ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã ã‘ãŒå¼·ãæ´»æ€§åŒ– â†’ é‡è¦ãªç‰¹å¾´ã«é›†ä¸­')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-ANx5rMOEyE"
   },
   "source": [
    "## 8. ãƒ¢ãƒ‡ãƒ«ä¿å­˜ & ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚»ã‚¯ã‚·ãƒ§ãƒ³8ã®è§£èª¬: ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å½¢å¼\n",
    "\n",
    "#### `.pth`ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆPyTorchå½¢å¼ï¼‰\n",
    "PyTorchã®æ¨™æº–çš„ãªä¿å­˜å½¢å¼ã§ã™ã€‚`state_dict()`ã§ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ã ã‘ã‚’ä¿å­˜ã—ã¾ã™ã€‚\n",
    "èª­ã¿è¾¼ã‚€éš›ã¯ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ã®å®šç¾©ãŒå¿…è¦ã§ã™ã€‚Python + PyTorchç’°å¢ƒã§ã®é–‹ç™ºãƒ»ç ”ç©¶ã«ä½¿ã„ã¾ã™ã€‚\n",
    "\n",
    "#### `.onnx`ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆONNXå½¢å¼ï¼‰\n",
    "**ONNX (Open Neural Network Exchange)** ã¯ã€ç•°ãªã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–“ã§ãƒ¢ãƒ‡ãƒ«ã‚’å…±æœ‰ã™ã‚‹ãŸã‚ã®æ¨™æº–å½¢å¼ã§ã™ã€‚\n",
    "- C++ã‚„Rustãªã©ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰Pythonãªã—ã§å®Ÿè¡Œã§ãã‚‹\n",
    "- NVIDIA TensorRTã€Intel OpenVINOãªã©ã®æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã§é«˜é€ŸåŒ–ã§ãã‚‹\n",
    "- ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹ï¼ˆJetsonã€Raspberry Piãªã©ï¼‰ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹éš›ã«å¿…é ˆ\n",
    "\n",
    "#### `benchmark_results.json`\n",
    "ã™ã¹ã¦ã®è©•ä¾¡çµæœï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã€å„ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚³ã‚¢ã€æ¨è«–é€Ÿåº¦ãªã©ï¼‰ã‚’JSONå½¢å¼ã§ä¿å­˜ã—ã¾ã™ã€‚\n",
    "å¾Œã‹ã‚‰çµæœã‚’æ¯”è¼ƒãƒ»åˆ†æã—ãŸã‚Šã€ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹éš›ã«ä¾¿åˆ©ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJC9zQJiOEyE"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ â”€â”€\n",
    "torch.save(sae.state_dict(), SAVE_DIR / 'sparse_ae.pth')\n",
    "torch.save(dae.state_dict(), SAVE_DIR / 'deep_ae.pth')\n",
    "print(f'ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {SAVE_DIR}')\n",
    "\n",
    "# â”€â”€ ONNX ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆã‚¨ãƒƒã‚¸å±•é–‹ç”¨ï¼‰â”€â”€\n",
    "try:\n",
    "    dummy = torch.randn(1, 1, CONFIG['image_size'], CONFIG['image_size']).to('cpu')\n",
    "    sae_cpu = SparseAutoencoder(latent_dim=CONFIG['sae_latent_dim']).cpu()\n",
    "    sae_cpu.load_state_dict(sae.cpu().state_dict())\n",
    "    sae_cpu.eval()\n",
    "    torch.onnx.export(\n",
    "        sae_cpu, dummy,\n",
    "        str(SAVE_DIR / 'sparse_ae.onnx'),\n",
    "        input_names=['input'], output_names=['reconstruction', 'latent'],\n",
    "        dynamic_axes={'input': {0: 'batch'}, 'reconstruction': {0: 'batch'}},\n",
    "        opset_version=14,\n",
    "    )\n",
    "    onnx_size = os.path.getsize(SAVE_DIR / 'sparse_ae.onnx') / (1024*1024)\n",
    "    print(f'âœ… ONNX ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: sparse_ae.onnx ({onnx_size:.2f} MB)')\n",
    "    sae.to(DEVICE)  # GPUã«æˆ»ã™\n",
    "except Exception as e:\n",
    "    print(f'âš ï¸ ONNX ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¹ã‚­ãƒƒãƒ—: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VV9QRjr0OEyE"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ è©•ä¾¡çµæœã‚’JSONã§ä¿å­˜ â”€â”€\n",
    "results = {\n",
    "    'config': CONFIG,\n",
    "    'device': str(DEVICE),\n",
    "    'sparse_ae': {\n",
    "        'params': count_params(sae),\n",
    "        'size_mb': round(model_size_mb(sae), 3),\n",
    "        'train_time_s': round(sae_train_time, 2),\n",
    "        'inference_ms': round(sae_inf, 3),\n",
    "        'metrics': {k: round(float(v), 5) for k, v in sae_m.items()},\n",
    "    },\n",
    "    'deep_ae': {\n",
    "        'params': count_params(dae),\n",
    "        'size_mb': round(model_size_mb(dae), 3),\n",
    "        'train_time_s': round(dae_train_time, 2),\n",
    "        'inference_ms': round(dae_inf, 3),\n",
    "        'metrics': {k: round(float(v), 5) for k, v in dae_m.items()},\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(SAVE_DIR / 'benchmark_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f'ğŸ’¾ çµæœä¿å­˜: {SAVE_DIR}/benchmark_results.json')\n",
    "print('\\nğŸ“‚ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:')\n",
    "for f in sorted(SAVE_DIR.iterdir()):\n",
    "    sz = f.stat().st_size / 1024\n",
    "    print(f'  {f.name:<30} {sz:>8.1f} KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr4Bou0NOEyF"
   },
   "source": [
    "## 9. å®Ÿãƒ‡ãƒ¼ã‚¿ã¸ã®åˆ‡ã‚Šæ›¿ãˆæ–¹æ³•\n",
    "\n",
    "åˆæˆãƒ‡ãƒ¼ã‚¿ã§å‹•ä½œç¢ºèªãŒã§ããŸã‚‰ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’ä½¿ã£ã¦å®Ÿãƒ‡ãƒ¼ã‚¿ã«å·®ã—æ›¿ãˆã‚‰ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5Hlk4fYOEyF"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# å®Ÿãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\n",
    "# Google Drive ã¾ãŸã¯ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ç”»åƒã‚’èª­ã¿è¾¼ã‚€\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# --- ã“ã®ã‚»ãƒ«ã¯å¿…è¦ãªæ™‚ã«ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦ä½¿ç”¨ ---\n",
    "\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import glob\n",
    "#\n",
    "# class RealImageDataset(Dataset):\n",
    "#     \"\"\"å®Ÿç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\"\"\"\n",
    "#     def __init__(self, image_dir, label=0, image_size=128):\n",
    "#         self.paths = sorted(glob.glob(f'{image_dir}/*.png') +\n",
    "#                            glob.glob(f'{image_dir}/*.jpg') +\n",
    "#                            glob.glob(f'{image_dir}/*.bmp'))\n",
    "#         self.label = label\n",
    "#         self.transform = transforms.Compose([\n",
    "#             transforms.Resize((image_size, image_size)),\n",
    "#             transforms.Grayscale(num_output_channels=1),\n",
    "#             transforms.ToTensor(),\n",
    "#         ])\n",
    "#\n",
    "#     def __len__(self): return len(self.paths)\n",
    "#     def __getitem__(self, idx):\n",
    "#         img = Image.open(self.paths[idx]).convert('L')\n",
    "#         img_t = self.transform(img)\n",
    "#         mask = torch.zeros_like(img_t)\n",
    "#         return img_t, self.label, mask\n",
    "#\n",
    "# # ä½¿ã„æ–¹:\n",
    "# # Google Driveä¸Šã«ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ:\n",
    "# #   /content/drive/MyDrive/inspection_data/\n",
    "# #     â”œâ”€â”€ train/normal/     â† æ­£å¸¸å“ç”»åƒ\n",
    "# #     â””â”€â”€ test/\n",
    "# #         â”œâ”€â”€ normal/       â† ãƒ†ã‚¹ãƒˆæ­£å¸¸å“\n",
    "# #         â””â”€â”€ anomaly/      â† ãƒ†ã‚¹ãƒˆç•°å¸¸å“\n",
    "#\n",
    "# REAL_DATA_DIR = '/content/drive/MyDrive/inspection_data'\n",
    "#\n",
    "# train_real = RealImageDataset(f'{REAL_DATA_DIR}/train/normal', label=0)\n",
    "# test_normal = RealImageDataset(f'{REAL_DATA_DIR}/test/normal', label=0)\n",
    "# test_anomaly = RealImageDataset(f'{REAL_DATA_DIR}/test/anomaly', label=1)\n",
    "# test_real = torch.utils.data.ConcatDataset([test_normal, test_anomaly])\n",
    "#\n",
    "# train_loader = DataLoader(train_real, batch_size=16, shuffle=True)\n",
    "# test_loader = DataLoader(test_real, batch_size=16, shuffle=False)\n",
    "#\n",
    "# print(f'å®Ÿãƒ‡ãƒ¼ã‚¿: å­¦ç¿’{len(train_real)}æš, ãƒ†ã‚¹ãƒˆ{len(test_real)}æš')\n",
    "\n",
    "print('ğŸ’¡ å®Ÿãƒ‡ãƒ¼ã‚¿ä½¿ç”¨æ™‚ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„')\n",
    "print('   ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆ:')\n",
    "print('   inspection_data/')\n",
    "print('   â”œâ”€â”€ train/normal/     â† æ­£å¸¸å“ç”»åƒ')\n",
    "print('   â””â”€â”€ test/')\n",
    "print('       â”œâ”€â”€ normal/       â† ãƒ†ã‚¹ãƒˆæ­£å¸¸å“')\n",
    "print('       â””â”€â”€ anomaly/      â† ãƒ†ã‚¹ãƒˆç•°å¸¸å“')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9guCbOWOEyF"
   },
   "source": [
    "---\n",
    "## ğŸ“ è£œè¶³æƒ…å ±\n",
    "\n",
    "### Windows ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ–¹æ³•\n",
    "\n",
    "```bash\n",
    "# 1. ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "# 2. Jupyter Notebook/Lab ã§é–‹ã\n",
    "pip install jupyter torch torchvision scikit-learn matplotlib\n",
    "jupyter notebook inspection_ai_benchmark.ipynb\n",
    "\n",
    "# ã¾ãŸã¯ .py ã«å¤‰æ›ã—ã¦å®Ÿè¡Œ\n",
    "jupyter nbconvert --to script inspection_ai_benchmark.ipynb\n",
    "python inspection_ai_benchmark.py\n",
    "```\n",
    "\n",
    "### ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•å¯¾å¿œ\n",
    "| ç’°å¢ƒ | ãƒ‡ãƒã‚¤ã‚¹ | å‚™è€ƒ |\n",
    "|------|----------|------|\n",
    "| Google Colab | CUDA (T4) | æœ€é€Ÿã€‚ç„¡æ–™æ ã§åˆ©ç”¨å¯ |\n",
    "| Windows + NVIDIA GPU | CUDA | CUDAãƒ‰ãƒ©ã‚¤ãƒè¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« |\n",
    "| Windows (GPUãªã—) | CPU | å‹•ä½œã™ã‚‹ãŒå­¦ç¿’ã«æ™‚é–“ãŒã‹ã‹ã‚‹ |\n",
    "| MacBook (M5) | MPS | Apple SiliconåŠ é€Ÿ |\n",
    "\n",
    "### æ¨å¥¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´\n",
    "| ç›®çš„ | å¤‰æ›´ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ |\n",
    "|------|-------------------|\n",
    "| ç²¾åº¦å‘ä¸Š | `n_epochs` â†‘, `n_train` â†‘ |\n",
    "| SAEã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–å¼·åŒ– | `sae_l1_weight` â†‘ (5e-3 ~ 1e-2) |\n",
    "| DAEç²¾åº¦é‡è¦– | `dae_ssim_weight` â†‘, `dae_latent_dim` â†‘ |\n",
    "| é«˜é€Ÿæ¤œè¨¼ | `image_size=64`, `n_epochs=10` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWhdTvDNOEyF"
   },
   "source": [
    "## 10. ğŸ–¼ï¸ ãƒ†ã‚¹ãƒˆç”»åƒã®èª­ã¿è¾¼ã¿ã¨åˆ¤å®š\n",
    "\n",
    "å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«è‡ªåˆ†ã®ç”»åƒã‚’å…¥åŠ›ã—ã¦åˆ¤å®šçµæœã‚’ç¢ºèªã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚»ã‚¯ã‚·ãƒ§ãƒ³10ã®è§£èª¬: ãƒ†ã‚¹ãƒˆç”»åƒã®æ¨è«–ãƒ•ãƒ­ãƒ¼\n",
    "\n",
    "#### æ¨è«–ã®æµã‚Œ\n",
    "```\n",
    "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ« â†’ PILç”»åƒ â†’ ãƒªã‚µã‚¤ã‚º(128Ã—128) â†’ ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ› â†’ ãƒ†ãƒ³ã‚½ãƒ«åŒ–\n",
    "    â†’ SAEã«å…¥åŠ› â†’ å†æ§‹æˆç”»åƒ â†’ å†æ§‹æˆèª¤å·®ï¼ˆç•°å¸¸ã‚¹ã‚³ã‚¢ï¼‰è¨ˆç®—\n",
    "    â†’ DAEã«å…¥åŠ› â†’ å†æ§‹æˆç”»åƒ â†’ å†æ§‹æˆèª¤å·®ï¼ˆç•°å¸¸ã‚¹ã‚³ã‚¢ï¼‰è¨ˆç®—\n",
    "    â†’ é–¾å€¤ã¨æ¯”è¼ƒ â†’ æ­£å¸¸/ç•°å¸¸ã®åˆ¤å®š\n",
    "```\n",
    "\n",
    "#### 3ã¤ã®å®Ÿè¡Œæ–¹æ³•\n",
    "| æ–¹æ³• | ç”¨é€” | ç’°å¢ƒ |\n",
    "|------|------|------|\n",
    "| **æ–¹æ³•A: åˆæˆãƒ†ã‚¹ãƒˆ** | å‹•ä½œç¢ºèªãƒ»ãƒ‡ãƒ¢ | ã©ã“ã§ã‚‚ |\n",
    "| **æ–¹æ³•B: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰** | å°‘æ•°ç”»åƒã®æ‰‹è»½ãªãƒ†ã‚¹ãƒˆ | Google Colab |\n",
    "| **æ–¹æ³•C: ãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®š** | å¤§é‡ç”»åƒã®ä¸€æ‹¬æ¤œæŸ» | Windows / Mac / Colab |\n",
    "\n",
    "#### é–¾å€¤ã®è¨­å®š\n",
    "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆæ­£å¸¸å“ï¼‰ã®ã‚¹ã‚³ã‚¢åˆ†å¸ƒã‹ã‚‰ã€Œå¹³å‡ + 3Ã—æ¨™æº–åå·®ã€ã‚’è‡ªå‹•è¨ˆç®—ã—ã¦ã„ã¾ã™ã€‚\n",
    "ã“ã®é–¾å€¤ã‚’è¶…ãˆã‚‹ã‚¹ã‚³ã‚¢ã‚’æŒã¤ç”»åƒã¯ã€Œç•°å¸¸ã€ã¨åˆ¤å®šã•ã‚Œã¾ã™ã€‚\n",
    "GUIã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§é–¾å€¤ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€æ¤œå‡ºæ„Ÿåº¦ã¨èª¤æ¤œçŸ¥ç‡ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å¤‰ãˆã‚‰ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8OapdzTOEyF"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ãƒ†ã‚¹ãƒˆç”»åƒã®èª­ã¿è¾¼ã¿ & æ¨è«–\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import torchvision.transforms as T_transforms\n",
    "from PIL import Image as PILImage\n",
    "import glob\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def preprocess_image(pil_img, target_size=128):\n",
    "    \"\"\"ç”»åƒã‚’ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ã«å¤‰æ›\"\"\"\n",
    "    transform = T_transforms.Compose([\n",
    "        T_transforms.Resize((target_size, target_size)),\n",
    "        T_transforms.Grayscale(num_output_channels=1),\n",
    "        T_transforms.ToTensor(),\n",
    "    ])\n",
    "    return transform(pil_img).unsqueeze(0)\n",
    "\n",
    "\n",
    "def run_inspection(image_paths_or_pils, sae_model, dae_model, device,\n",
    "                   image_size=128, sae_threshold=None, dae_threshold=None):\n",
    "    \"\"\"ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒãƒƒãƒæ¨è«–\"\"\"\n",
    "    sae_model.to(device).eval()\n",
    "    dae_model.to(device).eval()\n",
    "    results = []\n",
    "\n",
    "    for item in image_paths_or_pils:\n",
    "        if isinstance(item, str):\n",
    "            name = os.path.basename(item)\n",
    "            pil = PILImage.open(item).convert('RGB')\n",
    "        else:\n",
    "            name = getattr(item, 'filename', 'uploaded')\n",
    "            pil = item if isinstance(item, PILImage.Image) else PILImage.open(item).convert('RGB')\n",
    "\n",
    "        # å…ƒç”»åƒRGBï¼ˆãƒªã‚µã‚¤ã‚ºæ¸ˆã¿ï¼‰\n",
    "        original_rgb = np.array(pil.resize((image_size, image_size))).astype(np.float32) / 255.0\n",
    "\n",
    "        tensor = preprocess_image(pil, image_size).to(device)\n",
    "        with torch.no_grad():\n",
    "            sae_r, _ = sae_model(tensor)\n",
    "            dae_r, _ = dae_model(tensor)\n",
    "\n",
    "        sae_score = ((tensor - sae_r)**2).mean().item()\n",
    "        dae_score = ((tensor - dae_r)**2).mean().item()\n",
    "\n",
    "        results.append({\n",
    "            'name': name,\n",
    "            'pil': pil,\n",
    "            'original_rgb': original_rgb,\n",
    "            'input': tensor.squeeze().cpu().numpy(),\n",
    "            'sae_recon': sae_r.squeeze().cpu().numpy(),\n",
    "            'dae_recon': dae_r.squeeze().cpu().numpy(),\n",
    "            'sae_error': torch.abs(tensor - sae_r).squeeze().cpu().numpy(),\n",
    "            'dae_error': torch.abs(tensor - dae_r).squeeze().cpu().numpy(),\n",
    "            'sae_score': sae_score,\n",
    "            'dae_score': dae_score,\n",
    "            'sae_judge': 'ç•°å¸¸' if (sae_threshold and sae_score > sae_threshold) else 'æ­£å¸¸',\n",
    "            'dae_judge': 'ç•°å¸¸' if (dae_threshold and dae_score > dae_threshold) else 'æ­£å¸¸',\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def display_results(results):\n",
    "    \"\"\"çµæœã‚’è¡¨ã¨ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§è¡¨ç¤ºï¼ˆ7åˆ—: å…ƒç”»åƒ+ã‚¨ãƒ©ãƒ¼+ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼‰\"\"\"\n",
    "    # ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«\n",
    "    print('\\n' + 'â•'*75)\n",
    "    print('  ğŸ–¼ï¸ ãƒ†ã‚¹ãƒˆç”»åƒ åˆ¤å®šçµæœ')\n",
    "    print('â•'*75)\n",
    "    print(f'{\"ãƒ•ã‚¡ã‚¤ãƒ«\":<25} {\"SAEã‚¹ã‚³ã‚¢\":>12} {\"SAEåˆ¤å®š\":>8} {\"DAEã‚¹ã‚³ã‚¢\":>12} {\"DAEåˆ¤å®š\":>8}')\n",
    "    print('â”€'*75)\n",
    "    for r in results:\n",
    "        sae_icon = 'âŒ' if r['sae_judge']=='ç•°å¸¸' else 'âœ…'\n",
    "        dae_icon = 'âŒ' if r['dae_judge']=='ç•°å¸¸' else 'âœ…'\n",
    "        print(f'{r[\"name\"]:<25} {r[\"sae_score\"]:>12.6f} {sae_icon} {r[\"sae_judge\"]:>4}'\n",
    "              f' {r[\"dae_score\"]:>12.6f} {dae_icon} {r[\"dae_judge\"]:>4}')\n",
    "    print('â•'*75)\n",
    "\n",
    "    # ä¸ä¸€è‡´ãƒã‚§ãƒƒã‚¯\n",
    "    disagree = [r for r in results if r['sae_judge'] != r['dae_judge']]\n",
    "    if disagree:\n",
    "        print(f'\\nâš ï¸ {len(disagree)}æšã§åˆ¤å®šä¸ä¸€è‡´:')\n",
    "        for r in disagree:\n",
    "            print(f'  ğŸ“Œ {r[\"name\"]}: SAE={r[\"sae_judge\"]} / DAE={r[\"dae_judge\"]}')\n",
    "\n",
    "    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆ2è¡ŒÃ—4åˆ—ï¼‰\n",
    "    n = len(results)\n",
    "    fig, axes = plt.subplots(n * 2, 4, figsize=(18, n * 6))\n",
    "    if n == 1:\n",
    "        axes = axes.reshape(2, 4)\n",
    "\n",
    "    for i, r in enumerate(results):\n",
    "        row_top = i * 2\n",
    "        row_bot = i * 2 + 1\n",
    "\n",
    "        # ä¸Šæ®µ: å…ƒç”»åƒ, å…¥åŠ›(ã‚°ãƒ¬ãƒ¼), SAEå†æ§‹æˆ, DAEå†æ§‹æˆ\n",
    "        panels_top = [\n",
    "            (r['original_rgb'], 'å…ƒç”»åƒ', None),\n",
    "            (r['input'], 'å…¥åŠ›(ã‚°ãƒ¬ãƒ¼)', 'gray'),\n",
    "            (r['sae_recon'], 'SAEå†æ§‹æˆ', 'gray'),\n",
    "            (r['dae_recon'], 'DAEå†æ§‹æˆ', 'gray'),\n",
    "        ]\n",
    "        for j, (p, t, cm) in enumerate(panels_top):\n",
    "            ax = axes[row_top, j] if n > 1 else axes[0, j]\n",
    "            if cm: ax.imshow(p, cmap=cm, vmin=0, vmax=1)\n",
    "            else:  ax.imshow(p)\n",
    "            if i == 0: ax.set_title(t, fontsize=10, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "            if j == 0:\n",
    "                icon = 'ğŸ”´' if 'ç•°å¸¸' in r['sae_judge'] or 'ç•°å¸¸' in r['dae_judge'] else 'ğŸŸ¢'\n",
    "                ax.set_ylabel(f'{icon}{r[\"name\"][:12]}', fontsize=8, rotation=0, labelpad=70, va='center')\n",
    "\n",
    "        # ä¸‹æ®µ: SAEã‚¨ãƒ©ãƒ¼, DAEã‚¨ãƒ©ãƒ¼, SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤, DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤\n",
    "        sae_ov = create_overlay(r['input'], r['sae_error'], alpha=0.55)\n",
    "        dae_ov = create_overlay(r['input'], r['dae_error'], alpha=0.55)\n",
    "        panels_bot = [\n",
    "            (r['sae_error'], 'SAEã‚¨ãƒ©ãƒ¼', True),\n",
    "            (r['dae_error'], 'DAEã‚¨ãƒ©ãƒ¼', True),\n",
    "            (sae_ov, 'SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', False),\n",
    "            (dae_ov, 'DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', False),\n",
    "        ]\n",
    "        bot_titles = ['SAEã‚¨ãƒ©ãƒ¼', 'DAEã‚¨ãƒ©ãƒ¼', 'SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', 'DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤']\n",
    "        for j, (p, t, use_cmap) in enumerate(panels_bot):\n",
    "            ax = axes[row_bot, j] if n > 1 else axes[1, j]\n",
    "            if use_cmap:\n",
    "                vmax = max(p.max(), 0.001)\n",
    "                im = ax.imshow(p, cmap=INSPECTION_CMAP, vmin=0, vmax=vmax)\n",
    "                cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "                cbar.ax.tick_params(labelsize=6)\n",
    "            else:\n",
    "                ax.imshow(p)\n",
    "            if i == 0: ax.set_title(t, fontsize=10, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.suptitle('ãƒ†ã‚¹ãƒˆç”»åƒ ç•°å¸¸æ¤œçŸ¥çµæœ', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(SAVE_DIR / 'test_image_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "print('âœ… ãƒ†ã‚¹ãƒˆç”»åƒæ¨è«–é–¢æ•° å®šç¾©å®Œäº†')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2v1RrfpuOEyF"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# æ–¹æ³•A: åˆæˆãƒ†ã‚¹ãƒˆç”»åƒã§å‹•ä½œç¢ºèª\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# 3Ïƒé–¾å€¤ã‚’è¨ˆç®—\n",
    "sae_threshold = sae_m.get('normal_mean', 0) + 3 * sae_m.get('normal_std', 0.001)\n",
    "dae_threshold = dae_m.get('normal_mean', 0) + 3 * dae_m.get('normal_std', 0.001)\n",
    "print(f'é–¾å€¤: SAE={sae_threshold:.6f}, DAE={dae_threshold:.6f}')\n",
    "\n",
    "# åˆæˆãƒ†ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆ\n",
    "test_pils = []\n",
    "for i in range(3):\n",
    "    arr = generate_normal_image(CONFIG['image_size'], seed=8000+i)\n",
    "    pil = PILImage.fromarray((arr*255).astype(np.uint8), mode='L').convert('RGB')\n",
    "    pil.filename = f'normal_{i+1}.png'\n",
    "    test_pils.append(pil)\n",
    "\n",
    "for i, dt in enumerate(['scratch', 'stain', 'missing', 'discolor']):\n",
    "    base = generate_normal_image(CONFIG['image_size'], seed=9000+i)\n",
    "    defect, _ = add_defect(base, dt, seed=9100+i)\n",
    "    pil = PILImage.fromarray((defect*255).astype(np.uint8), mode='L').convert('RGB')\n",
    "    pil.filename = f'defect_{dt}.png'\n",
    "    test_pils.append(pil)\n",
    "\n",
    "# æ¨è«–å®Ÿè¡Œ\n",
    "results = run_inspection(\n",
    "    test_pils, sae, dae, DEVICE,\n",
    "    image_size=CONFIG['image_size'],\n",
    "    sae_threshold=sae_threshold,\n",
    "    dae_threshold=dae_threshold,\n",
    ")\n",
    "display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zy7xUs1QOEyF"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# æ–¹æ³•B: Colabã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ¤å®š\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# --- Colabã®å ´åˆ: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ€ã‚¤ã‚¢ãƒ­ã‚° ---\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print('ğŸ“ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰')\n",
    "    print('   å¯¾å¿œå½¢å¼: PNG, JPG, BMP, TIFF')\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    if uploaded:\n",
    "        upload_pils = []\n",
    "        for fname, content in uploaded.items():\n",
    "            pil = PILImage.open(io.BytesIO(content)).convert('RGB')\n",
    "            pil.filename = fname\n",
    "            upload_pils.append(pil)\n",
    "            print(f'  âœ… {fname} ({pil.size[0]}x{pil.size[1]})')\n",
    "\n",
    "        results_upload = run_inspection(\n",
    "            upload_pils, sae, dae, DEVICE,\n",
    "            image_size=CONFIG['image_size'],\n",
    "            sae_threshold=sae_threshold,\n",
    "            dae_threshold=dae_threshold,\n",
    "        )\n",
    "        display_results(results_upload)\n",
    "\n",
    "except ImportError:\n",
    "    print('ğŸ’¡ Colabä»¥å¤–ã®ç’°å¢ƒã§ã™ã€‚æ–¹æ³•Cã§ãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®šã—ã¦ãã ã•ã„ã€‚')\n",
    "    print('   ã¾ãŸã¯ä¸Šã®åˆæˆç”»åƒãƒ†ã‚¹ãƒˆï¼ˆæ–¹æ³•Aï¼‰ã‚’ãŠä½¿ã„ãã ã•ã„ã€‚')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrnbOTQcOEyF"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# æ–¹æ³•C: ãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®šã§ä¸€æ‹¬åˆ¤å®š\n",
    "# Windows / Mac / Colab(Drive) å…±é€š\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# --- ãƒ‘ã‚¹ã‚’å¤‰æ›´ã—ã¦ä½¿ç”¨ ---\n",
    "# TEST_IMAGE_DIR = r'C:\\Users\\your_name\\test_images'        # Windows\n",
    "# TEST_IMAGE_DIR = '/Users/your_name/test_images'            # Mac\n",
    "# TEST_IMAGE_DIR = '/content/drive/MyDrive/test_images'      # Colab + Drive\n",
    "\n",
    "TEST_IMAGE_DIR = ''  # â† ã“ã“ã«ãƒ‘ã‚¹ã‚’å…¥åŠ›\n",
    "\n",
    "if TEST_IMAGE_DIR and os.path.isdir(TEST_IMAGE_DIR):\n",
    "    extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tif', '*.tiff']\n",
    "    image_paths = []\n",
    "    for ext in extensions:\n",
    "        image_paths.extend(glob.glob(os.path.join(TEST_IMAGE_DIR, ext)))\n",
    "        image_paths.extend(glob.glob(os.path.join(TEST_IMAGE_DIR, ext.upper())))\n",
    "    image_paths = sorted(set(image_paths))\n",
    "\n",
    "    if image_paths:\n",
    "        print(f'ğŸ“‚ {len(image_paths)}æšã®ç”»åƒã‚’æ¤œå‡º: {TEST_IMAGE_DIR}')\n",
    "        for p in image_paths[:5]:\n",
    "            print(f'  ğŸ“„ {os.path.basename(p)}')\n",
    "        if len(image_paths) > 5:\n",
    "            print(f'  ... ä»–{len(image_paths)-5}æš')\n",
    "\n",
    "        results_folder = run_inspection(\n",
    "            image_paths, sae, dae, DEVICE,\n",
    "            image_size=CONFIG['image_size'],\n",
    "            sae_threshold=sae_threshold,\n",
    "            dae_threshold=dae_threshold,\n",
    "        )\n",
    "        display_results(results_folder)\n",
    "    else:\n",
    "        print(f'âš ï¸ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {TEST_IMAGE_DIR}')\n",
    "else:\n",
    "    print('ğŸ’¡ TEST_IMAGE_DIR ã«ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„')\n",
    "    print('   ä¾‹:')\n",
    "    print('   Windows:  r\"C:\\\\Users\\\\user\\\\test_images\"')\n",
    "    print('   Mac:      \"/Users/user/test_images\"')\n",
    "    print('   Colab:    \"/content/drive/MyDrive/test_images\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzUPILJrOEyF"
   },
   "source": [
    "## 11. ğŸ›ï¸ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–GUIï¼ˆColabå¯¾å¿œï¼‰\n",
    "\n",
    "ãƒœã‚¿ãƒ³æ“ä½œã ã‘ã§ **ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ æ¨è«– â†’ çµæœãƒ¬ãƒ“ãƒ¥ãƒ¼** ã‚’è¡Œãˆã‚‹GUIã§ã™ã€‚\n",
    "\n",
    "> **æ“ä½œæ–¹æ³•**: ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã¨GUIãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚»ã‚¯ã‚·ãƒ§ãƒ³11ã®è§£èª¬: GUIã®æ§‹æˆ\n",
    "\n",
    "#### ipywidgetsã¨ã¯ï¼Ÿ\n",
    "Jupyter Notebook / Google Colabä¸Šã§ã€ãƒœã‚¿ãƒ³ãƒ»ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãªã©ã®\n",
    "ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªUIéƒ¨å“ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚\n",
    "HTMLã¨CSSã‚’ä½¿ã£ãŸã‚¹ã‚¿ã‚¤ãƒ«è¨­å®šã‚‚ã§ãã€Pythonã ã‘ã§ç°¡æ˜“çš„ãªWebã‚¢ãƒ—ãƒªã®ã‚ˆã†ãªä½“é¨“ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚\n",
    "\n",
    "#### GUIã®æ“ä½œæ‰‹é †\n",
    "1. **ç”»åƒã‚’æº–å‚™**: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯åˆæˆãƒ†ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆ\n",
    "2. **é–¾å€¤ã‚’èª¿æ•´**: ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§SAE/DAEãã‚Œãã‚Œã®åˆ¤å®šé–¾å€¤ã‚’è¨­å®š\n",
    "3. **æ¨è«–ã‚’å®Ÿè¡Œ**: ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨å…¨ç”»åƒã‚’ä¸€æ‹¬åˆ¤å®š\n",
    "4. **çµæœã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼**: ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã§å…¨ä½“ã‚’ç¢ºèªã—ã€å€‹åˆ¥ç”»åƒã®è©³ç´°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’é–²è¦§\n",
    "5. **CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ**: åˆ¤å®šçµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "\n",
    "#### ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ©Ÿèƒ½\n",
    "- **ã™ã¹ã¦**: å…¨ç”»åƒã‚’è¡¨ç¤º\n",
    "- **ç•°å¸¸ã®ã¿**: SAEã¾ãŸã¯DAEã§ç•°å¸¸åˆ¤å®šã•ã‚ŒãŸç”»åƒã®ã¿\n",
    "- **æ­£å¸¸ã®ã¿**: ä¸¡ãƒ¢ãƒ‡ãƒ«ã§æ­£å¸¸åˆ¤å®šã•ã‚ŒãŸç”»åƒã®ã¿\n",
    "- **åˆ¤å®šä¸ä¸€è‡´ã®ã¿**: SAEã¨DAEã§åˆ¤å®šãŒåˆ†ã‹ã‚ŒãŸç”»åƒã®ã¿ï¼ˆè¦æ³¨ç›®ã®ã‚±ãƒ¼ã‚¹ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "si63LMIXOEyL"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# GUI ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆipywidgetsï¼‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import io as _io\n",
    "import base64\n",
    "from PIL import Image as PILImage\n",
    "import torchvision.transforms as T_transforms\n",
    "\n",
    "# â”€â”€ çŠ¶æ…‹ç®¡ç† â”€â”€\n",
    "gui_state = {\n",
    "    'images': [],       # [(name, PIL.Image), ...]\n",
    "    'results': [],      # run_inspection ã®å‡ºåŠ›\n",
    "    'current_idx': 0,   # ç¾åœ¨è¡¨ç¤ºä¸­ã®ç”»åƒindex\n",
    "}\n",
    "\n",
    "# â”€â”€ ã‚¹ã‚¿ã‚¤ãƒ«å®šç¾© â”€â”€\n",
    "CSS = HTML('''\n",
    "<style>\n",
    ".gui-header { background: linear-gradient(135deg, #1e3a5f, #0f2027);\n",
    "  color: white; padding: 16px 24px; border-radius: 12px;\n",
    "  font-size: 18px; font-weight: bold; margin-bottom: 12px; }\n",
    ".gui-card { background: #f8f9fa; border: 1px solid #e0e0e0;\n",
    "  border-radius: 8px; padding: 12px; margin: 6px 0; }\n",
    ".gui-ok { color: #10b981; font-weight: bold; font-size: 16px; }\n",
    ".gui-ng { color: #ef4444; font-weight: bold; font-size: 16px; }\n",
    ".gui-warn { color: #f59e0b; font-weight: bold; }\n",
    ".gui-stat { display: inline-block; background: #e2e8f0;\n",
    "  border-radius: 6px; padding: 6px 14px; margin: 4px;\n",
    "  font-family: monospace; font-size: 13px; }\n",
    "</style>\n",
    "''')\n",
    "display(CSS)\n",
    "\n",
    "print('âœ… GUI ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿å®Œäº†')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_77o3vROEyL"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# GUI ãƒ¡ã‚¤ãƒ³\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# â”€â”€ å‡ºåŠ›ã‚¨ãƒªã‚¢ â”€â”€\n",
    "out_upload_status = widgets.Output()\n",
    "out_summary = widgets.Output()\n",
    "out_detail = widgets.Output()\n",
    "out_heatmap = widgets.Output()\n",
    "\n",
    "# â”€â”€ é–¾å€¤ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ â”€â”€\n",
    "sae_thr_default = sae_m.get('normal_mean', 0) + 3 * sae_m.get('normal_std', 0.001)\n",
    "dae_thr_default = dae_m.get('normal_mean', 0) + 3 * dae_m.get('normal_std', 0.001)\n",
    "\n",
    "sae_thr_slider = widgets.FloatSlider(\n",
    "    value=sae_thr_default, min=0.0, max=max(sae_thr_default*5, 0.05),\n",
    "    step=0.0001, description='SAE é–¾å€¤:', readout_format='.5f',\n",
    "    style={'description_width': '80px'}, layout=widgets.Layout(width='450px'),\n",
    ")\n",
    "dae_thr_slider = widgets.FloatSlider(\n",
    "    value=dae_thr_default, min=0.0, max=max(dae_thr_default*5, 0.05),\n",
    "    step=0.0001, description='DAE é–¾å€¤:', readout_format='.5f',\n",
    "    style={'description_width': '80px'}, layout=widgets.Layout(width='450px'),\n",
    ")\n",
    "\n",
    "# â”€â”€ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ â”€â”€\n",
    "file_uploader = widgets.FileUpload(\n",
    "    accept='.png,.jpg,.jpeg,.bmp,.tif,.tiff',\n",
    "    multiple=True,\n",
    "    description='ğŸ“ ç”»åƒã‚’é¸æŠ',\n",
    "    layout=widgets.Layout(width='300px'),\n",
    ")\n",
    "\n",
    "# â”€â”€ ãƒœã‚¿ãƒ³ â”€â”€\n",
    "btn_run = widgets.Button(\n",
    "    description='â–¶ æ¨è«–å®Ÿè¡Œ', icon='play',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='160px', height='40px'),\n",
    ")\n",
    "btn_synthetic = widgets.Button(\n",
    "    description='ğŸ² åˆæˆãƒ†ã‚¹ãƒˆ', icon='random',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='160px', height='40px'),\n",
    ")\n",
    "btn_prev = widgets.Button(\n",
    "    description='â—€ å‰ã¸', layout=widgets.Layout(width='100px'),\n",
    ")\n",
    "btn_next = widgets.Button(\n",
    "    description='æ¬¡ã¸ â–¶', layout=widgets.Layout(width='100px'),\n",
    ")\n",
    "btn_export = widgets.Button(\n",
    "    description='ğŸ’¾ CSVä¿å­˜', icon='download',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='160px', height='40px'),\n",
    ")\n",
    "label_nav = widgets.HTML(value='<b>â”€</b>')\n",
    "\n",
    "# â”€â”€ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ â”€â”€\n",
    "filter_dropdown = widgets.Dropdown(\n",
    "    options=['ã™ã¹ã¦', 'ç•°å¸¸ã®ã¿', 'æ­£å¸¸ã®ã¿', 'åˆ¤å®šä¸ä¸€è‡´ã®ã¿'],\n",
    "    value='ã™ã¹ã¦', description='è¡¨ç¤º:',\n",
    "    style={'description_width': '50px'},\n",
    "    layout=widgets.Layout(width='220px'),\n",
    ")\n",
    "\n",
    "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°\n",
    "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "def load_uploaded_files(change=None):\n",
    "    \"\"\"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆipywidgetsæ–°æ—§ä¸¡å¯¾å¿œï¼‰\"\"\"\n",
    "    gui_state['images'] = []\n",
    "    with out_upload_status:\n",
    "        clear_output()\n",
    "        if not file_uploader.value:\n",
    "            print('ğŸ“ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„')\n",
    "            return\n",
    "\n",
    "        uploaded = file_uploader.value\n",
    "\n",
    "        # ipywidgets >= 8: tuple of FileUploadContent objects\n",
    "        # ipywidgets <  8: dict {filename: {content: bytes, ...}}\n",
    "        if isinstance(uploaded, dict):\n",
    "            items = [(fname, meta['content']) for fname, meta in uploaded.items()]\n",
    "        elif isinstance(uploaded, (list, tuple)):\n",
    "            items = []\n",
    "            for item in uploaded:\n",
    "                if hasattr(item, 'name') and hasattr(item, 'content'):\n",
    "                    items.append((item.name, item.content))\n",
    "                elif isinstance(item, dict):\n",
    "                    items.append((item.get('name', 'unknown'), item.get('content', b'')))\n",
    "                else:\n",
    "                    continue\n",
    "        else:\n",
    "            print(f'âš ï¸ æœªå¯¾å¿œã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å½¢å¼: {type(uploaded)}')\n",
    "            return\n",
    "\n",
    "        for name, content in items:\n",
    "            try:\n",
    "                pil = PILImage.open(_io.BytesIO(content)).convert('RGB')\n",
    "                pil.filename = name\n",
    "                gui_state['images'].append((name, pil))\n",
    "            except Exception as e:\n",
    "                print(f'  âš ï¸ {name}: èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({e})')\n",
    "        print(f'âœ… {len(gui_state[\"images\"])}æšã®ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ')\n",
    "        for n, p in gui_state['images']:\n",
    "            print(f'  ğŸ“„ {n} ({p.size[0]}Ã—{p.size[1]})')\n",
    "\n",
    "file_uploader.observe(load_uploaded_files, names='value')\n",
    "\n",
    "\n",
    "def on_synthetic_click(btn):\n",
    "    \"\"\"åˆæˆãƒ†ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆ\"\"\"\n",
    "    gui_state['images'] = []\n",
    "    with out_upload_status:\n",
    "        clear_output()\n",
    "        print('ğŸ² åˆæˆãƒ†ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆä¸­...')\n",
    "        for i in range(3):\n",
    "            arr = generate_normal_image(CONFIG['image_size'], seed=8000+i)\n",
    "            pil = PILImage.fromarray((arr*255).astype(np.uint8), mode='L').convert('RGB')\n",
    "            pil.filename = f'normal_{i+1}.png'\n",
    "            gui_state['images'].append((f'normal_{i+1}.png', pil))\n",
    "        for i, dt in enumerate(['scratch', 'stain', 'missing', 'discolor']):\n",
    "            base = generate_normal_image(CONFIG['image_size'], seed=9000+i)\n",
    "            defect, _ = add_defect(base, dt, seed=9100+i)\n",
    "            pil = PILImage.fromarray((defect*255).astype(np.uint8), mode='L').convert('RGB')\n",
    "            pil.filename = f'defect_{dt}.png'\n",
    "            gui_state['images'].append((f'defect_{dt}.png', pil))\n",
    "        print(f'âœ… {len(gui_state[\"images\"])}æšç”Ÿæˆï¼ˆæ­£å¸¸3æš + ç•°å¸¸4æšï¼‰')\n",
    "\n",
    "btn_synthetic.on_click(on_synthetic_click)\n",
    "\n",
    "\n",
    "def on_run_click(btn):\n",
    "    \"\"\"æ¨è«–å®Ÿè¡Œ\"\"\"\n",
    "    if not gui_state['images']:\n",
    "        with out_summary:\n",
    "            clear_output()\n",
    "            print('âš ï¸ ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯åˆæˆãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚')\n",
    "        return\n",
    "\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã‚’DEVICEã«åŒæœŸï¼ˆCPU/CUDAä¸ä¸€è‡´é˜²æ­¢ï¼‰\n",
    "    sae.to(DEVICE).eval()\n",
    "    dae.to(DEVICE).eval()\n",
    "\n",
    "    pils = [p for _, p in gui_state['images']]\n",
    "    gui_state['results'] = run_inspection(\n",
    "        pils, sae, dae, DEVICE,\n",
    "        image_size=CONFIG['image_size'],\n",
    "        sae_threshold=sae_thr_slider.value,\n",
    "        dae_threshold=dae_thr_slider.value,\n",
    "    )\n",
    "    gui_state['current_idx'] = 0\n",
    "    update_summary()\n",
    "    update_detail_view()\n",
    "\n",
    "btn_run.on_click(on_run_click)\n",
    "\n",
    "\n",
    "def get_filtered_results():\n",
    "    \"\"\"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨\"\"\"\n",
    "    results = gui_state['results']\n",
    "    f = filter_dropdown.value\n",
    "    if f == 'ç•°å¸¸ã®ã¿':\n",
    "        return [(i,r) for i,r in enumerate(results) if 'ç•°å¸¸' in r['sae_judge'] or 'ç•°å¸¸' in r['dae_judge']]\n",
    "    elif f == 'æ­£å¸¸ã®ã¿':\n",
    "        return [(i,r) for i,r in enumerate(results) if r['sae_judge']=='æ­£å¸¸' and r['dae_judge']=='æ­£å¸¸']\n",
    "    elif f == 'åˆ¤å®šä¸ä¸€è‡´ã®ã¿':\n",
    "        return [(i,r) for i,r in enumerate(results) if r['sae_judge'] != r['dae_judge']]\n",
    "    return list(enumerate(results))\n",
    "\n",
    "\n",
    "def update_summary():\n",
    "    \"\"\"ã‚µãƒãƒªãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–°\"\"\"\n",
    "    with out_summary:\n",
    "        clear_output(wait=True)\n",
    "        results = gui_state['results']\n",
    "        if not results:\n",
    "            return\n",
    "        n = len(results)\n",
    "        n_sae_ng = sum(1 for r in results if 'ç•°å¸¸' in r['sae_judge'])\n",
    "        n_dae_ng = sum(1 for r in results if 'ç•°å¸¸' in r['dae_judge'])\n",
    "        n_disagree = sum(1 for r in results if r['sae_judge'] != r['dae_judge'])\n",
    "\n",
    "        html = '<div class=\"gui-card\">'\n",
    "        html += '<b>ğŸ“Š åˆ¤å®šã‚µãƒãƒªãƒ¼</b><br><br>'\n",
    "        html += f'<span class=\"gui-stat\">æ¤œæŸ»æ•°: <b>{n}</b>æš</span>'\n",
    "        html += f'<span class=\"gui-stat\">SAEç•°å¸¸: <b class=\"gui-ng\">{n_sae_ng}</b>/{n}</span>'\n",
    "        html += f'<span class=\"gui-stat\">DAEç•°å¸¸: <b class=\"gui-ng\">{n_dae_ng}</b>/{n}</span>'\n",
    "        if n_disagree:\n",
    "            html += f'<br><br><span class=\"gui-warn\">âš ï¸ {n_disagree}æšã§åˆ¤å®šä¸ä¸€è‡´</span>'\n",
    "        html += '</div>'\n",
    "\n",
    "        # ãƒ†ãƒ¼ãƒ–ãƒ«\n",
    "        html += '<table style=\"width:100%; border-collapse:collapse; font-size:13px; margin-top:8px;\">'\n",
    "        html += '<tr style=\"background:#334155; color:white;\">'\n",
    "        html += '<th style=\"padding:6px 8px; text-align:left;\">ãƒ•ã‚¡ã‚¤ãƒ«</th>'\n",
    "        html += '<th>SAEã‚¹ã‚³ã‚¢</th><th>SAE</th>'\n",
    "        html += '<th>DAEã‚¹ã‚³ã‚¢</th><th>DAE</th><th></th></tr>'\n",
    "        for i, r in enumerate(results):\n",
    "            bg = '#fff5f5' if ('ç•°å¸¸' in r['sae_judge'] or 'ç•°å¸¸' in r['dae_judge']) else '#f0fdf4'\n",
    "            sae_cls = 'gui-ng' if 'ç•°å¸¸' in r['sae_judge'] else 'gui-ok'\n",
    "            dae_cls = 'gui-ng' if 'ç•°å¸¸' in r['dae_judge'] else 'gui-ok'\n",
    "            warn = ' âš ï¸' if r['sae_judge'] != r['dae_judge'] else ''\n",
    "            html += f'<tr style=\"background:{bg}; border-bottom:1px solid #e2e8f0;\">'\n",
    "            html += f'<td style=\"padding:5px 8px;\">{r[\"name\"]}</td>'\n",
    "            html += f'<td style=\"text-align:center; font-family:monospace;\">{r[\"sae_score\"]:.6f}</td>'\n",
    "            html += f'<td style=\"text-align:center;\"><span class=\"{sae_cls}\">{r[\"sae_judge\"]}</span></td>'\n",
    "            html += f'<td style=\"text-align:center; font-family:monospace;\">{r[\"dae_score\"]:.6f}</td>'\n",
    "            html += f'<td style=\"text-align:center;\"><span class=\"{dae_cls}\">{r[\"dae_judge\"]}</span>{warn}</td>'\n",
    "            html += f'<td style=\"text-align:center;\">#{i+1}</td></tr>'\n",
    "        html += '</table>'\n",
    "        display(HTML(html))\n",
    "\n",
    "\n",
    "def update_detail_view():\n",
    "    \"\"\"å€‹åˆ¥ç”»åƒã®è©³ç´°ãƒ“ãƒ¥ãƒ¼æ›´æ–°\"\"\"\n",
    "    filtered = get_filtered_results()\n",
    "    if not filtered:\n",
    "        with out_detail:\n",
    "            clear_output()\n",
    "            print('è©²å½“ã™ã‚‹ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“')\n",
    "        return\n",
    "\n",
    "    idx = gui_state['current_idx'] % len(filtered)\n",
    "    orig_i, r = filtered[idx]\n",
    "    label_nav.value = f'<b>{idx+1} / {len(filtered)}</b>'\n",
    "\n",
    "    with out_detail:\n",
    "        clear_output(wait=True)\n",
    "        sae_cls = 'gui-ng' if 'ç•°å¸¸' in r['sae_judge'] else 'gui-ok'\n",
    "        dae_cls = 'gui-ng' if 'ç•°å¸¸' in r['dae_judge'] else 'gui-ok'\n",
    "        html = f'<div class=\"gui-card\">'\n",
    "        html += f'<b>ğŸ“„ {r[\"name\"]}</b> (#{orig_i+1})<br><br>'\n",
    "        html += f'<span class=\"gui-stat\">SAE: <span class=\"{sae_cls}\">{r[\"sae_judge\"]}</span> ({r[\"sae_score\"]:.6f})</span> '\n",
    "        html += f'<span class=\"gui-stat\">DAE: <span class=\"{dae_cls}\">{r[\"dae_judge\"]}</span> ({r[\"dae_score\"]:.6f})</span>'\n",
    "        if r['sae_judge'] != r['dae_judge']:\n",
    "            html += '<br><span class=\"gui-warn\">âš ï¸ ãƒ¢ãƒ‡ãƒ«é–“ã§åˆ¤å®šä¸ä¸€è‡´</span>'\n",
    "        html += '</div>'\n",
    "        display(HTML(html))\n",
    "\n",
    "    with out_heatmap:\n",
    "        clear_output(wait=True)\n",
    "        # Replaced by 2x4 layout below\n",
    "        # ä¸Šæ®µ: å…ƒç”»åƒ, å…¥åŠ›, SAEå†æ§‹æˆ, DAEå†æ§‹æˆ\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(18, 7))\n",
    "        top_panels = [\n",
    "            (r.get('original_rgb', r['input']), 'å…ƒç”»åƒ', None),\n",
    "            (r['input'], 'å…¥åŠ›(ã‚°ãƒ¬ãƒ¼)', 'gray'),\n",
    "            (r['sae_recon'], 'SAEå†æ§‹æˆ', 'gray'),\n",
    "            (r['dae_recon'], 'DAEå†æ§‹æˆ', 'gray'),\n",
    "        ]\n",
    "        for j, (p, t, cm) in enumerate(top_panels):\n",
    "            ax = axes[0, j]\n",
    "            if cm: ax.imshow(p, cmap=cm, vmin=0, vmax=1)\n",
    "            else:  ax.imshow(p)\n",
    "            ax.set_title(t, fontsize=10, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "\n",
    "        # ä¸‹æ®µ: SAEã‚¨ãƒ©ãƒ¼, DAEã‚¨ãƒ©ãƒ¼, SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤, DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤\n",
    "        sae_ov = create_overlay(r['input'], r['sae_error'], alpha=0.55)\n",
    "        dae_ov = create_overlay(r['input'], r['dae_error'], alpha=0.55)\n",
    "        bot_panels = [\n",
    "            (r['sae_error'], 'SAEã‚¨ãƒ©ãƒ¼', True),\n",
    "            (r['dae_error'], 'DAEã‚¨ãƒ©ãƒ¼', True),\n",
    "            (sae_ov, 'SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', False),\n",
    "            (dae_ov, 'DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', False),\n",
    "        ]\n",
    "        for j, (p, t, use_cmap) in enumerate(bot_panels):\n",
    "            ax = axes[1, j]\n",
    "            if use_cmap:\n",
    "                vmax = max(p.max(), 0.001)\n",
    "                im = ax.imshow(p, cmap=INSPECTION_CMAP, vmin=0, vmax=vmax)\n",
    "                cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "                cbar.ax.tick_params(labelsize=6)\n",
    "            else:\n",
    "                ax.imshow(p)\n",
    "            ax.set_title(t, fontsize=10, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def on_prev(btn):\n",
    "    filtered = get_filtered_results()\n",
    "    if filtered:\n",
    "        gui_state['current_idx'] = (gui_state['current_idx'] - 1) % len(filtered)\n",
    "        update_detail_view()\n",
    "\n",
    "def on_next(btn):\n",
    "    filtered = get_filtered_results()\n",
    "    if filtered:\n",
    "        gui_state['current_idx'] = (gui_state['current_idx'] + 1) % len(filtered)\n",
    "        update_detail_view()\n",
    "\n",
    "btn_prev.on_click(on_prev)\n",
    "btn_next.on_click(on_next)\n",
    "\n",
    "\n",
    "def on_filter_change(change):\n",
    "    gui_state['current_idx'] = 0\n",
    "    update_detail_view()\n",
    "\n",
    "filter_dropdown.observe(on_filter_change, names='value')\n",
    "\n",
    "\n",
    "def on_export_csv(btn):\n",
    "    \"\"\"çµæœã‚’CSVã§ä¿å­˜\"\"\"\n",
    "    if not gui_state['results']:\n",
    "        return\n",
    "    import csv\n",
    "    csv_path = SAVE_DIR / 'test_results.csv'\n",
    "    with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(['ãƒ•ã‚¡ã‚¤ãƒ«å','SAEã‚¹ã‚³ã‚¢','SAEåˆ¤å®š','DAEã‚¹ã‚³ã‚¢','DAEåˆ¤å®š','ä¸ä¸€è‡´'])\n",
    "        for r in gui_state['results']:\n",
    "            w.writerow([\n",
    "                r['name'], f'{r[\"sae_score\"]:.6f}', r['sae_judge'],\n",
    "                f'{r[\"dae_score\"]:.6f}', r['dae_judge'],\n",
    "                'âš ' if r['sae_judge']!=r['dae_judge'] else '',\n",
    "            ])\n",
    "    with out_upload_status:\n",
    "        print(f'\\nğŸ’¾ CSVä¿å­˜å®Œäº†: {csv_path}')\n",
    "    # Colabè‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "    try:\n",
    "        from google.colab import files as colab_files\n",
    "        colab_files.download(str(csv_path))\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "btn_export.on_click(on_export_csv)\n",
    "\n",
    "\n",
    "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "# GUIãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆçµ„ã¿ç«‹ã¦\n",
    "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "header = widgets.HTML('<div class=\"gui-header\">ğŸ”¬ å¤–è¦³æ¤œæŸ»AI â€” ãƒ†ã‚¹ãƒˆç”»åƒãƒ¬ãƒ“ãƒ¥ãƒ¼</div>')\n",
    "\n",
    "upload_section = widgets.VBox([\n",
    "    widgets.HTML('<b>â‘  ç”»åƒã‚’æº–å‚™</b>'),\n",
    "    widgets.HBox([file_uploader, btn_synthetic]),\n",
    "    out_upload_status,\n",
    "])\n",
    "\n",
    "threshold_section = widgets.VBox([\n",
    "    widgets.HTML('<b>â‘¡ é–¾å€¤è¨­å®š</b>'),\n",
    "    sae_thr_slider,\n",
    "    dae_thr_slider,\n",
    "    widgets.HBox([btn_run, btn_export]),\n",
    "])\n",
    "\n",
    "nav_section = widgets.HBox(\n",
    "    [btn_prev, label_nav, btn_next, filter_dropdown],\n",
    "    layout=widgets.Layout(align_items='center', gap='12px'),\n",
    ")\n",
    "\n",
    "review_section = widgets.VBox([\n",
    "    widgets.HTML('<b>â‘¢ çµæœãƒ¬ãƒ“ãƒ¥ãƒ¼</b>'),\n",
    "    out_summary,\n",
    "    widgets.HTML('<hr>'),\n",
    "    widgets.HTML('<b>â‘£ å€‹åˆ¥ç”»åƒè©³ç´°</b>'),\n",
    "    nav_section,\n",
    "    out_detail,\n",
    "    out_heatmap,\n",
    "])\n",
    "\n",
    "gui = widgets.VBox([\n",
    "    header,\n",
    "    upload_section,\n",
    "    widgets.HTML('<hr>'),\n",
    "    threshold_section,\n",
    "    widgets.HTML('<hr>'),\n",
    "    review_section,\n",
    "], layout=widgets.Layout(max_width='900px'))\n",
    "\n",
    "display(gui)\n",
    "print('\\nğŸ’¡ æ“ä½œæ‰‹é †: â‘ ç”»åƒã‚’é¸æŠ â†’ â‘¡é–¾å€¤ã‚’èª¿æ•´ â†’ â–¶æ¨è«–å®Ÿè¡Œ â†’ â‘¢çµæœã‚’ç¢ºèª â†’ â—€â–¶ã§ç”»åƒã‚’åˆ‡æ›¿')"
   ]
  }
 ]
}