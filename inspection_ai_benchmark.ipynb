{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/biz-HK/inspection_ai_benchmark.ipynb/blob/main/inspection_ai_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xogUH5NUOEx9"
   },
   "source": [
    "# ğŸ”¬ å¤–è¦³æ¤œæŸ»AI ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯\n",
    "## Sparse Autoencoder vs Deep Autoencoder æ¯”è¼ƒæ¤œè¨¼\n",
    "\n",
    "| é …ç›® | å†…å®¹ |\n",
    "|------|------|\n",
    "| **ç›®çš„** | ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®ç•°å¸¸æ¤œçŸ¥æ€§èƒ½ã‚’åŒä¸€æ¡ä»¶ã§æ¯”è¼ƒ |\n",
    "| **ç’°å¢ƒ** | Google Colab (T4 GPU) / Windows (CPU/CUDA) / Mac (MPS) |\n",
    "| **ãƒ‡ãƒ¼ã‚¿** | åˆæˆãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿å·®ã—æ›¿ãˆå¯èƒ½ï¼‰ |\n",
    "| **è©•ä¾¡æŒ‡æ¨™** | AUC-ROC, F1, FPR@95TPR, æ¨è«–é€Ÿåº¦, ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º |\n",
    "\n",
    "---\n",
    "### å®Ÿè¡Œæ‰‹é †\n",
    "1. ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€â†’ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ã€â†’ **T4 GPU** ã‚’é¸æŠ\n",
    "2. ä¸Šã‹ã‚‰é †ã«ã‚»ãƒ«ã‚’å®Ÿè¡Œï¼ˆ`Shift+Enter`ï¼‰\n",
    "3. çµæœã¯è‡ªå‹•çš„ã«Google Driveã«ä¿å­˜ã•ã‚Œã¾ã™"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## åˆç´šãƒ»ä¸­ç´šå‘ã‘è§£èª¬: ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ä½•ã‚’ã—ã¦ã„ã‚‹ã®ã‹\n\n---\n\n### èƒŒæ™¯: å¤–è¦³æ¤œæŸ»AIã¨ã¯\n\nè£½é€ æ¥­ã®å·¥å ´ã§ã¯ã€è£½å“ã«**ã‚­ã‚ºãƒ»æ±šã‚Œãƒ»æ¬ ã‘ãƒ»å¤‰è‰²**ãŒãªã„ã‹ã‚’æ¤œæŸ»ã™ã‚‹å·¥ç¨‹ï¼ˆå¤–è¦³æ¤œæŸ»ï¼‰ãŒã‚ã‚Šã¾ã™ã€‚å¾“æ¥ã¯äººé–“ã®ç›®ã§è¡Œã£ã¦ã„ã¾ã—ãŸãŒã€AIã‚’ä½¿ã£ã¦è‡ªå‹•åŒ–ã™ã‚‹å‹•ããŒåºƒãŒã£ã¦ã„ã¾ã™ã€‚\n\nã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€å¤–è¦³æ¤œæŸ»AIã®ä»£è¡¨çš„ãªæ‰‹æ³•ã§ã‚ã‚‹ **Autoencoderï¼ˆã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼‰** ã‚’2ç¨®é¡æ¯”è¼ƒã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã™ã€‚\n\n---\n\n### æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢: ã€Œæ­£å¸¸ã ã‘è¦šãˆã¦ã€çŸ¥ã‚‰ãªã„ã‚‚ã®ã‚’ç•°å¸¸ã¨ã¿ãªã™ã€\n\nå¤–è¦³æ¤œæŸ»AIã¯**æ•™å¸«ãªã—ç•°å¸¸æ¤œçŸ¥**ã¨ã„ã†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å–ã‚Šã¾ã™ã€‚\n\n```\nå­¦ç¿’æ™‚: æ­£å¸¸å“ã®ç”»åƒã ã‘ã‚’å¤§é‡ã«å­¦ç¿’ã•ã›ã‚‹\næ¨è«–æ™‚: å…¥åŠ›ç”»åƒã‚’å¾©å…ƒã—ã€å¾©å…ƒãŒã†ã¾ãã„ã‹ãªã„éƒ¨åˆ† = ç•°å¸¸ç®‡æ‰€ã¨åˆ¤å®š\n```\n\n**Autoencoderï¼ˆAEï¼‰** ã¯ã€Œç”»åƒã‚’åœ§ç¸®â†’å¾©å…ƒã€ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚æ­£å¸¸å“ã ã‘ã§å­¦ç¿’ã™ã‚‹ãŸã‚ã€ç•°å¸¸å“ã‚’å…¥åŠ›ã™ã‚‹ã¨å¾©å…ƒç²¾åº¦ãŒè½ã¡ã€ãã®**å¾©å…ƒèª¤å·®ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰ãŒå¤§ãã„ç®‡æ‰€ = ç•°å¸¸ç®‡æ‰€**ã¨ã—ã¦æ¤œå‡ºã§ãã¾ã™ã€‚\n\n```\nå…¥åŠ›ç”»åƒ â†’ [ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€: åœ§ç¸®] â†’ æ½œåœ¨è¡¨ç¾(z) â†’ [ãƒ‡ã‚³ãƒ¼ãƒ€: å¾©å…ƒ] â†’ å¾©å…ƒç”»åƒ\n                                  â†‘\n                          ã“ã®æƒ…å ±ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãŒéµ\n```\n\n---\n\n### æ¯”è¼ƒã™ã‚‹2ã¤ã®ãƒ¢ãƒ‡ãƒ«\n\n| | Sparse Autoencoder (SAE) | Deep Autoencoder (DAE) |\n|---|---|---|\n| **æ§‹é€ ** | Conv 2å±¤ + L1æ­£å‰‡åŒ– | Conv 4å±¤ + SSIMæå¤± |\n| **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°** | å°‘ãªã„ï¼ˆè»½é‡ï¼‰ | å¤šã„ï¼ˆSAEã®10å€ä»¥ä¸Šï¼‰ |\n| **ç‰¹å¾´** | å°‘æ•°ã®é‡è¦ãªç‰¹å¾´ã ã‘ã«é›†ä¸­ | å¤šãã®ç‰¹å¾´ã‚’ç´°ã‹ãæ‰ãˆã‚‹ |\n| **å‘ã„ã¦ã„ã‚‹å ´é¢** | ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  | é«˜ç²¾åº¦ãŒå¿…è¦ãªãƒ©ã‚¤ãƒ³ |\n| **æ½œåœ¨æ¬¡å…ƒ** | 64æ¬¡å…ƒ | 128æ¬¡å…ƒ |\n\n#### Sparseï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹ï¼‰ã¨ã¯ï¼Ÿ\nL1æ­£å‰‡åŒ–ã¨ã„ã†ä»•çµ„ã¿ã§ã€æ½œåœ¨è¡¨ç¾ã®**å¤§éƒ¨åˆ†ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’0ã«è¿‘ã¥ã‘**ã€å°‘æ•°ã®é‡è¦ãªç‰¹å¾´ã ã‘ã‚’ä½¿ã†ã‚ˆã†å¼·åˆ¶ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šï¼š\n- ãƒ¢ãƒ‡ãƒ«ãŒè»½é‡ã«ãªã‚‹\n- éå­¦ç¿’ã—ã«ãããªã‚‹\n- è§£é‡ˆã—ã‚„ã™ããªã‚‹ï¼ˆã©ã®ç‰¹å¾´ãŒé‡è¦ã‹åˆ†ã‹ã‚‹ï¼‰\n\n#### Deepï¼ˆãƒ‡ã‚£ãƒ¼ãƒ—ï¼‰ã¨ã¯ï¼Ÿ\nConvå±¤ã‚’4æ®µé‡ã­ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šè¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‰ã‚Œã¾ã™ã€‚åŠ ãˆã¦**SSIMæå¤±**ï¼ˆç”»åƒã®æ§‹é€ çš„ãªé¡ä¼¼åº¦ï¼‰ã‚’ä½¿ã†ã“ã¨ã§ã€äººé–“ã®è¦–è¦šã«è¿‘ã„å¾©å…ƒå“è³ªã‚’è¿½æ±‚ã—ã¾ã™ã€‚\n\n---\n\n### è©•ä¾¡æŒ‡æ¨™ã®èª­ã¿æ–¹\n\n| æŒ‡æ¨™ | æ„å‘³ | è‰¯ã„å€¤ |\n|------|------|--------|\n| **AUC-ROC** | æ­£å¸¸/ç•°å¸¸ã®åˆ†é›¢èƒ½åŠ›ï¼ˆ1.0ãŒå®Œç’§ï¼‰ | é«˜ã„ã»ã©è‰¯ã„ |\n| **Best F1** | é©åˆç‡ã¨å†ç¾ç‡ã®ãƒãƒ©ãƒ³ã‚¹ï¼ˆæœ€é©é–¾å€¤æ™‚ï¼‰ | é«˜ã„ã»ã©è‰¯ã„ |\n| **F1 (3Ïƒé–¾å€¤)** | çµ±è¨ˆçš„ãªé–¾å€¤ï¼ˆå¹³å‡+3æ¨™æº–åå·®ï¼‰ã§ã®F1 | é«˜ã„ã»ã©è‰¯ã„ |\n| **FPR@95TPR** | ç•°å¸¸å“ã®95%ã‚’æ¤œå‡ºã—ãŸæ™‚ã®èª¤æ¤œå‡ºç‡ | ä½ã„ã»ã©è‰¯ã„ |\n| **æ¨è«–é€Ÿåº¦** | 1æšã‚ãŸã‚Šã®å‡¦ç†æ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰ | ä½ã„ã»ã©è‰¯ã„ |\n| **ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º** | ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆMBï¼‰ | ä½ã„ã»ã©è‰¯ã„ |\n\n> **åˆå¿ƒè€…å‘ã‘ãƒã‚¤ãƒ³ãƒˆ**: ã¾ãš **AUC-ROC** ã‚’è¦‹ã¦ãã ã•ã„ã€‚0.9ä»¥ä¸Šãªã‚‰ã€Œã‹ãªã‚Šè‰¯ã„ã€ã€0.95ä»¥ä¸Šãªã‚‰ã€Œå„ªç§€ã€ã§ã™ã€‚æ¬¡ã«**æ¨è«–é€Ÿåº¦**ã‚’è¦‹ã¦ã€å®Ÿç”¨çš„ãªé€Ÿã•ã‹ã©ã†ã‹åˆ¤æ–­ã—ã¾ã™ã€‚\n\n---\n\n### ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®å…¨ä½“ãƒ•ãƒ­ãƒ¼\n\n```\nã‚»ã‚¯ã‚·ãƒ§ãƒ³0: ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆGPUæ¤œå‡ºã€æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆç­‰ï¼‰\n    â†“\nã‚»ã‚¯ã‚·ãƒ§ãƒ³1: ãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆSAEã¨DAEã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ï¼‰\n    â†“\nã‚»ã‚¯ã‚·ãƒ§ãƒ³2: åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆæ­£å¸¸å“ + 4ç¨®é¡ã®æ¬ é™¥ç”»åƒï¼‰\n    â†“\nã‚»ã‚¯ã‚·ãƒ§ãƒ³3: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆã‚¨ãƒãƒƒã‚¯æ•°ã€å­¦ç¿’ç‡ãªã©ï¼‰\n    â†“\nã‚»ã‚¯ã‚·ãƒ§ãƒ³4: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆDataLoaderä½œæˆï¼‰\n    â†“\nã‚»ã‚¯ã‚·ãƒ§ãƒ³5: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆæ­£å¸¸å“ã®ã¿ã§å­¦ç¿’ï¼‰\n    â†“\nã‚»ã‚¯ã‚·ãƒ§ãƒ³6: å®šé‡è©•ä¾¡ï¼ˆAUC-ROC, F1ãªã©ã®æ•°å€¤æ¯”è¼ƒï¼‰\n    â†“\nã‚»ã‚¯ã‚·ãƒ§ãƒ³7: ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–ï¼ˆç•°å¸¸ç®‡æ‰€ã®è¦–è¦šçš„ãªç¢ºèªï¼‰\n    â†“\nã‚»ã‚¯ã‚·ãƒ§ãƒ³8: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ & ONNXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n    â†“\nã‚»ã‚¯ã‚·ãƒ§ãƒ³9: å®Ÿãƒ‡ãƒ¼ã‚¿ã¸ã®åˆ‡ã‚Šæ›¿ãˆæ–¹æ³•\n    â†“\nã‚»ã‚¯ã‚·ãƒ§ãƒ³10-11: ãƒ†ã‚¹ãƒˆç”»åƒã®èª­ã¿è¾¼ã¿ & ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–GUI\n```\n\n---\n\n### åˆæˆãƒ‡ãƒ¼ã‚¿ã®4ç¨®é¡ã®æ¬ é™¥\n\n| æ¬ é™¥ã‚¿ã‚¤ãƒ— | èª¬æ˜ | å®Ÿéš›ã®è£½é€ ä¾‹ |\n|-----------|------|-------------|\n| **scratch** | ç·šçŠ¶ã®ã‚­ã‚º | é‡‘å±è¡¨é¢ã®å¼•ã£ã‹ãå‚· |\n| **stain** | ã‚¬ã‚¦ã‚·ã‚¢ãƒ³çŠ¶ã®æ±šã‚Œ | æ¶²ã ã‚Œã€æŒ‡ç´‹ |\n| **missing** | å††å½¢ã®æ¬ æ | ç©´ã€æ¬ ã‘ |\n| **discolor** | çŸ©å½¢ã®å¤‰è‰² | ç„¼ã‘ã€é…¸åŒ–ãƒ ãƒ© |\n\n> **æ³¨æ„**: ã“ã‚Œã‚‰ã¯åˆæˆï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ç”Ÿæˆã—ãŸï¼‰ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚å®Ÿéš›ã®è£½å“ç”»åƒã«å·®ã—æ›¿ãˆã¦ä½¿ãˆã‚‹ã‚ˆã†ã«ã‚»ã‚¯ã‚·ãƒ§ãƒ³9ã«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Cwws86YOEx-"
   },
   "source": [
    "## 0. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zf4199AAOEx_"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆColabã«ãƒ—ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã®ã‚‚ã®ãŒå¤šã„ï¼‰â”€â”€\n",
    "!pip install -q scikit-learn matplotlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from typing import Tuple, Dict, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# â”€â”€ ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•æ¤œå‡º â”€â”€\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print(f'âœ… GPU: {torch.cuda.get_device_name(0)}')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "    print('âœ… Apple Silicon MPS')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print('âš ï¸ CPU modeï¼ˆGPUãªã—ï¼‰')\n",
    "\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'Device: {DEVICE}')\n",
    "\n",
    "# â”€â”€ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè‡ªå‹•è¨­å®š â”€â”€\n",
    "import matplotlib.font_manager as fm\n",
    "import platform as _pf\n",
    "\n",
    "def setup_japanese_font():\n",
    "    _sys = _pf.system()\n",
    "    candidates = {\n",
    "        'Windows': ['Yu Gothic', 'MS Gothic', 'Meiryo', 'BIZ UDGothic'],\n",
    "        'Darwin':  ['Hiragino Sans', 'Hiragino Kaku Gothic Pro'],\n",
    "    }.get(_sys, ['Noto Sans CJK JP', 'IPAGothic', 'TakaoPGothic'])\n",
    "    available = {f.name for f in fm.fontManager.ttflist}\n",
    "    for fn in candidates:\n",
    "        if fn in available:\n",
    "            matplotlib.rcParams['font.family'] = fn\n",
    "            break\n",
    "    else:\n",
    "        if _sys == 'Linux':\n",
    "            os.system('apt-get install -y fonts-ipafont-gothic > /dev/null 2>&1')\n",
    "            try:\n",
    "                fm.fontManager.addfont('/usr/share/fonts/opentype/ipafont-gothic/ipag.ttf')\n",
    "                matplotlib.rcParams['font.family'] = 'IPAGothic'\n",
    "            except: pass\n",
    "        matplotlib.rcParams['font.sans-serif'] = candidates + ['DejaVu Sans']\n",
    "    matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "setup_japanese_font()\n",
    "\n",
    "# â”€â”€ ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ï¼ˆé’â†’é»„â†’èµ¤ï¼‰â”€â”€\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "INSPECTION_CMAP = LinearSegmentedColormap.from_list(\n",
    "    'inspection_heatmap',\n",
    "    [(0.0, '#1a237e'), (0.15, '#1565c0'), (0.35, '#00bcd4'),\n",
    "     (0.50, '#ffeb3b'), (0.70, '#ff9800'), (0.85, '#f44336'),\n",
    "     (1.0, '#b71c1c')],\n",
    "    N=256,\n",
    ")\n",
    "\n",
    "def create_overlay(base_img, error_map, alpha=0.5, cmap=None):\n",
    "    \"\"\"å…ƒç”»åƒã«ã‚¨ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤åˆæˆ\"\"\"\n",
    "    if cmap is None: cmap = INSPECTION_CMAP\n",
    "    if base_img.ndim == 2:\n",
    "        base_rgb = np.stack([base_img]*3, axis=-1)\n",
    "    else:\n",
    "        base_rgb = base_img[:, :, :3]\n",
    "    emax = error_map.max()\n",
    "    error_norm = error_map / emax if emax > 0 else error_map\n",
    "    heat_rgba = cmap(error_norm)[:, :, :3]\n",
    "    return np.clip(base_rgb * (1-alpha) + heat_rgba * alpha, 0, 1)\n",
    "\n",
    "print('âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ + ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—è¨­å®šå®Œäº†')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_jBKUWErOEx_"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ Google Drive ãƒã‚¦ãƒ³ãƒˆï¼ˆçµæœä¿å­˜ç”¨ãƒ»ä»»æ„ï¼‰â”€â”€\n",
    "SAVE_TO_DRIVE = True  # Falseã«ã™ã‚‹ã¨ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ã®ã¿\n",
    "\n",
    "if SAVE_TO_DRIVE:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        SAVE_DIR = Path('/content/drive/MyDrive/inspection_ai_results')\n",
    "        SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'âœ… ä¿å­˜å…ˆ: {SAVE_DIR}')\n",
    "    except ImportError:\n",
    "        # Windows/Mac ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚\n",
    "        SAVE_DIR = Path('./results')\n",
    "        SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'âœ… ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜: {SAVE_DIR}')\n",
    "else:\n",
    "    SAVE_DIR = Path('./results')\n",
    "    SAVE_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpZiaRJtOEx_"
   },
   "source": [
    "## 1. ãƒ¢ãƒ‡ãƒ«å®šç¾©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6oiPXMDOEyA"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Sparse Autoencoder (SAE)\n",
    "# L1æ­£å‰‡åŒ–ã§æ½œåœ¨ç©ºé–“ã‚’ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Sparse Autoencoder\n",
    "    - è»½é‡ãª2å±¤Convæ§‹æˆ\n",
    "    - L1æ­£å‰‡åŒ–ã§å°‘æ•°ã®ç‰¹å¾´é‡ã«é›†ä¸­\n",
    "    - ã‚¨ãƒƒã‚¸å±•é–‹ã«é©ã—ãŸå°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(True),\n",
    "        )\n",
    "        self.fc_encode = nn.Linear(64 * 32 * 32, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, 64 * 32 * 32)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, in_channels, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_encode(h.view(h.size(0), -1))\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.fc_decode(z).view(z.size(0), 64, 32, 32)\n",
    "        return self.decoder(h)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z), z\n",
    "\n",
    "\n",
    "class SparseAELoss(nn.Module):\n",
    "    \"\"\"MSE + L1ã‚¹ãƒ‘ãƒ¼ã‚¹æ­£å‰‡åŒ–\"\"\"\n",
    "    def __init__(self, l1_weight=1e-3):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.l1_weight = l1_weight\n",
    "\n",
    "    def forward(self, x, x_recon, z):\n",
    "        recon = self.mse(x_recon, x)\n",
    "        sparse = self.l1_weight * torch.mean(torch.abs(z))\n",
    "        return recon + sparse, {'recon': recon.item(), 'sparse': sparse.item()}\n",
    "\n",
    "\n",
    "print('âœ… Sparse Autoencoder å®šç¾©å®Œäº†')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOhP-2LfOEyA"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Deep Autoencoder (DAE)\n",
    "# å¤šå±¤Conv + SSIMæå¤±ã«ã‚ˆã‚‹é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class DeepAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Autoencoder\n",
    "    - 4å±¤Convæ§‹æˆ\n",
    "    - é«˜ã„è¡¨ç¾åŠ›ã§å¾®ç´°ãªç•°å¸¸ã‚‚æ¤œå‡º\n",
    "    - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯SAEã®10å€ä»¥ä¸Š\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1, latent_dim=128):\n",
    "        super().__init__()\n",
    "        self.enc1 = self._conv(in_channels, 32)\n",
    "        self.enc2 = self._conv(32, 64)\n",
    "        self.enc3 = self._conv(64, 128)\n",
    "        self.enc4 = self._conv(128, 256)\n",
    "        self.fc_encode = nn.Linear(256 * 8 * 8, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, 256 * 8 * 8)\n",
    "        self.dec4 = self._deconv(256, 128)\n",
    "        self.dec3 = self._deconv(128, 64)\n",
    "        self.dec2 = self._deconv(64, 32)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, in_channels, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _conv(inc, outc):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(inc, outc, 4, 2, 1), nn.BatchNorm2d(outc), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(outc, outc, 3, 1, 1), nn.BatchNorm2d(outc), nn.LeakyReLU(0.2, True),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _deconv(inc, outc):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(inc, outc, 4, 2, 1), nn.BatchNorm2d(outc), nn.ReLU(True),\n",
    "            nn.Conv2d(outc, outc, 3, 1, 1), nn.BatchNorm2d(outc), nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.enc4(self.enc3(self.enc2(self.enc1(x))))\n",
    "        return self.fc_encode(h.view(h.size(0), -1))\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.fc_decode(z).view(z.size(0), 256, 8, 8)\n",
    "        return self.dec1(self.dec2(self.dec3(self.dec4(h))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z), z\n",
    "\n",
    "\n",
    "class DeepAELoss(nn.Module):\n",
    "    \"\"\"MSE + ç°¡æ˜“SSIMæ§‹é€ æå¤±\"\"\"\n",
    "    def __init__(self, ssim_weight=0.1):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.ssim_weight = ssim_weight\n",
    "\n",
    "    def _ssim_approx(self, x, y, ws=11):\n",
    "        C1, C2 = 0.01**2, 0.03**2\n",
    "        pad = ws // 2\n",
    "        mu_x = nn.functional.avg_pool2d(x, ws, 1, pad)\n",
    "        mu_y = nn.functional.avg_pool2d(y, ws, 1, pad)\n",
    "        s_x = nn.functional.avg_pool2d(x**2, ws, 1, pad) - mu_x**2\n",
    "        s_y = nn.functional.avg_pool2d(y**2, ws, 1, pad) - mu_y**2\n",
    "        s_xy = nn.functional.avg_pool2d(x*y, ws, 1, pad) - mu_x*mu_y\n",
    "        return ((2*mu_x*mu_y+C1)*(2*s_xy+C2) / ((mu_x**2+mu_y**2+C1)*(s_x+s_y+C2))).mean()\n",
    "\n",
    "    def forward(self, x, x_recon, z=None):\n",
    "        recon = self.mse(x_recon, x)\n",
    "        ssim = 1.0 - self._ssim_approx(x, x_recon)\n",
    "        return recon + self.ssim_weight * ssim, {'recon': recon.item(), 'ssim': ssim.item()}\n",
    "\n",
    "\n",
    "print('âœ… Deep Autoencoder å®šç¾©å®Œäº†')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWzO5sCTOEyA"
   },
   "source": [
    "## 2. åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8VUfll6EOEyB"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# åˆæˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "# æ­£å¸¸å“ + 4ç¨®é¡ã®æ¬ é™¥ï¼ˆscratch/stain/missing/discolorï¼‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def generate_normal_image(size=128, seed=None):\n",
    "    \"\"\"æ­£å¸¸å“ç”»åƒï¼ˆå‡ä¸€ãƒ†ã‚¯ã‚¹ãƒãƒ£ + æ ¼å­ãƒ‘ã‚¿ãƒ¼ãƒ³ + å††å½¢ç‰¹å¾´ï¼‰\"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    img = np.ones((size, size), dtype=np.float32) * 0.6\n",
    "    img += np.random.normal(0, 0.02, (size, size)).astype(np.float32)\n",
    "    for i in range(0, size, 16):\n",
    "        img[i:i+1, :] += 0.05\n",
    "        img[:, i:i+1] += 0.05\n",
    "    y, x = np.ogrid[-size//2:size//2, -size//2:size//2]\n",
    "    r = np.sqrt(x*x + y*y).astype(np.float32)\n",
    "    mask = (r < size * 0.35).astype(np.float32)\n",
    "    img = img * (1 - mask * 0.1) + mask * 0.05\n",
    "    return np.clip(img, 0, 1)\n",
    "\n",
    "\n",
    "def add_defect(img, defect_type='scratch', seed=None):\n",
    "    \"\"\"æ¬ é™¥ã‚’è¿½åŠ  â†’ (ç•°å¸¸ç”»åƒ, ãƒã‚¹ã‚¯)\"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    size = img.shape[0]\n",
    "    out = img.copy()\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    if defect_type == 'scratch':\n",
    "        ys, xs = np.random.randint(20, size-20), np.random.randint(20, size-40)\n",
    "        length, angle = np.random.randint(30, 60), np.random.uniform(-0.3, 0.3)\n",
    "        for i in range(length):\n",
    "            yi, xi = int(ys + i*np.sin(angle)), int(xs + i*np.cos(angle))\n",
    "            if 0 <= yi < size and 0 <= xi < size:\n",
    "                w = np.random.randint(1, 3)\n",
    "                out[max(0,yi-w):yi+w, max(0,xi-w):xi+w] -= 0.3\n",
    "                mask[max(0,yi-w):yi+w, max(0,xi-w):xi+w] = 1.0\n",
    "    elif defect_type == 'stain':\n",
    "        cy, cx = np.random.randint(30, size-30, 2)\n",
    "        rad = np.random.randint(8, 20)\n",
    "        yy, xx = np.ogrid[:size, :size]\n",
    "        blob = np.exp(-((xx-cx)**2 + (yy-cy)**2) / (2*rad**2))\n",
    "        out -= blob.astype(np.float32) * 0.25\n",
    "        mask = (blob > 0.3).astype(np.float32)\n",
    "    elif defect_type == 'missing':\n",
    "        cy, cx = np.random.randint(30, size-30, 2)\n",
    "        rad = np.random.randint(5, 15)\n",
    "        yy, xx = np.ogrid[:size, :size]\n",
    "        hole = (np.sqrt((xx-cx)**2 + (yy-cy)**2) < rad).astype(np.float32)\n",
    "        out = out * (1 - hole) + hole * 0.1\n",
    "        mask = hole\n",
    "    elif defect_type == 'discolor':\n",
    "        y1, x1 = np.random.randint(10, size-40), np.random.randint(10, size-40)\n",
    "        h, w = np.random.randint(15, 35), np.random.randint(15, 35)\n",
    "        out[y1:y1+h, x1:x1+w] += 0.15\n",
    "        mask[y1:y1+h, x1:x1+w] = 1.0\n",
    "\n",
    "    return np.clip(out, 0, 1), mask\n",
    "\n",
    "\n",
    "class InspectionDataset(Dataset):\n",
    "    def __init__(self, n_normal=200, n_anomaly=50, image_size=128, include_anomaly=True):\n",
    "        self.images, self.labels, self.masks, self.types = [], [], [], []\n",
    "        for i in range(n_normal):\n",
    "            img = generate_normal_image(image_size, seed=i)\n",
    "            self.images.append(img); self.labels.append(0)\n",
    "            self.masks.append(np.zeros_like(img)); self.types.append('normal')\n",
    "        if include_anomaly:\n",
    "            dtypes = ['scratch', 'stain', 'missing', 'discolor']\n",
    "            for i in range(n_anomaly):\n",
    "                base = generate_normal_image(image_size, seed=1000+i)\n",
    "                dt = dtypes[i % 4]\n",
    "                defect, m = add_defect(base, dt, seed=2000+i)\n",
    "                self.images.append(defect); self.labels.append(1)\n",
    "                self.masks.append(m); self.types.append(dt)\n",
    "\n",
    "    def __len__(self): return len(self.images)\n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.FloatTensor(self.images[idx]).unsqueeze(0),\n",
    "                self.labels[idx],\n",
    "                torch.FloatTensor(self.masks[idx]).unsqueeze(0))\n",
    "\n",
    "\n",
    "print('âœ… ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®šç¾©å®Œäº†')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "992LukgDOEyB"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®ç¢ºèª â”€â”€\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle('åˆæˆãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i in range(5):\n",
    "    img = generate_normal_image(128, seed=i)\n",
    "    axes[0, i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0, i].set_title(f'æ­£å¸¸å“ #{i+1}', fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "for i, dt in enumerate(['scratch', 'stain', 'missing', 'discolor', 'scratch']):\n",
    "    base = generate_normal_image(128, seed=100+i)\n",
    "    defect, _ = add_defect(base, dt, seed=200+i)\n",
    "    axes[1, i].imshow(defect, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1, i].set_title(f'ç•°å¸¸: {dt}', fontsize=10, color='red')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'sample_data.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f'ğŸ’¾ ä¿å­˜: {SAVE_DIR}/sample_data.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qL8AoRWOEyC"
   },
   "source": [
    "## 3. æ¤œè¨¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n",
    "\n",
    "ã“ã“ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ã¦ã€ç•°ãªã‚‹æ¡ä»¶ã§ã®æ¯”è¼ƒãŒå¯èƒ½ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ct-78-vwOEyC"
   },
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ğŸ›ï¸ æ¤œè¨¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã“ã“ã‚’å¤‰ãˆã¦å®Ÿé¨“ï¼‰       â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "CONFIG = {\n",
    "    # ãƒ‡ãƒ¼ã‚¿è¨­å®š\n",
    "    'n_train': 200,           # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°ï¼ˆæ­£å¸¸å“ï¼‰\n",
    "    'n_test_normal': 50,      # ãƒ†ã‚¹ãƒˆæ­£å¸¸å“æ•°\n",
    "    'n_test_anomaly': 50,     # ãƒ†ã‚¹ãƒˆç•°å¸¸å“æ•°\n",
    "    'image_size': 128,        # ç”»åƒã‚µã‚¤ã‚º (64 or 128)\n",
    "    'batch_size': 16,\n",
    "\n",
    "    # Sparse AE è¨­å®š\n",
    "    'sae_latent_dim': 64,     # æ½œåœ¨æ¬¡å…ƒ\n",
    "    'sae_l1_weight': 1e-3,    # L1æ­£å‰‡åŒ–å¼·åº¦ (Î»)\n",
    "\n",
    "    # Deep AE è¨­å®š\n",
    "    'dae_latent_dim': 128,    # æ½œåœ¨æ¬¡å…ƒ\n",
    "    'dae_ssim_weight': 0.1,   # SSIMæå¤±é‡ã¿\n",
    "\n",
    "    # å­¦ç¿’è¨­å®š\n",
    "    'n_epochs': 30,\n",
    "    'learning_rate': 1e-3,\n",
    "}\n",
    "\n",
    "print('ğŸ“‹ æ¤œè¨¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:')\n",
    "for k, v in CONFIG.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvBdeRnzOEyC"
   },
   "source": [
    "## 4. ãƒ‡ãƒ¼ã‚¿æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYg2GyzpOEyD"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ DataLoaderä½œæˆ â”€â”€\n",
    "train_dataset = InspectionDataset(\n",
    "    n_normal=CONFIG['n_train'], n_anomaly=0,\n",
    "    image_size=CONFIG['image_size'], include_anomaly=False,\n",
    ")\n",
    "test_dataset = InspectionDataset(\n",
    "    n_normal=CONFIG['n_test_normal'], n_anomaly=CONFIG['n_test_anomaly'],\n",
    "    image_size=CONFIG['image_size'], include_anomaly=True,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "print(f'âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(train_dataset)}æšï¼ˆæ­£å¸¸å“ã®ã¿ï¼‰')\n",
    "print(f'âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_dataset)}æšï¼ˆæ­£å¸¸{CONFIG[\"n_test_normal\"]} + ç•°å¸¸{CONFIG[\"n_test_anomaly\"]}ï¼‰')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hglnzvh9OEyD"
   },
   "source": [
    "## 5. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLCxIf3IOEyD"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ å­¦ç¿’é–¢æ•° â”€â”€\n",
    "def train_model(model, criterion, loader, config, model_name):\n",
    "    \"\"\"ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰\"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['n_epochs'])\n",
    "    model.to(DEVICE)\n",
    "    model.train()\n",
    "    losses = []\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    for epoch in range(config['n_epochs']):\n",
    "        ep_loss, nb = 0.0, 0\n",
    "        for imgs, _, _ in loader:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            recon, z = model(imgs)\n",
    "            loss, _ = criterion(imgs, recon, z)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ep_loss += loss.item(); nb += 1\n",
    "        scheduler.step()\n",
    "        avg = ep_loss / max(nb, 1)\n",
    "        losses.append(avg)\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(f'  {model_name} Epoch {epoch+1:3d}/{config[\"n_epochs\"]} | Loss: {avg:.6f}')\n",
    "\n",
    "    train_time = time.perf_counter() - t0\n",
    "    print(f'  âœ… {model_name} å­¦ç¿’å®Œäº†: {train_time:.1f}ç§’')\n",
    "    return losses, train_time\n",
    "\n",
    "\n",
    "# â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â”€â”€\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def model_size_mb(model):\n",
    "    ps = sum(p.nelement() * p.element_size() for p in model.parameters())\n",
    "    bs = sum(b.nelement() * b.element_size() for b in model.buffers())\n",
    "    return (ps + bs) / (1024 * 1024)\n",
    "\n",
    "def sparsity(z, thr=0.01):\n",
    "    return (z.abs() < thr).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7tcKNpghOEyD"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– â”€â”€\n",
    "sae = SparseAutoencoder(in_channels=1, latent_dim=CONFIG['sae_latent_dim'])\n",
    "dae = DeepAutoencoder(in_channels=1, latent_dim=CONFIG['dae_latent_dim'])\n",
    "sae_criterion = SparseAELoss(l1_weight=CONFIG['sae_l1_weight'])\n",
    "dae_criterion = DeepAELoss(ssim_weight=CONFIG['dae_ssim_weight'])\n",
    "\n",
    "print('â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”')\n",
    "print(f'â”‚ SAE: {count_params(sae):>10,} params | {model_size_mb(sae):>6.2f} MB â”‚')\n",
    "print(f'â”‚ DAE: {count_params(dae):>10,} params | {model_size_mb(dae):>6.2f} MB â”‚')\n",
    "print('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNB1VIq3OEyD"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ‹ï¸ Sparse AE å­¦ç¿’\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print('â”' * 50)\n",
    "print('ğŸ‹ï¸ Sparse Autoencoder å­¦ç¿’é–‹å§‹')\n",
    "print('â”' * 50)\n",
    "sae_losses, sae_train_time = train_model(sae, sae_criterion, train_loader, CONFIG, 'SAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xy0HWDDBOEyD"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ‹ï¸ Deep AE å­¦ç¿’\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print('â”' * 50)\n",
    "print('ğŸ‹ï¸ Deep Autoencoder å­¦ç¿’é–‹å§‹')\n",
    "print('â”' * 50)\n",
    "dae_losses, dae_train_time = train_model(dae, dae_criterion, train_loader, CONFIG, 'DAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnkO-W8yOEyD"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ å­¦ç¿’æ›²ç·šæ¯”è¼ƒ â”€â”€\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(sae_losses, color='#22d3ee', linewidth=2, label=f'Sparse AE ({sae_train_time:.1f}s)')\n",
    "ax.plot(dae_losses, color='#f97316', linewidth=2, label=f'Deep AE ({dae_train_time:.1f}s)')\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Loss')\n",
    "ax.set_title('å­¦ç¿’æ›²ç·šæ¯”è¼ƒ', fontsize=14, fontweight='bold')\n",
    "ax.legend(); ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_p3MJ12OEyE"
   },
   "source": [
    "## 6. è©•ä¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnCEvEhROEyE"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®— â”€â”€\n",
    "def compute_scores(model, loader, device):\n",
    "    \"\"\"å…¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç•°å¸¸ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—\"\"\"\n",
    "    model.eval()\n",
    "    scores, labels, error_maps = [], [], []\n",
    "    total_time, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbl, _ in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            bs = imgs.size(0)\n",
    "            t0 = time.perf_counter()\n",
    "            recon, z = model(imgs)\n",
    "            if device.type == 'cuda': torch.cuda.synchronize()\n",
    "            total_time += time.perf_counter() - t0\n",
    "            n += bs\n",
    "            err = (imgs - recon) ** 2\n",
    "            scores.extend(err.mean(dim=(1,2,3)).cpu().numpy())\n",
    "            labels.extend(lbl.numpy())\n",
    "            error_maps.extend(err.squeeze(1).cpu().numpy())\n",
    "    return np.array(scores), np.array(labels), error_maps, (total_time/n)*1000\n",
    "\n",
    "\n",
    "def compute_metrics(scores, labels):\n",
    "    \"\"\"è©•ä¾¡æŒ‡æ¨™\"\"\"\n",
    "    m = {}\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        m['auc_roc'] = roc_auc_score(labels, scores)\n",
    "        fpr, tpr, thr = roc_curve(labels, scores)\n",
    "        idx95 = np.argmin(np.abs(tpr - 0.95))\n",
    "        m['fpr_at_95tpr'] = fpr[idx95]\n",
    "        prec, rec, pthr = precision_recall_curve(labels, scores)\n",
    "        f1s = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "        m['best_f1'] = f1s.max()\n",
    "        ns = scores[labels == 0]\n",
    "        thr3s = ns.mean() + 3 * ns.std()\n",
    "        m['f1_3sigma'] = f1_score(labels, (scores > thr3s).astype(int), zero_division=0)\n",
    "    m['normal_mean'] = scores[labels==0].mean()\n",
    "    m['normal_std'] = scores[labels==0].std()\n",
    "    m['anomaly_mean'] = scores[labels==1].mean()\n",
    "    m['anomaly_std'] = scores[labels==1].std()\n",
    "    return m\n",
    "\n",
    "\n",
    "print('ğŸ“Š ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—ä¸­...')\n",
    "sae_scores, sae_labels, sae_maps, sae_inf = compute_scores(sae, test_loader, DEVICE)\n",
    "dae_scores, dae_labels, dae_maps, dae_inf = compute_scores(dae, test_loader, DEVICE)\n",
    "sae_m = compute_metrics(sae_scores, sae_labels)\n",
    "dae_m = compute_metrics(dae_scores, dae_labels)\n",
    "print('âœ… å®Œäº†')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Yn3HSqzOEyE"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“Š å®šé‡è©•ä¾¡çµæœ\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print('\\n' + 'â•' * 65)\n",
    "print('  ğŸ“Š å®šé‡è©•ä¾¡çµæœ')\n",
    "print('â•' * 65)\n",
    "print(f'{\"æŒ‡æ¨™\":<20} {\"Sparse AE\":>15} {\"Deep AE\":>15}  {\"Winner\":>8}')\n",
    "print('â”€' * 65)\n",
    "\n",
    "comparisons = [\n",
    "    ('AUC-ROC',          sae_m.get('auc_roc',0),     dae_m.get('auc_roc',0),     'higher'),\n",
    "    ('Best F1',          sae_m.get('best_f1',0),     dae_m.get('best_f1',0),     'higher'),\n",
    "    ('F1 (3Ïƒé–¾å€¤)',      sae_m.get('f1_3sigma',0),   dae_m.get('f1_3sigma',0),   'higher'),\n",
    "    ('FPR@95TPR',        sae_m.get('fpr_at_95tpr',0),dae_m.get('fpr_at_95tpr',0),'lower'),\n",
    "    ('æ¨è«–é€Ÿåº¦ (ms)',    sae_inf,                     dae_inf,                     'lower'),\n",
    "    ('å­¦ç¿’æ™‚é–“ (s)',     sae_train_time,              dae_train_time,              'lower'),\n",
    "    ('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°',    count_params(sae),           count_params(dae),           'lower'),\n",
    "    ('ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º(MB)', model_size_mb(sae),          model_size_mb(dae),          'lower'),\n",
    "]\n",
    "\n",
    "for name, sv, dv, direction in comparisons:\n",
    "    if isinstance(sv, int):\n",
    "        sf, df = f'{sv:>15,}', f'{dv:>15,}'\n",
    "    else:\n",
    "        sf, df = f'{sv:>15.4f}', f'{dv:>15.4f}'\n",
    "    if direction == 'higher':\n",
    "        w = '  SAE âœ“' if sv > dv else '  DAE âœ“'\n",
    "    else:\n",
    "        w = '  SAE âœ“' if sv < dv else '  DAE âœ“'\n",
    "    print(f'{name:<20} {sf} {df} {w}')\n",
    "\n",
    "print('â•' * 65)\n",
    "\n",
    "# ç²¾åº¦å·®ã®è©•ä¾¡\n",
    "auc_diff = abs(sae_m.get('auc_roc',0) - dae_m.get('auc_roc',0))\n",
    "speed_ratio = dae_inf / max(sae_inf, 0.001)\n",
    "print(f'\\nğŸ“Œ AUC-ROCå·®: {auc_diff:.4f}  |  é€Ÿåº¦æ¯”: SAEãŒ{speed_ratio:.1f}å€é«˜é€Ÿ')\n",
    "if auc_diff < 0.05 and speed_ratio > 3:\n",
    "    print('ğŸ’¡ çµè«–: ç²¾åº¦å·®ãŒå°ã•ãé€Ÿåº¦å·®ãŒå¤§ãã„ â†’ ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒå®Ÿç”¨çš„')\n",
    "elif auc_diff > 0.1:\n",
    "    print('ğŸ’¡ çµè«–: ç²¾åº¦å·®ãŒå¤§ãã„ â†’ ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ¢ãƒ‡ãƒ«ã‚’æ¨å¥¨')\n",
    "else:\n",
    "    print('ğŸ’¡ çµè«–: ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚ã‚Š â†’ è£½é€ ãƒ©ã‚¤ãƒ³è¦ä»¶ã«å¿œã˜ã¦é¸æŠ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "raAtgL2WOEyE"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ç•°å¸¸ã‚¹ã‚³ã‚¢åˆ†å¸ƒ â”€â”€\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, scores, labels, title, color in [\n",
    "    (ax1, sae_scores, sae_labels, 'Sparse AE', '#22d3ee'),\n",
    "    (ax2, dae_scores, dae_labels, 'Deep AE', '#f97316'),\n",
    "]:\n",
    "    ns, ans = scores[labels==0], scores[labels==1]\n",
    "    ax.hist(ns, bins=30, alpha=0.7, color='#10b981', label='æ­£å¸¸', density=True)\n",
    "    ax.hist(ans, bins=30, alpha=0.7, color='#ef4444', label='ç•°å¸¸', density=True)\n",
    "    ax.axvline(ns.mean() + 3*ns.std(), color='white', ls='--', lw=1.5, label='3Ïƒé–¾å€¤')\n",
    "    ax.set_title(title, fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('ç•°å¸¸ã‚¹ã‚³ã‚¢'); ax.legend()\n",
    "    ax.grid(alpha=0.2)\n",
    "\n",
    "plt.suptitle('ç•°å¸¸ã‚¹ã‚³ã‚¢åˆ†å¸ƒæ¯”è¼ƒ', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'score_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0z6DgUFOEyE"
   },
   "source": [
    "## 7. ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5PmJsHwOEyE"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ç•°å¸¸æ¤œçŸ¥ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æ¯”è¼ƒ â”€â”€\n",
    "all_imgs, all_labels_t, all_masks_t = [], [], []\n",
    "for imgs, lbl, msk in test_loader:\n",
    "    all_imgs.append(imgs); all_labels_t.append(lbl); all_masks_t.append(msk)\n",
    "all_imgs = torch.cat(all_imgs)\n",
    "all_labels = torch.cat(all_labels_t).numpy()\n",
    "all_masks = torch.cat(all_masks_t)\n",
    "\n",
    "anomaly_idx = np.where(all_labels == 1)[0]\n",
    "n_show = min(6, len(anomaly_idx))\n",
    "sel = anomaly_idx[:n_show]\n",
    "\n",
    "sae.eval(); dae.eval()\n",
    "n_cols = 7\n",
    "fig, axes = plt.subplots(n_show, n_cols, figsize=(n_cols*3, n_show*3))\n",
    "if n_show == 1: axes = axes.reshape(1, -1)\n",
    "\n",
    "col_titles = ['å…ƒç”»åƒ', 'çœŸå€¤ãƒã‚¹ã‚¯', 'SAEå†æ§‹æˆ', 'DAEå†æ§‹æˆ',\n",
    "              'SAEã‚¨ãƒ©ãƒ¼', 'DAEã‚¨ãƒ©ãƒ¼', 'SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤']\n",
    "for j, t in enumerate(col_titles):\n",
    "    axes[0, j].set_title(t, fontsize=10, fontweight='bold')\n",
    "\n",
    "for i, idx in enumerate(sel):\n",
    "    img = all_imgs[idx:idx+1].to(DEVICE)\n",
    "    mask = all_masks[idx].squeeze().numpy()\n",
    "    with torch.no_grad():\n",
    "        sr, _ = sae(img)\n",
    "        dr, _ = dae(img)\n",
    "    inp = all_imgs[idx].squeeze().numpy()\n",
    "    sr_np = sr.squeeze().cpu().numpy()\n",
    "    dr_np = dr.squeeze().cpu().numpy()\n",
    "    se = np.abs(inp - sr_np)\n",
    "    de = np.abs(inp - dr_np)\n",
    "    overlay = create_overlay(inp, se, alpha=0.55)\n",
    "\n",
    "    panels = [\n",
    "        (inp,     'gray', 1.0,  False),\n",
    "        (mask,    'Reds', 1.0,  False),\n",
    "        (sr_np,   'gray', 1.0,  False),\n",
    "        (dr_np,   'gray', 1.0,  False),\n",
    "        (se,      INSPECTION_CMAP, None, True),\n",
    "        (de,      INSPECTION_CMAP, None, True),\n",
    "        (overlay, None,   None, False),\n",
    "    ]\n",
    "    for j, (p, cm, vmax_f, add_cbar) in enumerate(panels):\n",
    "        ax = axes[i, j]\n",
    "        if cm is None:\n",
    "            ax.imshow(p)\n",
    "        elif vmax_f is not None:\n",
    "            ax.imshow(p, cmap=cm, vmin=0, vmax=vmax_f)\n",
    "        else:\n",
    "            vmax = max(p.max(), 0.001)\n",
    "            im = ax.imshow(p, cmap=cm, vmin=0, vmax=vmax)\n",
    "            if add_cbar:\n",
    "                cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "                cbar.ax.tick_params(labelsize=6)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.suptitle('ç•°å¸¸æ¤œçŸ¥ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æ¯”è¼ƒ', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'heatmap_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VeZm1U9DOEyE"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ æ½œåœ¨ç©ºé–“ã®ã‚¹ãƒ‘ãƒ¼ã‚¹åº¦å¯è¦–åŒ– â”€â”€\n",
    "sample = all_imgs[:1].to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    _, sz = sae(sample)\n",
    "    _, dz = dae(sample)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 3.5))\n",
    "\n",
    "szn = sz.cpu().numpy().flatten()\n",
    "dzn = dz.cpu().numpy().flatten()\n",
    "\n",
    "ax1.bar(range(len(szn)), np.abs(szn), color='#22d3ee', alpha=0.8, width=1.0)\n",
    "ax1.set_title(f'SAE æ½œåœ¨è¡¨ç¾ (ã‚¹ãƒ‘ãƒ¼ã‚¹åº¦: {sparsity(sz):.1%})', fontweight='bold')\n",
    "ax1.set_xlabel('ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³Index'); ax1.set_ylabel('|æ´»æ€§åŒ–å€¤|')\n",
    "\n",
    "ax2.bar(range(len(dzn)), np.abs(dzn), color='#f97316', alpha=0.8, width=1.0)\n",
    "ax2.set_title(f'DAE æ½œåœ¨è¡¨ç¾ (ã‚¹ãƒ‘ãƒ¼ã‚¹åº¦: {sparsity(dz):.1%})', fontweight='bold')\n",
    "ax2.set_xlabel('ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³Index'); ax2.set_ylabel('|æ´»æ€§åŒ–å€¤|')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'sparsity_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f'ğŸ’¡ SAEã¯å°‘æ•°ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã ã‘ãŒå¼·ãæ´»æ€§åŒ– â†’ é‡è¦ãªç‰¹å¾´ã«é›†ä¸­')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-ANx5rMOEyE"
   },
   "source": [
    "## 8. ãƒ¢ãƒ‡ãƒ«ä¿å­˜ & ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJC9zQJiOEyE"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ â”€â”€\n",
    "torch.save(sae.state_dict(), SAVE_DIR / 'sparse_ae.pth')\n",
    "torch.save(dae.state_dict(), SAVE_DIR / 'deep_ae.pth')\n",
    "print(f'ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {SAVE_DIR}')\n",
    "\n",
    "# â”€â”€ ONNX ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆã‚¨ãƒƒã‚¸å±•é–‹ç”¨ï¼‰â”€â”€\n",
    "try:\n",
    "    dummy = torch.randn(1, 1, CONFIG['image_size'], CONFIG['image_size']).to('cpu')\n",
    "    sae_cpu = SparseAutoencoder(latent_dim=CONFIG['sae_latent_dim']).cpu()\n",
    "    sae_cpu.load_state_dict(sae.cpu().state_dict())\n",
    "    sae_cpu.eval()\n",
    "    torch.onnx.export(\n",
    "        sae_cpu, dummy,\n",
    "        str(SAVE_DIR / 'sparse_ae.onnx'),\n",
    "        input_names=['input'], output_names=['reconstruction', 'latent'],\n",
    "        dynamic_axes={'input': {0: 'batch'}, 'reconstruction': {0: 'batch'}},\n",
    "        opset_version=14,\n",
    "    )\n",
    "    onnx_size = os.path.getsize(SAVE_DIR / 'sparse_ae.onnx') / (1024*1024)\n",
    "    print(f'âœ… ONNX ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: sparse_ae.onnx ({onnx_size:.2f} MB)')\n",
    "    sae.to(DEVICE)  # GPUã«æˆ»ã™\n",
    "except Exception as e:\n",
    "    print(f'âš ï¸ ONNX ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¹ã‚­ãƒƒãƒ—: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VV9QRjr0OEyE"
   },
   "outputs": [],
   "source": [
    "# â”€â”€ è©•ä¾¡çµæœã‚’JSONã§ä¿å­˜ â”€â”€\n",
    "results = {\n",
    "    'config': CONFIG,\n",
    "    'device': str(DEVICE),\n",
    "    'sparse_ae': {\n",
    "        'params': count_params(sae),\n",
    "        'size_mb': round(model_size_mb(sae), 3),\n",
    "        'train_time_s': round(sae_train_time, 2),\n",
    "        'inference_ms': round(sae_inf, 3),\n",
    "        'metrics': {k: round(float(v), 5) for k, v in sae_m.items()},\n",
    "    },\n",
    "    'deep_ae': {\n",
    "        'params': count_params(dae),\n",
    "        'size_mb': round(model_size_mb(dae), 3),\n",
    "        'train_time_s': round(dae_train_time, 2),\n",
    "        'inference_ms': round(dae_inf, 3),\n",
    "        'metrics': {k: round(float(v), 5) for k, v in dae_m.items()},\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(SAVE_DIR / 'benchmark_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f'ğŸ’¾ çµæœä¿å­˜: {SAVE_DIR}/benchmark_results.json')\n",
    "print('\\nğŸ“‚ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:')\n",
    "for f in sorted(SAVE_DIR.iterdir()):\n",
    "    sz = f.stat().st_size / 1024\n",
    "    print(f'  {f.name:<30} {sz:>8.1f} KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr4Bou0NOEyF"
   },
   "source": [
    "## 9. å®Ÿãƒ‡ãƒ¼ã‚¿ã¸ã®åˆ‡ã‚Šæ›¿ãˆæ–¹æ³•\n",
    "\n",
    "åˆæˆãƒ‡ãƒ¼ã‚¿ã§å‹•ä½œç¢ºèªãŒã§ããŸã‚‰ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’ä½¿ã£ã¦å®Ÿãƒ‡ãƒ¼ã‚¿ã«å·®ã—æ›¿ãˆã‚‰ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5Hlk4fYOEyF"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# å®Ÿãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\n",
    "# Google Drive ã¾ãŸã¯ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ç”»åƒã‚’èª­ã¿è¾¼ã‚€\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# --- ã“ã®ã‚»ãƒ«ã¯å¿…è¦ãªæ™‚ã«ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦ä½¿ç”¨ ---\n",
    "\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import glob\n",
    "#\n",
    "# class RealImageDataset(Dataset):\n",
    "#     \"\"\"å®Ÿç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\"\"\"\n",
    "#     def __init__(self, image_dir, label=0, image_size=128):\n",
    "#         self.paths = sorted(glob.glob(f'{image_dir}/*.png') +\n",
    "#                            glob.glob(f'{image_dir}/*.jpg') +\n",
    "#                            glob.glob(f'{image_dir}/*.bmp'))\n",
    "#         self.label = label\n",
    "#         self.transform = transforms.Compose([\n",
    "#             transforms.Resize((image_size, image_size)),\n",
    "#             transforms.Grayscale(num_output_channels=1),\n",
    "#             transforms.ToTensor(),\n",
    "#         ])\n",
    "#\n",
    "#     def __len__(self): return len(self.paths)\n",
    "#     def __getitem__(self, idx):\n",
    "#         img = Image.open(self.paths[idx]).convert('L')\n",
    "#         img_t = self.transform(img)\n",
    "#         mask = torch.zeros_like(img_t)\n",
    "#         return img_t, self.label, mask\n",
    "#\n",
    "# # ä½¿ã„æ–¹:\n",
    "# # Google Driveä¸Šã«ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ:\n",
    "# #   /content/drive/MyDrive/inspection_data/\n",
    "# #     â”œâ”€â”€ train/normal/     â† æ­£å¸¸å“ç”»åƒ\n",
    "# #     â””â”€â”€ test/\n",
    "# #         â”œâ”€â”€ normal/       â† ãƒ†ã‚¹ãƒˆæ­£å¸¸å“\n",
    "# #         â””â”€â”€ anomaly/      â† ãƒ†ã‚¹ãƒˆç•°å¸¸å“\n",
    "#\n",
    "# REAL_DATA_DIR = '/content/drive/MyDrive/inspection_data'\n",
    "#\n",
    "# train_real = RealImageDataset(f'{REAL_DATA_DIR}/train/normal', label=0)\n",
    "# test_normal = RealImageDataset(f'{REAL_DATA_DIR}/test/normal', label=0)\n",
    "# test_anomaly = RealImageDataset(f'{REAL_DATA_DIR}/test/anomaly', label=1)\n",
    "# test_real = torch.utils.data.ConcatDataset([test_normal, test_anomaly])\n",
    "#\n",
    "# train_loader = DataLoader(train_real, batch_size=16, shuffle=True)\n",
    "# test_loader = DataLoader(test_real, batch_size=16, shuffle=False)\n",
    "#\n",
    "# print(f'å®Ÿãƒ‡ãƒ¼ã‚¿: å­¦ç¿’{len(train_real)}æš, ãƒ†ã‚¹ãƒˆ{len(test_real)}æš')\n",
    "\n",
    "print('ğŸ’¡ å®Ÿãƒ‡ãƒ¼ã‚¿ä½¿ç”¨æ™‚ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„')\n",
    "print('   ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆ:')\n",
    "print('   inspection_data/')\n",
    "print('   â”œâ”€â”€ train/normal/     â† æ­£å¸¸å“ç”»åƒ')\n",
    "print('   â””â”€â”€ test/')\n",
    "print('       â”œâ”€â”€ normal/       â† ãƒ†ã‚¹ãƒˆæ­£å¸¸å“')\n",
    "print('       â””â”€â”€ anomaly/      â† ãƒ†ã‚¹ãƒˆç•°å¸¸å“')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9guCbOWOEyF"
   },
   "source": [
    "---\n",
    "## ğŸ“ è£œè¶³æƒ…å ±\n",
    "\n",
    "### Windows ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ–¹æ³•\n",
    "\n",
    "```bash\n",
    "# 1. ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "# 2. Jupyter Notebook/Lab ã§é–‹ã\n",
    "pip install jupyter torch torchvision scikit-learn matplotlib\n",
    "jupyter notebook inspection_ai_benchmark.ipynb\n",
    "\n",
    "# ã¾ãŸã¯ .py ã«å¤‰æ›ã—ã¦å®Ÿè¡Œ\n",
    "jupyter nbconvert --to script inspection_ai_benchmark.ipynb\n",
    "python inspection_ai_benchmark.py\n",
    "```\n",
    "\n",
    "### ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•å¯¾å¿œ\n",
    "| ç’°å¢ƒ | ãƒ‡ãƒã‚¤ã‚¹ | å‚™è€ƒ |\n",
    "|------|----------|------|\n",
    "| Google Colab | CUDA (T4) | æœ€é€Ÿã€‚ç„¡æ–™æ ã§åˆ©ç”¨å¯ |\n",
    "| Windows + NVIDIA GPU | CUDA | CUDAãƒ‰ãƒ©ã‚¤ãƒè¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« |\n",
    "| Windows (GPUãªã—) | CPU | å‹•ä½œã™ã‚‹ãŒå­¦ç¿’ã«æ™‚é–“ãŒã‹ã‹ã‚‹ |\n",
    "| MacBook (M5) | MPS | Apple SiliconåŠ é€Ÿ |\n",
    "\n",
    "### æ¨å¥¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´\n",
    "| ç›®çš„ | å¤‰æ›´ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ |\n",
    "|------|-------------------|\n",
    "| ç²¾åº¦å‘ä¸Š | `n_epochs` â†‘, `n_train` â†‘ |\n",
    "| SAEã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–å¼·åŒ– | `sae_l1_weight` â†‘ (5e-3 ~ 1e-2) |\n",
    "| DAEç²¾åº¦é‡è¦– | `dae_ssim_weight` â†‘, `dae_latent_dim` â†‘ |\n",
    "| é«˜é€Ÿæ¤œè¨¼ | `image_size=64`, `n_epochs=10` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWhdTvDNOEyF"
   },
   "source": [
    "## 10. ğŸ–¼ï¸ ãƒ†ã‚¹ãƒˆç”»åƒã®èª­ã¿è¾¼ã¿ã¨åˆ¤å®š\n",
    "\n",
    "å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«è‡ªåˆ†ã®ç”»åƒã‚’å…¥åŠ›ã—ã¦åˆ¤å®šçµæœã‚’ç¢ºèªã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8OapdzTOEyF"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ãƒ†ã‚¹ãƒˆç”»åƒã®èª­ã¿è¾¼ã¿ & æ¨è«–\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import torchvision.transforms as T_transforms\n",
    "from PIL import Image as PILImage\n",
    "import glob\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def preprocess_image(pil_img, target_size=128):\n",
    "    \"\"\"ç”»åƒã‚’ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ã«å¤‰æ›\"\"\"\n",
    "    transform = T_transforms.Compose([\n",
    "        T_transforms.Resize((target_size, target_size)),\n",
    "        T_transforms.Grayscale(num_output_channels=1),\n",
    "        T_transforms.ToTensor(),\n",
    "    ])\n",
    "    return transform(pil_img).unsqueeze(0)\n",
    "\n",
    "\n",
    "def run_inspection(image_paths_or_pils, sae_model, dae_model, device,\n",
    "                   image_size=128, sae_threshold=None, dae_threshold=None):\n",
    "    \"\"\"ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒãƒƒãƒæ¨è«–\"\"\"\n",
    "    sae_model.to(device).eval()\n",
    "    dae_model.to(device).eval()\n",
    "    results = []\n",
    "\n",
    "    for item in image_paths_or_pils:\n",
    "        if isinstance(item, str):\n",
    "            name = os.path.basename(item)\n",
    "            pil = PILImage.open(item).convert('RGB')\n",
    "        else:\n",
    "            name = getattr(item, 'filename', 'uploaded')\n",
    "            pil = item if isinstance(item, PILImage.Image) else PILImage.open(item).convert('RGB')\n",
    "\n",
    "        # å…ƒç”»åƒRGBï¼ˆãƒªã‚µã‚¤ã‚ºæ¸ˆã¿ï¼‰\n",
    "        original_rgb = np.array(pil.resize((image_size, image_size))).astype(np.float32) / 255.0\n",
    "\n",
    "        tensor = preprocess_image(pil, image_size).to(device)\n",
    "        with torch.no_grad():\n",
    "            sae_r, _ = sae_model(tensor)\n",
    "            dae_r, _ = dae_model(tensor)\n",
    "\n",
    "        sae_score = ((tensor - sae_r)**2).mean().item()\n",
    "        dae_score = ((tensor - dae_r)**2).mean().item()\n",
    "\n",
    "        results.append({\n",
    "            'name': name,\n",
    "            'pil': pil,\n",
    "            'original_rgb': original_rgb,\n",
    "            'input': tensor.squeeze().cpu().numpy(),\n",
    "            'sae_recon': sae_r.squeeze().cpu().numpy(),\n",
    "            'dae_recon': dae_r.squeeze().cpu().numpy(),\n",
    "            'sae_error': torch.abs(tensor - sae_r).squeeze().cpu().numpy(),\n",
    "            'dae_error': torch.abs(tensor - dae_r).squeeze().cpu().numpy(),\n",
    "            'sae_score': sae_score,\n",
    "            'dae_score': dae_score,\n",
    "            'sae_judge': 'ç•°å¸¸' if (sae_threshold and sae_score > sae_threshold) else 'æ­£å¸¸',\n",
    "            'dae_judge': 'ç•°å¸¸' if (dae_threshold and dae_score > dae_threshold) else 'æ­£å¸¸',\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def display_results(results):\n",
    "    \"\"\"çµæœã‚’è¡¨ã¨ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§è¡¨ç¤ºï¼ˆ7åˆ—: å…ƒç”»åƒ+ã‚¨ãƒ©ãƒ¼+ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼‰\"\"\"\n",
    "    # ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«\n",
    "    print('\\n' + 'â•'*75)\n",
    "    print('  ğŸ–¼ï¸ ãƒ†ã‚¹ãƒˆç”»åƒ åˆ¤å®šçµæœ')\n",
    "    print('â•'*75)\n",
    "    print(f'{\"ãƒ•ã‚¡ã‚¤ãƒ«\":<25} {\"SAEã‚¹ã‚³ã‚¢\":>12} {\"SAEåˆ¤å®š\":>8} {\"DAEã‚¹ã‚³ã‚¢\":>12} {\"DAEåˆ¤å®š\":>8}')\n",
    "    print('â”€'*75)\n",
    "    for r in results:\n",
    "        sae_icon = 'âŒ' if r['sae_judge']=='ç•°å¸¸' else 'âœ…'\n",
    "        dae_icon = 'âŒ' if r['dae_judge']=='ç•°å¸¸' else 'âœ…'\n",
    "        print(f'{r[\"name\"]:<25} {r[\"sae_score\"]:>12.6f} {sae_icon} {r[\"sae_judge\"]:>4}'\n",
    "              f' {r[\"dae_score\"]:>12.6f} {dae_icon} {r[\"dae_judge\"]:>4}')\n",
    "    print('â•'*75)\n",
    "\n",
    "    # ä¸ä¸€è‡´ãƒã‚§ãƒƒã‚¯\n",
    "    disagree = [r for r in results if r['sae_judge'] != r['dae_judge']]\n",
    "    if disagree:\n",
    "        print(f'\\nâš ï¸ {len(disagree)}æšã§åˆ¤å®šä¸ä¸€è‡´:')\n",
    "        for r in disagree:\n",
    "            print(f'  ğŸ“Œ {r[\"name\"]}: SAE={r[\"sae_judge\"]} / DAE={r[\"dae_judge\"]}')\n",
    "\n",
    "    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆ2è¡ŒÃ—4åˆ—ï¼‰\n",
    "    n = len(results)\n",
    "    fig, axes = plt.subplots(n * 2, 4, figsize=(18, n * 6))\n",
    "    if n == 1:\n",
    "        axes = axes.reshape(2, 4)\n",
    "\n",
    "    for i, r in enumerate(results):\n",
    "        row_top = i * 2\n",
    "        row_bot = i * 2 + 1\n",
    "\n",
    "        # ä¸Šæ®µ: å…ƒç”»åƒ, å…¥åŠ›(ã‚°ãƒ¬ãƒ¼), SAEå†æ§‹æˆ, DAEå†æ§‹æˆ\n",
    "        panels_top = [\n",
    "            (r['original_rgb'], 'å…ƒç”»åƒ', None),\n",
    "            (r['input'], 'å…¥åŠ›(ã‚°ãƒ¬ãƒ¼)', 'gray'),\n",
    "            (r['sae_recon'], 'SAEå†æ§‹æˆ', 'gray'),\n",
    "            (r['dae_recon'], 'DAEå†æ§‹æˆ', 'gray'),\n",
    "        ]\n",
    "        for j, (p, t, cm) in enumerate(panels_top):\n",
    "            ax = axes[row_top, j] if n > 1 else axes[0, j]\n",
    "            if cm: ax.imshow(p, cmap=cm, vmin=0, vmax=1)\n",
    "            else:  ax.imshow(p)\n",
    "            if i == 0: ax.set_title(t, fontsize=10, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "            if j == 0:\n",
    "                icon = 'ğŸ”´' if 'ç•°å¸¸' in r['sae_judge'] or 'ç•°å¸¸' in r['dae_judge'] else 'ğŸŸ¢'\n",
    "                ax.set_ylabel(f'{icon}{r[\"name\"][:12]}', fontsize=8, rotation=0, labelpad=70, va='center')\n",
    "\n",
    "        # ä¸‹æ®µ: SAEã‚¨ãƒ©ãƒ¼, DAEã‚¨ãƒ©ãƒ¼, SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤, DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤\n",
    "        sae_ov = create_overlay(r['input'], r['sae_error'], alpha=0.55)\n",
    "        dae_ov = create_overlay(r['input'], r['dae_error'], alpha=0.55)\n",
    "        panels_bot = [\n",
    "            (r['sae_error'], 'SAEã‚¨ãƒ©ãƒ¼', True),\n",
    "            (r['dae_error'], 'DAEã‚¨ãƒ©ãƒ¼', True),\n",
    "            (sae_ov, 'SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', False),\n",
    "            (dae_ov, 'DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', False),\n",
    "        ]\n",
    "        bot_titles = ['SAEã‚¨ãƒ©ãƒ¼', 'DAEã‚¨ãƒ©ãƒ¼', 'SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', 'DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤']\n",
    "        for j, (p, t, use_cmap) in enumerate(panels_bot):\n",
    "            ax = axes[row_bot, j] if n > 1 else axes[1, j]\n",
    "            if use_cmap:\n",
    "                vmax = max(p.max(), 0.001)\n",
    "                im = ax.imshow(p, cmap=INSPECTION_CMAP, vmin=0, vmax=vmax)\n",
    "                cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "                cbar.ax.tick_params(labelsize=6)\n",
    "            else:\n",
    "                ax.imshow(p)\n",
    "            if i == 0: ax.set_title(t, fontsize=10, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.suptitle('ãƒ†ã‚¹ãƒˆç”»åƒ ç•°å¸¸æ¤œçŸ¥çµæœ', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(SAVE_DIR / 'test_image_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "print('âœ… ãƒ†ã‚¹ãƒˆç”»åƒæ¨è«–é–¢æ•° å®šç¾©å®Œäº†')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2v1RrfpuOEyF"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# æ–¹æ³•A: åˆæˆãƒ†ã‚¹ãƒˆç”»åƒã§å‹•ä½œç¢ºèª\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# 3Ïƒé–¾å€¤ã‚’è¨ˆç®—\n",
    "sae_threshold = sae_m.get('normal_mean', 0) + 3 * sae_m.get('normal_std', 0.001)\n",
    "dae_threshold = dae_m.get('normal_mean', 0) + 3 * dae_m.get('normal_std', 0.001)\n",
    "print(f'é–¾å€¤: SAE={sae_threshold:.6f}, DAE={dae_threshold:.6f}')\n",
    "\n",
    "# åˆæˆãƒ†ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆ\n",
    "test_pils = []\n",
    "for i in range(3):\n",
    "    arr = generate_normal_image(CONFIG['image_size'], seed=8000+i)\n",
    "    pil = PILImage.fromarray((arr*255).astype(np.uint8), mode='L').convert('RGB')\n",
    "    pil.filename = f'normal_{i+1}.png'\n",
    "    test_pils.append(pil)\n",
    "\n",
    "for i, dt in enumerate(['scratch', 'stain', 'missing', 'discolor']):\n",
    "    base = generate_normal_image(CONFIG['image_size'], seed=9000+i)\n",
    "    defect, _ = add_defect(base, dt, seed=9100+i)\n",
    "    pil = PILImage.fromarray((defect*255).astype(np.uint8), mode='L').convert('RGB')\n",
    "    pil.filename = f'defect_{dt}.png'\n",
    "    test_pils.append(pil)\n",
    "\n",
    "# æ¨è«–å®Ÿè¡Œ\n",
    "results = run_inspection(\n",
    "    test_pils, sae, dae, DEVICE,\n",
    "    image_size=CONFIG['image_size'],\n",
    "    sae_threshold=sae_threshold,\n",
    "    dae_threshold=dae_threshold,\n",
    ")\n",
    "display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zy7xUs1QOEyF"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# æ–¹æ³•B: Colabã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ¤å®š\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# --- Colabã®å ´åˆ: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ€ã‚¤ã‚¢ãƒ­ã‚° ---\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print('ğŸ“ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰')\n",
    "    print('   å¯¾å¿œå½¢å¼: PNG, JPG, BMP, TIFF')\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    if uploaded:\n",
    "        upload_pils = []\n",
    "        for fname, content in uploaded.items():\n",
    "            pil = PILImage.open(io.BytesIO(content)).convert('RGB')\n",
    "            pil.filename = fname\n",
    "            upload_pils.append(pil)\n",
    "            print(f'  âœ… {fname} ({pil.size[0]}x{pil.size[1]})')\n",
    "\n",
    "        results_upload = run_inspection(\n",
    "            upload_pils, sae, dae, DEVICE,\n",
    "            image_size=CONFIG['image_size'],\n",
    "            sae_threshold=sae_threshold,\n",
    "            dae_threshold=dae_threshold,\n",
    "        )\n",
    "        display_results(results_upload)\n",
    "\n",
    "except ImportError:\n",
    "    print('ğŸ’¡ Colabä»¥å¤–ã®ç’°å¢ƒã§ã™ã€‚æ–¹æ³•Cã§ãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®šã—ã¦ãã ã•ã„ã€‚')\n",
    "    print('   ã¾ãŸã¯ä¸Šã®åˆæˆç”»åƒãƒ†ã‚¹ãƒˆï¼ˆæ–¹æ³•Aï¼‰ã‚’ãŠä½¿ã„ãã ã•ã„ã€‚')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrnbOTQcOEyF"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# æ–¹æ³•C: ãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®šã§ä¸€æ‹¬åˆ¤å®š\n",
    "# Windows / Mac / Colab(Drive) å…±é€š\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# --- ãƒ‘ã‚¹ã‚’å¤‰æ›´ã—ã¦ä½¿ç”¨ ---\n",
    "# TEST_IMAGE_DIR = r'C:\\Users\\your_name\\test_images'        # Windows\n",
    "# TEST_IMAGE_DIR = '/Users/your_name/test_images'            # Mac\n",
    "# TEST_IMAGE_DIR = '/content/drive/MyDrive/test_images'      # Colab + Drive\n",
    "\n",
    "TEST_IMAGE_DIR = ''  # â† ã“ã“ã«ãƒ‘ã‚¹ã‚’å…¥åŠ›\n",
    "\n",
    "if TEST_IMAGE_DIR and os.path.isdir(TEST_IMAGE_DIR):\n",
    "    extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tif', '*.tiff']\n",
    "    image_paths = []\n",
    "    for ext in extensions:\n",
    "        image_paths.extend(glob.glob(os.path.join(TEST_IMAGE_DIR, ext)))\n",
    "        image_paths.extend(glob.glob(os.path.join(TEST_IMAGE_DIR, ext.upper())))\n",
    "    image_paths = sorted(set(image_paths))\n",
    "\n",
    "    if image_paths:\n",
    "        print(f'ğŸ“‚ {len(image_paths)}æšã®ç”»åƒã‚’æ¤œå‡º: {TEST_IMAGE_DIR}')\n",
    "        for p in image_paths[:5]:\n",
    "            print(f'  ğŸ“„ {os.path.basename(p)}')\n",
    "        if len(image_paths) > 5:\n",
    "            print(f'  ... ä»–{len(image_paths)-5}æš')\n",
    "\n",
    "        results_folder = run_inspection(\n",
    "            image_paths, sae, dae, DEVICE,\n",
    "            image_size=CONFIG['image_size'],\n",
    "            sae_threshold=sae_threshold,\n",
    "            dae_threshold=dae_threshold,\n",
    "        )\n",
    "        display_results(results_folder)\n",
    "    else:\n",
    "        print(f'âš ï¸ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {TEST_IMAGE_DIR}')\n",
    "else:\n",
    "    print('ğŸ’¡ TEST_IMAGE_DIR ã«ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„')\n",
    "    print('   ä¾‹:')\n",
    "    print('   Windows:  r\"C:\\\\Users\\\\user\\\\test_images\"')\n",
    "    print('   Mac:      \"/Users/user/test_images\"')\n",
    "    print('   Colab:    \"/content/drive/MyDrive/test_images\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzUPILJrOEyF"
   },
   "source": [
    "## 11. ğŸ›ï¸ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–GUIï¼ˆColabå¯¾å¿œï¼‰\n",
    "\n",
    "ãƒœã‚¿ãƒ³æ“ä½œã ã‘ã§ **ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ æ¨è«– â†’ çµæœãƒ¬ãƒ“ãƒ¥ãƒ¼** ã‚’è¡Œãˆã‚‹GUIã§ã™ã€‚\n",
    "\n",
    "> **æ“ä½œæ–¹æ³•**: ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã¨GUIãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "si63LMIXOEyL"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# GUI ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆipywidgetsï¼‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import io as _io\n",
    "import base64\n",
    "from PIL import Image as PILImage\n",
    "import torchvision.transforms as T_transforms\n",
    "\n",
    "# â”€â”€ çŠ¶æ…‹ç®¡ç† â”€â”€\n",
    "gui_state = {\n",
    "    'images': [],       # [(name, PIL.Image), ...]\n",
    "    'results': [],      # run_inspection ã®å‡ºåŠ›\n",
    "    'current_idx': 0,   # ç¾åœ¨è¡¨ç¤ºä¸­ã®ç”»åƒindex\n",
    "}\n",
    "\n",
    "# â”€â”€ ã‚¹ã‚¿ã‚¤ãƒ«å®šç¾© â”€â”€\n",
    "CSS = HTML('''\n",
    "<style>\n",
    ".gui-header { background: linear-gradient(135deg, #1e3a5f, #0f2027);\n",
    "  color: white; padding: 16px 24px; border-radius: 12px;\n",
    "  font-size: 18px; font-weight: bold; margin-bottom: 12px; }\n",
    ".gui-card { background: #f8f9fa; border: 1px solid #e0e0e0;\n",
    "  border-radius: 8px; padding: 12px; margin: 6px 0; }\n",
    ".gui-ok { color: #10b981; font-weight: bold; font-size: 16px; }\n",
    ".gui-ng { color: #ef4444; font-weight: bold; font-size: 16px; }\n",
    ".gui-warn { color: #f59e0b; font-weight: bold; }\n",
    ".gui-stat { display: inline-block; background: #e2e8f0;\n",
    "  border-radius: 6px; padding: 6px 14px; margin: 4px;\n",
    "  font-family: monospace; font-size: 13px; }\n",
    "</style>\n",
    "''')\n",
    "display(CSS)\n",
    "\n",
    "print('âœ… GUI ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿å®Œäº†')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 12. è¿½åŠ æ¤œè¨¼ã‚’æ¨å¥¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«\n\nç¾åœ¨ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ **Sparse AE vs Deep AE** ã®2ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã§ã™ãŒã€å¤–è¦³æ¤œæŸ»AIã®å®Ÿç”¨æ€§ã‚’æ­£ã—ãè©•ä¾¡ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ã‚‚åŠ ãˆã¦æ¯”è¼ƒã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚\n\n---\n\n### A. å„ªå…ˆåº¦: é«˜ï¼ˆå®Ÿå‹™ã§ä¸»æµ / æ€§èƒ½å·®ãŒå¤§ãã„ï¼‰\n\n#### 1. VAEï¼ˆVariational Autoencoderï¼‰\n| é …ç›® | å†…å®¹ |\n|------|------|\n| **æ¦‚è¦** | æ½œåœ¨ç©ºé–“ã‚’ç¢ºç‡åˆ†å¸ƒï¼ˆã‚¬ã‚¦ã‚¹åˆ†å¸ƒï¼‰ã¨ã—ã¦å­¦ç¿’ã™ã‚‹ |\n| **è¿½åŠ ã™ã‚‹ç†ç”±** | SAEã®L1æ­£å‰‡åŒ– vs VAEã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹æ­£å‰‡åŒ–ã®æ¯”è¼ƒãŒæœ¬è³ªçš„ã«é‡è¦ã€‚VAEã¯æ½œåœ¨ç©ºé–“ãŒãªã‚ã‚‰ã‹ã«ãªã‚‹ãŸã‚ã€ç•°å¸¸æ¤œçŸ¥ã®é–¾å€¤è¨­å®šãŒå®‰å®šã—ã‚„ã™ã„ |\n| **å®Ÿè£…ã®æ‰‹é–“** | å°ï¼ˆæ—¢å­˜SAEã«KLæå¤±ã‚’è¿½åŠ ã™ã‚‹ã ã‘ï¼‰ |\n| **æœŸå¾…ã•ã‚Œã‚‹çµæœ** | SAEã¨DAEã®ä¸­é–“çš„ãªæ€§èƒ½ã€‚é–¾å€¤ã®å®‰å®šæ€§ã¯SAE/DAEã‚ˆã‚Šå„ªã‚Œã‚‹å¯èƒ½æ€§ã‚ã‚Š |\n\n#### 2. PatchCore\n| é …ç›® | å†…å®¹ |\n|------|------|\n| **æ¦‚è¦** | ImageNetäº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆResNetç­‰ï¼‰ã®ä¸­é–“ç‰¹å¾´é‡ã‚’æ­£å¸¸å“ã®ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ã¨ã—ã¦ä¿å­˜ã—ã€ãƒ†ã‚¹ãƒˆæ™‚ã«æœ€è¿‘å‚è·é›¢ã§ç•°å¸¸åˆ¤å®š |\n| **è¿½åŠ ã™ã‚‹ç†ç”±** | MVTec AD ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§**State-of-the-Art**ã‚’è¨˜éŒ²ã—ãŸæ‰‹æ³•ã€‚å­¦ç¿’ä¸è¦ï¼ˆç‰¹å¾´æŠ½å‡ºã®ã¿ï¼‰ã§é«˜ç²¾åº¦ã€‚ç¾åœ¨ã®AEãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã¨æ ¹æœ¬çš„ã«ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒç•°ãªã‚‹ãŸã‚ã€æ¯”è¼ƒã¨ã—ã¦ä¸å¯æ¬  |\n| **å®Ÿè£…ã®æ‰‹é–“** | ä¸­ï¼ˆanomalibãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ãˆã°æ•°è¡Œã§å®Ÿè£…å¯èƒ½ï¼‰ |\n| **æœŸå¾…ã•ã‚Œã‚‹çµæœ** | AUC-ROCã§SAE/DAEã‚’å¤§å¹…ã«ä¸Šå›ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ |\n\n#### 3. EfficientAD\n| é …ç›® | å†…å®¹ |\n|------|------|\n| **æ¦‚è¦** | è»½é‡ãªçŸ¥è­˜è’¸ç•™ãƒ™ãƒ¼ã‚¹ã®ç•°å¸¸æ¤œçŸ¥ã€‚Teacher-Studentã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ |\n| **è¿½åŠ ã™ã‚‹ç†ç”±** | 2023å¹´ä»¥é™ã®å¤–è¦³æ¤œæŸ»ã§æ³¨ç›®ã•ã‚Œã¦ã„ã‚‹æ‰‹æ³•ã€‚**é«˜ç²¾åº¦ã‹ã¤é«˜é€Ÿ**ã§ã€SAEã®ã€Œè»½é‡ã€ã¨DAEã®ã€Œé«˜ç²¾åº¦ã€ã®ä¸¡ç«‹ã‚’ç›®æŒ‡ã™ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦é‡è¦ãªæ¯”è¼ƒå¯¾è±¡ |\n| **å®Ÿè£…ã®æ‰‹é–“** | ä¸­ï¼ˆanomalibãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§å¯¾å¿œï¼‰ |\n| **æœŸå¾…ã•ã‚Œã‚‹çµæœ** | ç²¾åº¦ã¨é€Ÿåº¦ã®ä¸¡é¢ã§ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ |\n\n---\n\n### B. å„ªå…ˆåº¦: ä¸­ï¼ˆç‰¹å®šæ¡ä»¶ã§æœ‰åŠ¹ï¼‰\n\n#### 4. U-Net Autoencoderï¼ˆSkip Connectionä»˜ãAEï¼‰\n| é …ç›® | å†…å®¹ |\n|------|------|\n| **æ¦‚è¦** | ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¨ãƒ‡ã‚³ãƒ¼ãƒ€ã‚’ã‚¹ã‚­ãƒƒãƒ—æ¥ç¶šã§ã¤ãªãã€‚å…ƒç”»åƒã®ç´°éƒ¨ã‚’ä¿æŒã—ã‚„ã™ã„ |\n| **è¿½åŠ ã™ã‚‹ç†ç”±** | ç¾åœ¨ã®DAEã¯ã‚¹ã‚­ãƒƒãƒ—æ¥ç¶šãŒãªã„ãŸã‚ã€å¾®ç´°ãªãƒ†ã‚¯ã‚¹ãƒãƒ£ã®å¾©å…ƒãŒè‹¦æ‰‹ã€‚U-Netæ§‹é€ ã‚’åŠ ãˆã‚‹ã“ã¨ã§ã€Œæ§‹é€ ã¯ä¿æŒã—ã¤ã¤ç•°å¸¸éƒ¨åˆ†ã ã‘å¾©å…ƒå¤±æ•—ã™ã‚‹ã€ç†æƒ³çš„ãªæŒ™å‹•ãŒæœŸå¾…ã§ãã‚‹ |\n| **æœŸå¾…ã•ã‚Œã‚‹çµæœ** | DAEã‚ˆã‚Šãƒ”ã‚¯ã‚»ãƒ«ãƒ¬ãƒ™ãƒ«ã®ç•°å¸¸ä½ç½®ç‰¹å®šï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼‰ãŒæ”¹å–„ |\n\n#### 5. GANomaly / f-AnoGAN\n| é …ç›® | å†…å®¹ |\n|------|------|\n| **æ¦‚è¦** | GANï¼ˆæ•µå¯¾çš„ç”Ÿæˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã‚’ä½¿ã£ãŸç•°å¸¸æ¤œçŸ¥ã€‚Encoder-Decoder-Encoderæ§‹é€  |\n| **è¿½åŠ ã™ã‚‹ç†ç”±** | AEã®å¾©å…ƒèª¤å·®ã ã‘ã§ãªãã€æ½œåœ¨ç©ºé–“ã§ã®å·®åˆ†ã‚‚ç•°å¸¸ã‚¹ã‚³ã‚¢ã«ä½¿ã†ãŸã‚ã€AEã§ã¯æ¤œå‡ºå›°é›£ãªå¾®ç´°ç•°å¸¸ã«å¼·ã„å ´åˆãŒã‚ã‚‹ |\n| **æ³¨æ„ç‚¹** | GANç‰¹æœ‰ã®å­¦ç¿’ä¸å®‰å®šæ€§ãŒã‚ã‚‹ã€‚åˆæˆãƒ‡ãƒ¼ã‚¿ã§ã¯å·®ãŒå‡ºã«ãã„å¯èƒ½æ€§ã‚ã‚Š |\n\n#### 6. Flow-based Modelï¼ˆFastFlow / CFLOW-ADï¼‰\n| é …ç›® | å†…å®¹ |\n|------|------|\n| **æ¦‚è¦** | æ­£è¦åŒ–ãƒ•ãƒ­ãƒ¼ï¼ˆNormalizing Flowï¼‰ã§æ­£å¸¸å“ã®ç‰¹å¾´é‡åˆ†å¸ƒã‚’æ­£ç¢ºã«ãƒ¢ãƒ‡ãƒªãƒ³ã‚° |\n| **è¿½åŠ ã™ã‚‹ç†ç”±** | AEã®ã€Œå¾©å…ƒãƒ™ãƒ¼ã‚¹ã€ã¨ã¯ç•°ãªã‚‹ã€Œå¯†åº¦æ¨å®šãƒ™ãƒ¼ã‚¹ã€ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€‚ç†è«–çš„ã«æ­£å¸¸åˆ†å¸ƒã‹ã‚‰ã®é€¸è„±ã‚’æ­£ç¢ºã«æ¸¬å®šã§ãã‚‹ |\n| **æœŸå¾…ã•ã‚Œã‚‹çµæœ** | ç‰¹ã«æ­£å¸¸å“ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒå°‘ãªã„å ´åˆã«é«˜ã„æ€§èƒ½ |\n\n---\n\n### C. å„ªå…ˆåº¦: ä½ï¼ˆç™ºå±•çš„ / ç ”ç©¶å¯„ã‚Šï¼‰\n\n#### 7. Vision Transformer (ViT) ãƒ™ãƒ¼ã‚¹AE\n| é …ç›® | å†…å®¹ |\n|------|------|\n| **æ¦‚è¦** | CNNã®ä»£ã‚ã‚Šã«Transformerã§ç”»åƒã‚’å‡¦ç†ã€‚ç”»åƒã‚’ãƒ‘ãƒƒãƒã«åˆ†å‰²ã—ã¦Attentionã§é–¢ä¿‚æ€§ã‚’å­¦ç¿’ |\n| **è¿½åŠ ã™ã‚‹ç†ç”±** | åºƒåŸŸçš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ‰ãˆã‚„ã™ãã€å±€æ‰€çš„ãªCNNã§ã¯è¦‹é€ƒã™ç•°å¸¸ã‚’æ¤œå‡ºã§ãã‚‹å ´åˆãŒã‚ã‚‹ |\n| **æ³¨æ„ç‚¹** | ãƒ‡ãƒ¼ã‚¿é‡ãŒå°‘ãªã„ã¨æ€§èƒ½ãŒå‡ºã«ãã„ã€‚åˆæˆãƒ‡ãƒ¼ã‚¿200æšç¨‹åº¦ã§ã¯ä¸åˆ© |\n\n#### 8. Diffusion Model ãƒ™ãƒ¼ã‚¹ç•°å¸¸æ¤œçŸ¥\n| é …ç›® | å†…å®¹ |\n|------|------|\n| **æ¦‚è¦** | æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®é€†éç¨‹ã§æ­£å¸¸ç”»åƒã‚’å¾©å…ƒã—ã€å¾©å…ƒå·®åˆ†ã§ç•°å¸¸æ¤œçŸ¥ |\n| **è¿½åŠ ã™ã‚‹ç†ç”±** | ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦AEã‚„GANã‚ˆã‚Šè¡¨ç¾åŠ›ãŒé«˜ã„ã€‚æœ€æ–°ã®ç ”ç©¶ã§æ³¨ç›® |\n| **æ³¨æ„ç‚¹** | æ¨è«–é€Ÿåº¦ãŒéå¸¸ã«é…ã„ã€‚å®Ÿç”¨æ€§ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå¤§ãã„ |\n\n---\n\n### æ¨å¥¨ã™ã‚‹è¿½åŠ æ¤œè¨¼ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—\n\n```\nStep 1 (æœ€å„ªå…ˆ):  + VAE ã‚’è¿½åŠ ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®æ”¹ä¿®ã§å¯¾å¿œå¯èƒ½ï¼‰\nStep 2 (é‡è¦):    + PatchCore ã‚’è¿½åŠ ï¼ˆanomalibãƒ©ã‚¤ãƒ–ãƒ©ãƒªåˆ©ç”¨ï¼‰\nStep 3 (æ¨å¥¨):    + EfficientAD ã‚’è¿½åŠ ï¼ˆanomalibãƒ©ã‚¤ãƒ–ãƒ©ãƒªåˆ©ç”¨ï¼‰\nStep 4 (ä»»æ„):    + U-Net AE / GANomaly ã‹ã‚‰1ã¤é¸æŠ\n```\n\n> **å®Ÿå‹™ã¸ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹**: åˆæˆãƒ‡ãƒ¼ã‚¿ã§ã®æ¯”è¼ƒã¯ã€Œæ‰‹æ³•ã®ç‰¹æ€§ç†è§£ã€ã«ã¯æœ‰åŠ¹ã§ã™ãŒã€**æœ€çµ‚çš„ãªæ€§èƒ½è©•ä¾¡ã¯å¿…ãšå®Ÿãƒ‡ãƒ¼ã‚¿ã§è¡Œã£ã¦ãã ã•ã„**ã€‚åˆæˆãƒ‡ãƒ¼ã‚¿ã§ã¯æ¬ é™¥ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå˜ç´”ãªãŸã‚ã€ãƒ¢ãƒ‡ãƒ«é–“ã®å·®ãŒå®Ÿãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šå°ã•ãå‡ºã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚MVTec AD ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆç„¡æ–™å…¬é–‹ï¼‰ã‚’ä½¿ã£ãŸæ¤œè¨¼ã‚‚æœ‰åŠ¹ã§ã™ã€‚",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_77o3vROEyL"
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# GUI ãƒ¡ã‚¤ãƒ³\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# â”€â”€ å‡ºåŠ›ã‚¨ãƒªã‚¢ â”€â”€\n",
    "out_upload_status = widgets.Output()\n",
    "out_summary = widgets.Output()\n",
    "out_detail = widgets.Output()\n",
    "out_heatmap = widgets.Output()\n",
    "\n",
    "# â”€â”€ é–¾å€¤ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ â”€â”€\n",
    "sae_thr_default = sae_m.get('normal_mean', 0) + 3 * sae_m.get('normal_std', 0.001)\n",
    "dae_thr_default = dae_m.get('normal_mean', 0) + 3 * dae_m.get('normal_std', 0.001)\n",
    "\n",
    "sae_thr_slider = widgets.FloatSlider(\n",
    "    value=sae_thr_default, min=0.0, max=max(sae_thr_default*5, 0.05),\n",
    "    step=0.0001, description='SAE é–¾å€¤:', readout_format='.5f',\n",
    "    style={'description_width': '80px'}, layout=widgets.Layout(width='450px'),\n",
    ")\n",
    "dae_thr_slider = widgets.FloatSlider(\n",
    "    value=dae_thr_default, min=0.0, max=max(dae_thr_default*5, 0.05),\n",
    "    step=0.0001, description='DAE é–¾å€¤:', readout_format='.5f',\n",
    "    style={'description_width': '80px'}, layout=widgets.Layout(width='450px'),\n",
    ")\n",
    "\n",
    "# â”€â”€ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ â”€â”€\n",
    "file_uploader = widgets.FileUpload(\n",
    "    accept='.png,.jpg,.jpeg,.bmp,.tif,.tiff',\n",
    "    multiple=True,\n",
    "    description='ğŸ“ ç”»åƒã‚’é¸æŠ',\n",
    "    layout=widgets.Layout(width='300px'),\n",
    ")\n",
    "\n",
    "# â”€â”€ ãƒœã‚¿ãƒ³ â”€â”€\n",
    "btn_run = widgets.Button(\n",
    "    description='â–¶ æ¨è«–å®Ÿè¡Œ', icon='play',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='160px', height='40px'),\n",
    ")\n",
    "btn_synthetic = widgets.Button(\n",
    "    description='ğŸ² åˆæˆãƒ†ã‚¹ãƒˆ', icon='random',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='160px', height='40px'),\n",
    ")\n",
    "btn_prev = widgets.Button(\n",
    "    description='â—€ å‰ã¸', layout=widgets.Layout(width='100px'),\n",
    ")\n",
    "btn_next = widgets.Button(\n",
    "    description='æ¬¡ã¸ â–¶', layout=widgets.Layout(width='100px'),\n",
    ")\n",
    "btn_export = widgets.Button(\n",
    "    description='ğŸ’¾ CSVä¿å­˜', icon='download',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='160px', height='40px'),\n",
    ")\n",
    "label_nav = widgets.HTML(value='<b>â”€</b>')\n",
    "\n",
    "# â”€â”€ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ â”€â”€\n",
    "filter_dropdown = widgets.Dropdown(\n",
    "    options=['ã™ã¹ã¦', 'ç•°å¸¸ã®ã¿', 'æ­£å¸¸ã®ã¿', 'åˆ¤å®šä¸ä¸€è‡´ã®ã¿'],\n",
    "    value='ã™ã¹ã¦', description='è¡¨ç¤º:',\n",
    "    style={'description_width': '50px'},\n",
    "    layout=widgets.Layout(width='220px'),\n",
    ")\n",
    "\n",
    "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°\n",
    "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "def load_uploaded_files(change=None):\n",
    "    \"\"\"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆipywidgetsæ–°æ—§ä¸¡å¯¾å¿œï¼‰\"\"\"\n",
    "    gui_state['images'] = []\n",
    "    with out_upload_status:\n",
    "        clear_output()\n",
    "        if not file_uploader.value:\n",
    "            print('ğŸ“ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„')\n",
    "            return\n",
    "\n",
    "        uploaded = file_uploader.value\n",
    "\n",
    "        # ipywidgets >= 8: tuple of FileUploadContent objects\n",
    "        # ipywidgets <  8: dict {filename: {content: bytes, ...}}\n",
    "        if isinstance(uploaded, dict):\n",
    "            items = [(fname, meta['content']) for fname, meta in uploaded.items()]\n",
    "        elif isinstance(uploaded, (list, tuple)):\n",
    "            items = []\n",
    "            for item in uploaded:\n",
    "                if hasattr(item, 'name') and hasattr(item, 'content'):\n",
    "                    items.append((item.name, item.content))\n",
    "                elif isinstance(item, dict):\n",
    "                    items.append((item.get('name', 'unknown'), item.get('content', b'')))\n",
    "                else:\n",
    "                    continue\n",
    "        else:\n",
    "            print(f'âš ï¸ æœªå¯¾å¿œã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å½¢å¼: {type(uploaded)}')\n",
    "            return\n",
    "\n",
    "        for name, content in items:\n",
    "            try:\n",
    "                pil = PILImage.open(_io.BytesIO(content)).convert('RGB')\n",
    "                pil.filename = name\n",
    "                gui_state['images'].append((name, pil))\n",
    "            except Exception as e:\n",
    "                print(f'  âš ï¸ {name}: èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({e})')\n",
    "        print(f'âœ… {len(gui_state[\"images\"])}æšã®ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ')\n",
    "        for n, p in gui_state['images']:\n",
    "            print(f'  ğŸ“„ {n} ({p.size[0]}Ã—{p.size[1]})')\n",
    "\n",
    "file_uploader.observe(load_uploaded_files, names='value')\n",
    "\n",
    "\n",
    "def on_synthetic_click(btn):\n",
    "    \"\"\"åˆæˆãƒ†ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆ\"\"\"\n",
    "    gui_state['images'] = []\n",
    "    with out_upload_status:\n",
    "        clear_output()\n",
    "        print('ğŸ² åˆæˆãƒ†ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆä¸­...')\n",
    "        for i in range(3):\n",
    "            arr = generate_normal_image(CONFIG['image_size'], seed=8000+i)\n",
    "            pil = PILImage.fromarray((arr*255).astype(np.uint8), mode='L').convert('RGB')\n",
    "            pil.filename = f'normal_{i+1}.png'\n",
    "            gui_state['images'].append((f'normal_{i+1}.png', pil))\n",
    "        for i, dt in enumerate(['scratch', 'stain', 'missing', 'discolor']):\n",
    "            base = generate_normal_image(CONFIG['image_size'], seed=9000+i)\n",
    "            defect, _ = add_defect(base, dt, seed=9100+i)\n",
    "            pil = PILImage.fromarray((defect*255).astype(np.uint8), mode='L').convert('RGB')\n",
    "            pil.filename = f'defect_{dt}.png'\n",
    "            gui_state['images'].append((f'defect_{dt}.png', pil))\n",
    "        print(f'âœ… {len(gui_state[\"images\"])}æšç”Ÿæˆï¼ˆæ­£å¸¸3æš + ç•°å¸¸4æšï¼‰')\n",
    "\n",
    "btn_synthetic.on_click(on_synthetic_click)\n",
    "\n",
    "\n",
    "def on_run_click(btn):\n",
    "    \"\"\"æ¨è«–å®Ÿè¡Œ\"\"\"\n",
    "    if not gui_state['images']:\n",
    "        with out_summary:\n",
    "            clear_output()\n",
    "            print('âš ï¸ ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯åˆæˆãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚')\n",
    "        return\n",
    "\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã‚’DEVICEã«åŒæœŸï¼ˆCPU/CUDAä¸ä¸€è‡´é˜²æ­¢ï¼‰\n",
    "    sae.to(DEVICE).eval()\n",
    "    dae.to(DEVICE).eval()\n",
    "\n",
    "    pils = [p for _, p in gui_state['images']]\n",
    "    gui_state['results'] = run_inspection(\n",
    "        pils, sae, dae, DEVICE,\n",
    "        image_size=CONFIG['image_size'],\n",
    "        sae_threshold=sae_thr_slider.value,\n",
    "        dae_threshold=dae_thr_slider.value,\n",
    "    )\n",
    "    gui_state['current_idx'] = 0\n",
    "    update_summary()\n",
    "    update_detail_view()\n",
    "\n",
    "btn_run.on_click(on_run_click)\n",
    "\n",
    "\n",
    "def get_filtered_results():\n",
    "    \"\"\"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨\"\"\"\n",
    "    results = gui_state['results']\n",
    "    f = filter_dropdown.value\n",
    "    if f == 'ç•°å¸¸ã®ã¿':\n",
    "        return [(i,r) for i,r in enumerate(results) if 'ç•°å¸¸' in r['sae_judge'] or 'ç•°å¸¸' in r['dae_judge']]\n",
    "    elif f == 'æ­£å¸¸ã®ã¿':\n",
    "        return [(i,r) for i,r in enumerate(results) if r['sae_judge']=='æ­£å¸¸' and r['dae_judge']=='æ­£å¸¸']\n",
    "    elif f == 'åˆ¤å®šä¸ä¸€è‡´ã®ã¿':\n",
    "        return [(i,r) for i,r in enumerate(results) if r['sae_judge'] != r['dae_judge']]\n",
    "    return list(enumerate(results))\n",
    "\n",
    "\n",
    "def update_summary():\n",
    "    \"\"\"ã‚µãƒãƒªãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–°\"\"\"\n",
    "    with out_summary:\n",
    "        clear_output(wait=True)\n",
    "        results = gui_state['results']\n",
    "        if not results:\n",
    "            return\n",
    "        n = len(results)\n",
    "        n_sae_ng = sum(1 for r in results if 'ç•°å¸¸' in r['sae_judge'])\n",
    "        n_dae_ng = sum(1 for r in results if 'ç•°å¸¸' in r['dae_judge'])\n",
    "        n_disagree = sum(1 for r in results if r['sae_judge'] != r['dae_judge'])\n",
    "\n",
    "        html = '<div class=\"gui-card\">'\n",
    "        html += '<b>ğŸ“Š åˆ¤å®šã‚µãƒãƒªãƒ¼</b><br><br>'\n",
    "        html += f'<span class=\"gui-stat\">æ¤œæŸ»æ•°: <b>{n}</b>æš</span>'\n",
    "        html += f'<span class=\"gui-stat\">SAEç•°å¸¸: <b class=\"gui-ng\">{n_sae_ng}</b>/{n}</span>'\n",
    "        html += f'<span class=\"gui-stat\">DAEç•°å¸¸: <b class=\"gui-ng\">{n_dae_ng}</b>/{n}</span>'\n",
    "        if n_disagree:\n",
    "            html += f'<br><br><span class=\"gui-warn\">âš ï¸ {n_disagree}æšã§åˆ¤å®šä¸ä¸€è‡´</span>'\n",
    "        html += '</div>'\n",
    "\n",
    "        # ãƒ†ãƒ¼ãƒ–ãƒ«\n",
    "        html += '<table style=\"width:100%; border-collapse:collapse; font-size:13px; margin-top:8px;\">'\n",
    "        html += '<tr style=\"background:#334155; color:white;\">'\n",
    "        html += '<th style=\"padding:6px 8px; text-align:left;\">ãƒ•ã‚¡ã‚¤ãƒ«</th>'\n",
    "        html += '<th>SAEã‚¹ã‚³ã‚¢</th><th>SAE</th>'\n",
    "        html += '<th>DAEã‚¹ã‚³ã‚¢</th><th>DAE</th><th></th></tr>'\n",
    "        for i, r in enumerate(results):\n",
    "            bg = '#fff5f5' if ('ç•°å¸¸' in r['sae_judge'] or 'ç•°å¸¸' in r['dae_judge']) else '#f0fdf4'\n",
    "            sae_cls = 'gui-ng' if 'ç•°å¸¸' in r['sae_judge'] else 'gui-ok'\n",
    "            dae_cls = 'gui-ng' if 'ç•°å¸¸' in r['dae_judge'] else 'gui-ok'\n",
    "            warn = ' âš ï¸' if r['sae_judge'] != r['dae_judge'] else ''\n",
    "            html += f'<tr style=\"background:{bg}; border-bottom:1px solid #e2e8f0;\">'\n",
    "            html += f'<td style=\"padding:5px 8px;\">{r[\"name\"]}</td>'\n",
    "            html += f'<td style=\"text-align:center; font-family:monospace;\">{r[\"sae_score\"]:.6f}</td>'\n",
    "            html += f'<td style=\"text-align:center;\"><span class=\"{sae_cls}\">{r[\"sae_judge\"]}</span></td>'\n",
    "            html += f'<td style=\"text-align:center; font-family:monospace;\">{r[\"dae_score\"]:.6f}</td>'\n",
    "            html += f'<td style=\"text-align:center;\"><span class=\"{dae_cls}\">{r[\"dae_judge\"]}</span>{warn}</td>'\n",
    "            html += f'<td style=\"text-align:center;\">#{i+1}</td></tr>'\n",
    "        html += '</table>'\n",
    "        display(HTML(html))\n",
    "\n",
    "\n",
    "def update_detail_view():\n",
    "    \"\"\"å€‹åˆ¥ç”»åƒã®è©³ç´°ãƒ“ãƒ¥ãƒ¼æ›´æ–°\"\"\"\n",
    "    filtered = get_filtered_results()\n",
    "    if not filtered:\n",
    "        with out_detail:\n",
    "            clear_output()\n",
    "            print('è©²å½“ã™ã‚‹ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“')\n",
    "        return\n",
    "\n",
    "    idx = gui_state['current_idx'] % len(filtered)\n",
    "    orig_i, r = filtered[idx]\n",
    "    label_nav.value = f'<b>{idx+1} / {len(filtered)}</b>'\n",
    "\n",
    "    with out_detail:\n",
    "        clear_output(wait=True)\n",
    "        sae_cls = 'gui-ng' if 'ç•°å¸¸' in r['sae_judge'] else 'gui-ok'\n",
    "        dae_cls = 'gui-ng' if 'ç•°å¸¸' in r['dae_judge'] else 'gui-ok'\n",
    "        html = f'<div class=\"gui-card\">'\n",
    "        html += f'<b>ğŸ“„ {r[\"name\"]}</b> (#{orig_i+1})<br><br>'\n",
    "        html += f'<span class=\"gui-stat\">SAE: <span class=\"{sae_cls}\">{r[\"sae_judge\"]}</span> ({r[\"sae_score\"]:.6f})</span> '\n",
    "        html += f'<span class=\"gui-stat\">DAE: <span class=\"{dae_cls}\">{r[\"dae_judge\"]}</span> ({r[\"dae_score\"]:.6f})</span>'\n",
    "        if r['sae_judge'] != r['dae_judge']:\n",
    "            html += '<br><span class=\"gui-warn\">âš ï¸ ãƒ¢ãƒ‡ãƒ«é–“ã§åˆ¤å®šä¸ä¸€è‡´</span>'\n",
    "        html += '</div>'\n",
    "        display(HTML(html))\n",
    "\n",
    "    with out_heatmap:\n",
    "        clear_output(wait=True)\n",
    "        # Replaced by 2x4 layout below\n",
    "        # ä¸Šæ®µ: å…ƒç”»åƒ, å…¥åŠ›, SAEå†æ§‹æˆ, DAEå†æ§‹æˆ\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(18, 7))\n",
    "        top_panels = [\n",
    "            (r.get('original_rgb', r['input']), 'å…ƒç”»åƒ', None),\n",
    "            (r['input'], 'å…¥åŠ›(ã‚°ãƒ¬ãƒ¼)', 'gray'),\n",
    "            (r['sae_recon'], 'SAEå†æ§‹æˆ', 'gray'),\n",
    "            (r['dae_recon'], 'DAEå†æ§‹æˆ', 'gray'),\n",
    "        ]\n",
    "        for j, (p, t, cm) in enumerate(top_panels):\n",
    "            ax = axes[0, j]\n",
    "            if cm: ax.imshow(p, cmap=cm, vmin=0, vmax=1)\n",
    "            else:  ax.imshow(p)\n",
    "            ax.set_title(t, fontsize=10, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "\n",
    "        # ä¸‹æ®µ: SAEã‚¨ãƒ©ãƒ¼, DAEã‚¨ãƒ©ãƒ¼, SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤, DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤\n",
    "        sae_ov = create_overlay(r['input'], r['sae_error'], alpha=0.55)\n",
    "        dae_ov = create_overlay(r['input'], r['dae_error'], alpha=0.55)\n",
    "        bot_panels = [\n",
    "            (r['sae_error'], 'SAEã‚¨ãƒ©ãƒ¼', True),\n",
    "            (r['dae_error'], 'DAEã‚¨ãƒ©ãƒ¼', True),\n",
    "            (sae_ov, 'SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', False),\n",
    "            (dae_ov, 'DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', False),\n",
    "        ]\n",
    "        for j, (p, t, use_cmap) in enumerate(bot_panels):\n",
    "            ax = axes[1, j]\n",
    "            if use_cmap:\n",
    "                vmax = max(p.max(), 0.001)\n",
    "                im = ax.imshow(p, cmap=INSPECTION_CMAP, vmin=0, vmax=vmax)\n",
    "                cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "                cbar.ax.tick_params(labelsize=6)\n",
    "            else:\n",
    "                ax.imshow(p)\n",
    "            ax.set_title(t, fontsize=10, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def on_prev(btn):\n",
    "    filtered = get_filtered_results()\n",
    "    if filtered:\n",
    "        gui_state['current_idx'] = (gui_state['current_idx'] - 1) % len(filtered)\n",
    "        update_detail_view()\n",
    "\n",
    "def on_next(btn):\n",
    "    filtered = get_filtered_results()\n",
    "    if filtered:\n",
    "        gui_state['current_idx'] = (gui_state['current_idx'] + 1) % len(filtered)\n",
    "        update_detail_view()\n",
    "\n",
    "btn_prev.on_click(on_prev)\n",
    "btn_next.on_click(on_next)\n",
    "\n",
    "\n",
    "def on_filter_change(change):\n",
    "    gui_state['current_idx'] = 0\n",
    "    update_detail_view()\n",
    "\n",
    "filter_dropdown.observe(on_filter_change, names='value')\n",
    "\n",
    "\n",
    "def on_export_csv(btn):\n",
    "    \"\"\"çµæœã‚’CSVã§ä¿å­˜\"\"\"\n",
    "    if not gui_state['results']:\n",
    "        return\n",
    "    import csv\n",
    "    csv_path = SAVE_DIR / 'test_results.csv'\n",
    "    with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(['ãƒ•ã‚¡ã‚¤ãƒ«å','SAEã‚¹ã‚³ã‚¢','SAEåˆ¤å®š','DAEã‚¹ã‚³ã‚¢','DAEåˆ¤å®š','ä¸ä¸€è‡´'])\n",
    "        for r in gui_state['results']:\n",
    "            w.writerow([\n",
    "                r['name'], f'{r[\"sae_score\"]:.6f}', r['sae_judge'],\n",
    "                f'{r[\"dae_score\"]:.6f}', r['dae_judge'],\n",
    "                'âš ' if r['sae_judge']!=r['dae_judge'] else '',\n",
    "            ])\n",
    "    with out_upload_status:\n",
    "        print(f'\\nğŸ’¾ CSVä¿å­˜å®Œäº†: {csv_path}')\n",
    "    # Colabè‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "    try:\n",
    "        from google.colab import files as colab_files\n",
    "        colab_files.download(str(csv_path))\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "btn_export.on_click(on_export_csv)\n",
    "\n",
    "\n",
    "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "# GUIãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆçµ„ã¿ç«‹ã¦\n",
    "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "header = widgets.HTML('<div class=\"gui-header\">ğŸ”¬ å¤–è¦³æ¤œæŸ»AI â€” ãƒ†ã‚¹ãƒˆç”»åƒãƒ¬ãƒ“ãƒ¥ãƒ¼</div>')\n",
    "\n",
    "upload_section = widgets.VBox([\n",
    "    widgets.HTML('<b>â‘  ç”»åƒã‚’æº–å‚™</b>'),\n",
    "    widgets.HBox([file_uploader, btn_synthetic]),\n",
    "    out_upload_status,\n",
    "])\n",
    "\n",
    "threshold_section = widgets.VBox([\n",
    "    widgets.HTML('<b>â‘¡ é–¾å€¤è¨­å®š</b>'),\n",
    "    sae_thr_slider,\n",
    "    dae_thr_slider,\n",
    "    widgets.HBox([btn_run, btn_export]),\n",
    "])\n",
    "\n",
    "nav_section = widgets.HBox(\n",
    "    [btn_prev, label_nav, btn_next, filter_dropdown],\n",
    "    layout=widgets.Layout(align_items='center', gap='12px'),\n",
    ")\n",
    "\n",
    "review_section = widgets.VBox([\n",
    "    widgets.HTML('<b>â‘¢ çµæœãƒ¬ãƒ“ãƒ¥ãƒ¼</b>'),\n",
    "    out_summary,\n",
    "    widgets.HTML('<hr>'),\n",
    "    widgets.HTML('<b>â‘£ å€‹åˆ¥ç”»åƒè©³ç´°</b>'),\n",
    "    nav_section,\n",
    "    out_detail,\n",
    "    out_heatmap,\n",
    "])\n",
    "\n",
    "gui = widgets.VBox([\n",
    "    header,\n",
    "    upload_section,\n",
    "    widgets.HTML('<hr>'),\n",
    "    threshold_section,\n",
    "    widgets.HTML('<hr>'),\n",
    "    review_section,\n",
    "], layout=widgets.Layout(max_width='900px'))\n",
    "\n",
    "display(gui)\n",
    "print('\\nğŸ’¡ æ“ä½œæ‰‹é †: â‘ ç”»åƒã‚’é¸æŠ â†’ â‘¡é–¾å€¤ã‚’èª¿æ•´ â†’ â–¶æ¨è«–å®Ÿè¡Œ â†’ â‘¢çµæœã‚’ç¢ºèª â†’ â—€â–¶ã§ç”»åƒã‚’åˆ‡æ›¿')"
   ]
  }
 ]
}