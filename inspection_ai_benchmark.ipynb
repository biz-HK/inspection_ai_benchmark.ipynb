{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biz-HK/inspection_ai_benchmark.ipynb/blob/main/inspection_ai_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xogUH5NUOEx9"
      },
      "source": [
        "# ğŸ”¬ å¤–è¦³æ¤œæŸ»AI ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯\n",
        "## Sparse Autoencoder vs Deep Autoencoder æ¯”è¼ƒæ¤œè¨¼\n",
        "\n",
        "| é …ç›® | å†…å®¹ |\n",
        "|------|------|\n",
        "| **ç›®çš„** | ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®ç•°å¸¸æ¤œçŸ¥æ€§èƒ½ã‚’åŒä¸€æ¡ä»¶ã§æ¯”è¼ƒ |\n",
        "| **ç’°å¢ƒ** | Google Colab (T4 GPU) / Windows (CPU/CUDA) / Mac (MPS) |\n",
        "| **ãƒ‡ãƒ¼ã‚¿** | åˆæˆãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿å·®ã—æ›¿ãˆå¯èƒ½ï¼‰ |\n",
        "| **è©•ä¾¡æŒ‡æ¨™** | AUC-ROC, F1, FPR@95TPR, æ¨è«–é€Ÿåº¦, ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º |\n",
        "\n",
        "---\n",
        "### å®Ÿè¡Œæ‰‹é †\n",
        "1. ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€â†’ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ã€â†’ **T4 GPU** ã‚’é¸æŠ\n",
        "2. ä¸Šã‹ã‚‰é †ã«ã‚»ãƒ«ã‚’å®Ÿè¡Œï¼ˆ`Shift+Enter`ï¼‰\n",
        "3. çµæœã¯è‡ªå‹•çš„ã«Google Driveã«ä¿å­˜ã•ã‚Œã¾ã™"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Cwws86YOEx-"
      },
      "source": [
        "## 0. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf4199AAOEx_"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆColabã«ãƒ—ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã®ã‚‚ã®ãŒå¤šã„ï¼‰â”€â”€\n",
        "!pip install -q scikit-learn matplotlib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from typing import Tuple, Dict, List\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# â”€â”€ ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•æ¤œå‡º â”€â”€\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "    print(f'âœ… GPU: {torch.cuda.get_device_name(0)}')\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    DEVICE = torch.device('mps')\n",
        "    print('âœ… Apple Silicon MPS')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "    print('âš ï¸ CPU modeï¼ˆGPUãªã—ï¼‰')\n",
        "\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'Device: {DEVICE}')\n",
        "\n",
        "# â”€â”€ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè‡ªå‹•è¨­å®š â”€â”€\n",
        "import matplotlib.font_manager as fm\n",
        "import platform as _pf\n",
        "\n",
        "def setup_japanese_font():\n",
        "    _sys = _pf.system()\n",
        "    candidates = {\n",
        "        'Windows': ['Yu Gothic', 'MS Gothic', 'Meiryo', 'BIZ UDGothic'],\n",
        "        'Darwin':  ['Hiragino Sans', 'Hiragino Kaku Gothic Pro'],\n",
        "    }.get(_sys, ['Noto Sans CJK JP', 'IPAGothic', 'TakaoPGothic'])\n",
        "    available = {f.name for f in fm.fontManager.ttflist}\n",
        "    for fn in candidates:\n",
        "        if fn in available:\n",
        "            matplotlib.rcParams['font.family'] = fn\n",
        "            break\n",
        "    else:\n",
        "        if _sys == 'Linux':\n",
        "            os.system('apt-get install -y fonts-ipafont-gothic > /dev/null 2>&1')\n",
        "            try:\n",
        "                fm.fontManager.addfont('/usr/share/fonts/opentype/ipafont-gothic/ipag.ttf')\n",
        "                matplotlib.rcParams['font.family'] = 'IPAGothic'\n",
        "            except: pass\n",
        "        matplotlib.rcParams['font.sans-serif'] = candidates + ['DejaVu Sans']\n",
        "    matplotlib.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "setup_japanese_font()\n",
        "\n",
        "# â”€â”€ ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ï¼ˆé’â†’é»„â†’èµ¤ï¼‰â”€â”€\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "INSPECTION_CMAP = LinearSegmentedColormap.from_list(\n",
        "    'inspection_heatmap',\n",
        "    [(0.0, '#1a237e'), (0.15, '#1565c0'), (0.35, '#00bcd4'),\n",
        "     (0.50, '#ffeb3b'), (0.70, '#ff9800'), (0.85, '#f44336'),\n",
        "     (1.0, '#b71c1c')],\n",
        "    N=256,\n",
        ")\n",
        "\n",
        "def create_overlay(base_img, error_map, alpha=0.5, cmap=None):\n",
        "    \"\"\"å…ƒç”»åƒã«ã‚¨ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤åˆæˆ\"\"\"\n",
        "    if cmap is None: cmap = INSPECTION_CMAP\n",
        "    if base_img.ndim == 2:\n",
        "        base_rgb = np.stack([base_img]*3, axis=-1)\n",
        "    else:\n",
        "        base_rgb = base_img[:, :, :3]\n",
        "    emax = error_map.max()\n",
        "    error_norm = error_map / emax if emax > 0 else error_map\n",
        "    heat_rgba = cmap(error_norm)[:, :, :3]\n",
        "    return np.clip(base_rgb * (1-alpha) + heat_rgba * alpha, 0, 1)\n",
        "\n",
        "print('âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ + ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—è¨­å®šå®Œäº†')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jBKUWErOEx_"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Google Drive ãƒã‚¦ãƒ³ãƒˆï¼ˆçµæœä¿å­˜ç”¨ãƒ»ä»»æ„ï¼‰â”€â”€\n",
        "SAVE_TO_DRIVE = True  # Falseã«ã™ã‚‹ã¨ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ã®ã¿\n",
        "\n",
        "if SAVE_TO_DRIVE:\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        SAVE_DIR = Path('/content/drive/MyDrive/inspection_ai_results')\n",
        "        SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "        print(f'âœ… ä¿å­˜å…ˆ: {SAVE_DIR}')\n",
        "    except ImportError:\n",
        "        # Windows/Mac ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚\n",
        "        SAVE_DIR = Path('./results')\n",
        "        SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "        print(f'âœ… ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜: {SAVE_DIR}')\n",
        "else:\n",
        "    SAVE_DIR = Path('./results')\n",
        "    SAVE_DIR.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpZiaRJtOEx_"
      },
      "source": [
        "## 1. ãƒ¢ãƒ‡ãƒ«å®šç¾©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6oiPXMDOEyA"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Sparse Autoencoder (SAE)\n",
        "# L1æ­£å‰‡åŒ–ã§æ½œåœ¨ç©ºé–“ã‚’ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "class SparseAutoencoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Sparse Autoencoder\n",
        "    - è»½é‡ãª2å±¤Convæ§‹æˆ\n",
        "    - L1æ­£å‰‡åŒ–ã§å°‘æ•°ã®ç‰¹å¾´é‡ã«é›†ä¸­\n",
        "    - ã‚¨ãƒƒã‚¸å±•é–‹ã«é©ã—ãŸå°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=1, latent_dim=64):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32), nn.ReLU(True),\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64), nn.ReLU(True),\n",
        "        )\n",
        "        self.fc_encode = nn.Linear(64 * 32 * 32, latent_dim)\n",
        "        self.fc_decode = nn.Linear(latent_dim, 64 * 32 * 32)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32), nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, in_channels, 4, stride=2, padding=1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        return self.fc_encode(h.view(h.size(0), -1))\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = self.fc_decode(z).view(z.size(0), 64, 32, 32)\n",
        "        return self.decoder(h)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encode(x)\n",
        "        return self.decode(z), z\n",
        "\n",
        "\n",
        "class SparseAELoss(nn.Module):\n",
        "    \"\"\"MSE + L1ã‚¹ãƒ‘ãƒ¼ã‚¹æ­£å‰‡åŒ–\"\"\"\n",
        "    def __init__(self, l1_weight=1e-3):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.l1_weight = l1_weight\n",
        "\n",
        "    def forward(self, x, x_recon, z):\n",
        "        recon = self.mse(x_recon, x)\n",
        "        sparse = self.l1_weight * torch.mean(torch.abs(z))\n",
        "        return recon + sparse, {'recon': recon.item(), 'sparse': sparse.item()}\n",
        "\n",
        "\n",
        "print('âœ… Sparse Autoencoder å®šç¾©å®Œäº†')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOhP-2LfOEyA"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Deep Autoencoder (DAE)\n",
        "# å¤šå±¤Conv + SSIMæå¤±ã«ã‚ˆã‚‹é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "class DeepAutoencoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Deep Autoencoder\n",
        "    - 4å±¤Convæ§‹æˆ\n",
        "    - é«˜ã„è¡¨ç¾åŠ›ã§å¾®ç´°ãªç•°å¸¸ã‚‚æ¤œå‡º\n",
        "    - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯SAEã®10å€ä»¥ä¸Š\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=1, latent_dim=128):\n",
        "        super().__init__()\n",
        "        self.enc1 = self._conv(in_channels, 32)\n",
        "        self.enc2 = self._conv(32, 64)\n",
        "        self.enc3 = self._conv(64, 128)\n",
        "        self.enc4 = self._conv(128, 256)\n",
        "        self.fc_encode = nn.Linear(256 * 8 * 8, latent_dim)\n",
        "        self.fc_decode = nn.Linear(latent_dim, 256 * 8 * 8)\n",
        "        self.dec4 = self._deconv(256, 128)\n",
        "        self.dec3 = self._deconv(128, 64)\n",
        "        self.dec2 = self._deconv(64, 32)\n",
        "        self.dec1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, in_channels, 4, stride=2, padding=1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def _conv(inc, outc):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(inc, outc, 4, 2, 1), nn.BatchNorm2d(outc), nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(outc, outc, 3, 1, 1), nn.BatchNorm2d(outc), nn.LeakyReLU(0.2, True),\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def _deconv(inc, outc):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(inc, outc, 4, 2, 1), nn.BatchNorm2d(outc), nn.ReLU(True),\n",
        "            nn.Conv2d(outc, outc, 3, 1, 1), nn.BatchNorm2d(outc), nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.enc4(self.enc3(self.enc2(self.enc1(x))))\n",
        "        return self.fc_encode(h.view(h.size(0), -1))\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = self.fc_decode(z).view(z.size(0), 256, 8, 8)\n",
        "        return self.dec1(self.dec2(self.dec3(self.dec4(h))))\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encode(x)\n",
        "        return self.decode(z), z\n",
        "\n",
        "\n",
        "class DeepAELoss(nn.Module):\n",
        "    \"\"\"MSE + ç°¡æ˜“SSIMæ§‹é€ æå¤±\"\"\"\n",
        "    def __init__(self, ssim_weight=0.1):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.ssim_weight = ssim_weight\n",
        "\n",
        "    def _ssim_approx(self, x, y, ws=11):\n",
        "        C1, C2 = 0.01**2, 0.03**2\n",
        "        pad = ws // 2\n",
        "        mu_x = nn.functional.avg_pool2d(x, ws, 1, pad)\n",
        "        mu_y = nn.functional.avg_pool2d(y, ws, 1, pad)\n",
        "        s_x = nn.functional.avg_pool2d(x**2, ws, 1, pad) - mu_x**2\n",
        "        s_y = nn.functional.avg_pool2d(y**2, ws, 1, pad) - mu_y**2\n",
        "        s_xy = nn.functional.avg_pool2d(x*y, ws, 1, pad) - mu_x*mu_y\n",
        "        return ((2*mu_x*mu_y+C1)*(2*s_xy+C2) / ((mu_x**2+mu_y**2+C1)*(s_x+s_y+C2))).mean()\n",
        "\n",
        "    def forward(self, x, x_recon, z=None):\n",
        "        recon = self.mse(x_recon, x)\n",
        "        ssim = 1.0 - self._ssim_approx(x, x_recon)\n",
        "        return recon + self.ssim_weight * ssim, {'recon': recon.item(), 'ssim': ssim.item()}\n",
        "\n",
        "\n",
        "print('âœ… Deep Autoencoder å®šç¾©å®Œäº†')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWzO5sCTOEyA"
      },
      "source": [
        "## 2. åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VUfll6EOEyB"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# åˆæˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
        "# æ­£å¸¸å“ + 4ç¨®é¡ã®æ¬ é™¥ï¼ˆscratch/stain/missing/discolorï¼‰\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def generate_normal_image(size=128, seed=None):\n",
        "    \"\"\"æ­£å¸¸å“ç”»åƒï¼ˆå‡ä¸€ãƒ†ã‚¯ã‚¹ãƒãƒ£ + æ ¼å­ãƒ‘ã‚¿ãƒ¼ãƒ³ + å††å½¢ç‰¹å¾´ï¼‰\"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    img = np.ones((size, size), dtype=np.float32) * 0.6\n",
        "    img += np.random.normal(0, 0.02, (size, size)).astype(np.float32)\n",
        "    for i in range(0, size, 16):\n",
        "        img[i:i+1, :] += 0.05\n",
        "        img[:, i:i+1] += 0.05\n",
        "    y, x = np.ogrid[-size//2:size//2, -size//2:size//2]\n",
        "    r = np.sqrt(x*x + y*y).astype(np.float32)\n",
        "    mask = (r < size * 0.35).astype(np.float32)\n",
        "    img = img * (1 - mask * 0.1) + mask * 0.05\n",
        "    return np.clip(img, 0, 1)\n",
        "\n",
        "\n",
        "def add_defect(img, defect_type='scratch', seed=None):\n",
        "    \"\"\"æ¬ é™¥ã‚’è¿½åŠ  â†’ (ç•°å¸¸ç”»åƒ, ãƒã‚¹ã‚¯)\"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    size = img.shape[0]\n",
        "    out = img.copy()\n",
        "    mask = np.zeros_like(img)\n",
        "\n",
        "    if defect_type == 'scratch':\n",
        "        ys, xs = np.random.randint(20, size-20), np.random.randint(20, size-40)\n",
        "        length, angle = np.random.randint(30, 60), np.random.uniform(-0.3, 0.3)\n",
        "        for i in range(length):\n",
        "            yi, xi = int(ys + i*np.sin(angle)), int(xs + i*np.cos(angle))\n",
        "            if 0 <= yi < size and 0 <= xi < size:\n",
        "                w = np.random.randint(1, 3)\n",
        "                out[max(0,yi-w):yi+w, max(0,xi-w):xi+w] -= 0.3\n",
        "                mask[max(0,yi-w):yi+w, max(0,xi-w):xi+w] = 1.0\n",
        "    elif defect_type == 'stain':\n",
        "        cy, cx = np.random.randint(30, size-30, 2)\n",
        "        rad = np.random.randint(8, 20)\n",
        "        yy, xx = np.ogrid[:size, :size]\n",
        "        blob = np.exp(-((xx-cx)**2 + (yy-cy)**2) / (2*rad**2))\n",
        "        out -= blob.astype(np.float32) * 0.25\n",
        "        mask = (blob > 0.3).astype(np.float32)\n",
        "    elif defect_type == 'missing':\n",
        "        cy, cx = np.random.randint(30, size-30, 2)\n",
        "        rad = np.random.randint(5, 15)\n",
        "        yy, xx = np.ogrid[:size, :size]\n",
        "        hole = (np.sqrt((xx-cx)**2 + (yy-cy)**2) < rad).astype(np.float32)\n",
        "        out = out * (1 - hole) + hole * 0.1\n",
        "        mask = hole\n",
        "    elif defect_type == 'discolor':\n",
        "        y1, x1 = np.random.randint(10, size-40), np.random.randint(10, size-40)\n",
        "        h, w = np.random.randint(15, 35), np.random.randint(15, 35)\n",
        "        out[y1:y1+h, x1:x1+w] += 0.15\n",
        "        mask[y1:y1+h, x1:x1+w] = 1.0\n",
        "\n",
        "    return np.clip(out, 0, 1), mask\n",
        "\n",
        "\n",
        "class InspectionDataset(Dataset):\n",
        "    def __init__(self, n_normal=200, n_anomaly=50, image_size=128, include_anomaly=True):\n",
        "        self.images, self.labels, self.masks, self.types = [], [], [], []\n",
        "        for i in range(n_normal):\n",
        "            img = generate_normal_image(image_size, seed=i)\n",
        "            self.images.append(img); self.labels.append(0)\n",
        "            self.masks.append(np.zeros_like(img)); self.types.append('normal')\n",
        "        if include_anomaly:\n",
        "            dtypes = ['scratch', 'stain', 'missing', 'discolor']\n",
        "            for i in range(n_anomaly):\n",
        "                base = generate_normal_image(image_size, seed=1000+i)\n",
        "                dt = dtypes[i % 4]\n",
        "                defect, m = add_defect(base, dt, seed=2000+i)\n",
        "                self.images.append(defect); self.labels.append(1)\n",
        "                self.masks.append(m); self.types.append(dt)\n",
        "\n",
        "    def __len__(self): return len(self.images)\n",
        "    def __getitem__(self, idx):\n",
        "        return (torch.FloatTensor(self.images[idx]).unsqueeze(0),\n",
        "                self.labels[idx],\n",
        "                torch.FloatTensor(self.masks[idx]).unsqueeze(0))\n",
        "\n",
        "\n",
        "print('âœ… ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®šç¾©å®Œäº†')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "992LukgDOEyB"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®ç¢ºèª â”€â”€\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "fig.suptitle('åˆæˆãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«', fontsize=16, fontweight='bold')\n",
        "\n",
        "for i in range(5):\n",
        "    img = generate_normal_image(128, seed=i)\n",
        "    axes[0, i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
        "    axes[0, i].set_title(f'æ­£å¸¸å“ #{i+1}', fontsize=10)\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "for i, dt in enumerate(['scratch', 'stain', 'missing', 'discolor', 'scratch']):\n",
        "    base = generate_normal_image(128, seed=100+i)\n",
        "    defect, _ = add_defect(base, dt, seed=200+i)\n",
        "    axes[1, i].imshow(defect, cmap='gray', vmin=0, vmax=1)\n",
        "    axes[1, i].set_title(f'ç•°å¸¸: {dt}', fontsize=10, color='red')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(SAVE_DIR / 'sample_data.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(f'ğŸ’¾ ä¿å­˜: {SAVE_DIR}/sample_data.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qL8AoRWOEyC"
      },
      "source": [
        "## 3. æ¤œè¨¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n",
        "\n",
        "ã“ã“ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ã¦ã€ç•°ãªã‚‹æ¡ä»¶ã§ã®æ¯”è¼ƒãŒå¯èƒ½ã§ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct-78-vwOEyC"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  ğŸ›ï¸ æ¤œè¨¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã“ã“ã‚’å¤‰ãˆã¦å®Ÿé¨“ï¼‰       â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "CONFIG = {\n",
        "    # ãƒ‡ãƒ¼ã‚¿è¨­å®š\n",
        "    'n_train': 200,           # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°ï¼ˆæ­£å¸¸å“ï¼‰\n",
        "    'n_test_normal': 50,      # ãƒ†ã‚¹ãƒˆæ­£å¸¸å“æ•°\n",
        "    'n_test_anomaly': 50,     # ãƒ†ã‚¹ãƒˆç•°å¸¸å“æ•°\n",
        "    'image_size': 128,        # ç”»åƒã‚µã‚¤ã‚º (64 or 128)\n",
        "    'batch_size': 16,\n",
        "\n",
        "    # Sparse AE è¨­å®š\n",
        "    'sae_latent_dim': 64,     # æ½œåœ¨æ¬¡å…ƒ\n",
        "    'sae_l1_weight': 1e-3,    # L1æ­£å‰‡åŒ–å¼·åº¦ (Î»)\n",
        "\n",
        "    # Deep AE è¨­å®š\n",
        "    'dae_latent_dim': 128,    # æ½œåœ¨æ¬¡å…ƒ\n",
        "    'dae_ssim_weight': 0.1,   # SSIMæå¤±é‡ã¿\n",
        "\n",
        "    # å­¦ç¿’è¨­å®š\n",
        "    'n_epochs': 30,\n",
        "    'learning_rate': 1e-3,\n",
        "}\n",
        "\n",
        "print('ğŸ“‹ æ¤œè¨¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:')\n",
        "for k, v in CONFIG.items():\n",
        "    print(f'  {k}: {v}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvBdeRnzOEyC"
      },
      "source": [
        "## 4. ãƒ‡ãƒ¼ã‚¿æº–å‚™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYg2GyzpOEyD"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ DataLoaderä½œæˆ â”€â”€\n",
        "train_dataset = InspectionDataset(\n",
        "    n_normal=CONFIG['n_train'], n_anomaly=0,\n",
        "    image_size=CONFIG['image_size'], include_anomaly=False,\n",
        ")\n",
        "test_dataset = InspectionDataset(\n",
        "    n_normal=CONFIG['n_test_normal'], n_anomaly=CONFIG['n_test_anomaly'],\n",
        "    image_size=CONFIG['image_size'], include_anomaly=True,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
        "\n",
        "print(f'âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(train_dataset)}æšï¼ˆæ­£å¸¸å“ã®ã¿ï¼‰')\n",
        "print(f'âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_dataset)}æšï¼ˆæ­£å¸¸{CONFIG[\"n_test_normal\"]} + ç•°å¸¸{CONFIG[\"n_test_anomaly\"]}ï¼‰')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hglnzvh9OEyD"
      },
      "source": [
        "## 5. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLCxIf3IOEyD"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ å­¦ç¿’é–¢æ•° â”€â”€\n",
        "def train_model(model, criterion, loader, config, model_name):\n",
        "    \"\"\"ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰\"\"\"\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['n_epochs'])\n",
        "    model.to(DEVICE)\n",
        "    model.train()\n",
        "    losses = []\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    for epoch in range(config['n_epochs']):\n",
        "        ep_loss, nb = 0.0, 0\n",
        "        for imgs, _, _ in loader:\n",
        "            imgs = imgs.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            recon, z = model(imgs)\n",
        "            loss, _ = criterion(imgs, recon, z)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            ep_loss += loss.item(); nb += 1\n",
        "        scheduler.step()\n",
        "        avg = ep_loss / max(nb, 1)\n",
        "        losses.append(avg)\n",
        "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "            print(f'  {model_name} Epoch {epoch+1:3d}/{config[\"n_epochs\"]} | Loss: {avg:.6f}')\n",
        "\n",
        "    train_time = time.perf_counter() - t0\n",
        "    print(f'  âœ… {model_name} å­¦ç¿’å®Œäº†: {train_time:.1f}ç§’')\n",
        "    return losses, train_time\n",
        "\n",
        "\n",
        "# â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â”€â”€\n",
        "def count_params(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "def model_size_mb(model):\n",
        "    ps = sum(p.nelement() * p.element_size() for p in model.parameters())\n",
        "    bs = sum(b.nelement() * b.element_size() for b in model.buffers())\n",
        "    return (ps + bs) / (1024 * 1024)\n",
        "\n",
        "def sparsity(z, thr=0.01):\n",
        "    return (z.abs() < thr).float().mean().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tcKNpghOEyD"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– â”€â”€\n",
        "sae = SparseAutoencoder(in_channels=1, latent_dim=CONFIG['sae_latent_dim'])\n",
        "dae = DeepAutoencoder(in_channels=1, latent_dim=CONFIG['dae_latent_dim'])\n",
        "sae_criterion = SparseAELoss(l1_weight=CONFIG['sae_l1_weight'])\n",
        "dae_criterion = DeepAELoss(ssim_weight=CONFIG['dae_ssim_weight'])\n",
        "\n",
        "print('â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”')\n",
        "print(f'â”‚ SAE: {count_params(sae):>10,} params | {model_size_mb(sae):>6.2f} MB â”‚')\n",
        "print(f'â”‚ DAE: {count_params(dae):>10,} params | {model_size_mb(dae):>6.2f} MB â”‚')\n",
        "print('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNB1VIq3OEyD"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸ‹ï¸ Sparse AE å­¦ç¿’\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "print('â”' * 50)\n",
        "print('ğŸ‹ï¸ Sparse Autoencoder å­¦ç¿’é–‹å§‹')\n",
        "print('â”' * 50)\n",
        "sae_losses, sae_train_time = train_model(sae, sae_criterion, train_loader, CONFIG, 'SAE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xy0HWDDBOEyD"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸ‹ï¸ Deep AE å­¦ç¿’\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "print('â”' * 50)\n",
        "print('ğŸ‹ï¸ Deep Autoencoder å­¦ç¿’é–‹å§‹')\n",
        "print('â”' * 50)\n",
        "dae_losses, dae_train_time = train_model(dae, dae_criterion, train_loader, CONFIG, 'DAE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnkO-W8yOEyD"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ å­¦ç¿’æ›²ç·šæ¯”è¼ƒ â”€â”€\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "ax.plot(sae_losses, color='#22d3ee', linewidth=2, label=f'Sparse AE ({sae_train_time:.1f}s)')\n",
        "ax.plot(dae_losses, color='#f97316', linewidth=2, label=f'Deep AE ({dae_train_time:.1f}s)')\n",
        "ax.set_xlabel('Epoch'); ax.set_ylabel('Loss')\n",
        "ax.set_title('å­¦ç¿’æ›²ç·šæ¯”è¼ƒ', fontsize=14, fontweight='bold')\n",
        "ax.legend(); ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(SAVE_DIR / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_p3MJ12OEyE"
      },
      "source": [
        "## 6. è©•ä¾¡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnCEvEhROEyE"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®— â”€â”€\n",
        "def compute_scores(model, loader, device):\n",
        "    \"\"\"å…¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç•°å¸¸ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—\"\"\"\n",
        "    model.eval()\n",
        "    scores, labels, error_maps = [], [], []\n",
        "    total_time, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, lbl, _ in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            bs = imgs.size(0)\n",
        "            t0 = time.perf_counter()\n",
        "            recon, z = model(imgs)\n",
        "            if device.type == 'cuda': torch.cuda.synchronize()\n",
        "            total_time += time.perf_counter() - t0\n",
        "            n += bs\n",
        "            err = (imgs - recon) ** 2\n",
        "            scores.extend(err.mean(dim=(1,2,3)).cpu().numpy())\n",
        "            labels.extend(lbl.numpy())\n",
        "            error_maps.extend(err.squeeze(1).cpu().numpy())\n",
        "    return np.array(scores), np.array(labels), error_maps, (total_time/n)*1000\n",
        "\n",
        "\n",
        "def compute_metrics(scores, labels):\n",
        "    \"\"\"è©•ä¾¡æŒ‡æ¨™\"\"\"\n",
        "    m = {}\n",
        "    if len(np.unique(labels)) > 1:\n",
        "        m['auc_roc'] = roc_auc_score(labels, scores)\n",
        "        fpr, tpr, thr = roc_curve(labels, scores)\n",
        "        idx95 = np.argmin(np.abs(tpr - 0.95))\n",
        "        m['fpr_at_95tpr'] = fpr[idx95]\n",
        "        prec, rec, pthr = precision_recall_curve(labels, scores)\n",
        "        f1s = 2 * prec * rec / (prec + rec + 1e-8)\n",
        "        m['best_f1'] = f1s.max()\n",
        "        ns = scores[labels == 0]\n",
        "        thr3s = ns.mean() + 3 * ns.std()\n",
        "        m['f1_3sigma'] = f1_score(labels, (scores > thr3s).astype(int), zero_division=0)\n",
        "    m['normal_mean'] = scores[labels==0].mean()\n",
        "    m['normal_std'] = scores[labels==0].std()\n",
        "    m['anomaly_mean'] = scores[labels==1].mean()\n",
        "    m['anomaly_std'] = scores[labels==1].std()\n",
        "    return m\n",
        "\n",
        "\n",
        "print('ğŸ“Š ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—ä¸­...')\n",
        "sae_scores, sae_labels, sae_maps, sae_inf = compute_scores(sae, test_loader, DEVICE)\n",
        "dae_scores, dae_labels, dae_maps, dae_inf = compute_scores(dae, test_loader, DEVICE)\n",
        "sae_m = compute_metrics(sae_scores, sae_labels)\n",
        "dae_m = compute_metrics(dae_scores, dae_labels)\n",
        "print('âœ… å®Œäº†')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Yn3HSqzOEyE"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸ“Š å®šé‡è©•ä¾¡çµæœ\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print('\\n' + 'â•' * 65)\n",
        "print('  ğŸ“Š å®šé‡è©•ä¾¡çµæœ')\n",
        "print('â•' * 65)\n",
        "print(f'{\"æŒ‡æ¨™\":<20} {\"Sparse AE\":>15} {\"Deep AE\":>15}  {\"Winner\":>8}')\n",
        "print('â”€' * 65)\n",
        "\n",
        "comparisons = [\n",
        "    ('AUC-ROC',          sae_m.get('auc_roc',0),     dae_m.get('auc_roc',0),     'higher'),\n",
        "    ('Best F1',          sae_m.get('best_f1',0),     dae_m.get('best_f1',0),     'higher'),\n",
        "    ('F1 (3Ïƒé–¾å€¤)',      sae_m.get('f1_3sigma',0),   dae_m.get('f1_3sigma',0),   'higher'),\n",
        "    ('FPR@95TPR',        sae_m.get('fpr_at_95tpr',0),dae_m.get('fpr_at_95tpr',0),'lower'),\n",
        "    ('æ¨è«–é€Ÿåº¦ (ms)',    sae_inf,                     dae_inf,                     'lower'),\n",
        "    ('å­¦ç¿’æ™‚é–“ (s)',     sae_train_time,              dae_train_time,              'lower'),\n",
        "    ('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°',    count_params(sae),           count_params(dae),           'lower'),\n",
        "    ('ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º(MB)', model_size_mb(sae),          model_size_mb(dae),          'lower'),\n",
        "]\n",
        "\n",
        "for name, sv, dv, direction in comparisons:\n",
        "    if isinstance(sv, int):\n",
        "        sf, df = f'{sv:>15,}', f'{dv:>15,}'\n",
        "    else:\n",
        "        sf, df = f'{sv:>15.4f}', f'{dv:>15.4f}'\n",
        "    if direction == 'higher':\n",
        "        w = '  SAE âœ“' if sv > dv else '  DAE âœ“'\n",
        "    else:\n",
        "        w = '  SAE âœ“' if sv < dv else '  DAE âœ“'\n",
        "    print(f'{name:<20} {sf} {df} {w}')\n",
        "\n",
        "print('â•' * 65)\n",
        "\n",
        "# ç²¾åº¦å·®ã®è©•ä¾¡\n",
        "auc_diff = abs(sae_m.get('auc_roc',0) - dae_m.get('auc_roc',0))\n",
        "speed_ratio = dae_inf / max(sae_inf, 0.001)\n",
        "print(f'\\nğŸ“Œ AUC-ROCå·®: {auc_diff:.4f}  |  é€Ÿåº¦æ¯”: SAEãŒ{speed_ratio:.1f}å€é«˜é€Ÿ')\n",
        "if auc_diff < 0.05 and speed_ratio > 3:\n",
        "    print('ğŸ’¡ çµè«–: ç²¾åº¦å·®ãŒå°ã•ãé€Ÿåº¦å·®ãŒå¤§ãã„ â†’ ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒå®Ÿç”¨çš„')\n",
        "elif auc_diff > 0.1:\n",
        "    print('ğŸ’¡ çµè«–: ç²¾åº¦å·®ãŒå¤§ãã„ â†’ ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ¢ãƒ‡ãƒ«ã‚’æ¨å¥¨')\n",
        "else:\n",
        "    print('ğŸ’¡ çµè«–: ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚ã‚Š â†’ è£½é€ ãƒ©ã‚¤ãƒ³è¦ä»¶ã«å¿œã˜ã¦é¸æŠ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raAtgL2WOEyE"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ç•°å¸¸ã‚¹ã‚³ã‚¢åˆ†å¸ƒ â”€â”€\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for ax, scores, labels, title, color in [\n",
        "    (ax1, sae_scores, sae_labels, 'Sparse AE', '#22d3ee'),\n",
        "    (ax2, dae_scores, dae_labels, 'Deep AE', '#f97316'),\n",
        "]:\n",
        "    ns, ans = scores[labels==0], scores[labels==1]\n",
        "    ax.hist(ns, bins=30, alpha=0.7, color='#10b981', label='æ­£å¸¸', density=True)\n",
        "    ax.hist(ans, bins=30, alpha=0.7, color='#ef4444', label='ç•°å¸¸', density=True)\n",
        "    ax.axvline(ns.mean() + 3*ns.std(), color='white', ls='--', lw=1.5, label='3Ïƒé–¾å€¤')\n",
        "    ax.set_title(title, fontsize=13, fontweight='bold')\n",
        "    ax.set_xlabel('ç•°å¸¸ã‚¹ã‚³ã‚¢'); ax.legend()\n",
        "    ax.grid(alpha=0.2)\n",
        "\n",
        "plt.suptitle('ç•°å¸¸ã‚¹ã‚³ã‚¢åˆ†å¸ƒæ¯”è¼ƒ', fontsize=15, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(SAVE_DIR / 'score_distribution.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0z6DgUFOEyE"
      },
      "source": [
        "## 7. ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5PmJsHwOEyE"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ç•°å¸¸æ¤œçŸ¥ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æ¯”è¼ƒ â”€â”€\n",
        "all_imgs, all_labels_t, all_masks_t = [], [], []\n",
        "for imgs, lbl, msk in test_loader:\n",
        "    all_imgs.append(imgs); all_labels_t.append(lbl); all_masks_t.append(msk)\n",
        "all_imgs = torch.cat(all_imgs)\n",
        "all_labels = torch.cat(all_labels_t).numpy()\n",
        "all_masks = torch.cat(all_masks_t)\n",
        "\n",
        "anomaly_idx = np.where(all_labels == 1)[0]\n",
        "n_show = min(6, len(anomaly_idx))\n",
        "sel = anomaly_idx[:n_show]\n",
        "\n",
        "sae.eval(); dae.eval()\n",
        "n_cols = 7\n",
        "fig, axes = plt.subplots(n_show, n_cols, figsize=(n_cols*3, n_show*3))\n",
        "if n_show == 1: axes = axes.reshape(1, -1)\n",
        "\n",
        "col_titles = ['å…ƒç”»åƒ', 'çœŸå€¤ãƒã‚¹ã‚¯', 'SAEå†æ§‹æˆ', 'DAEå†æ§‹æˆ',\n",
        "              'SAEã‚¨ãƒ©ãƒ¼', 'DAEã‚¨ãƒ©ãƒ¼', 'SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤']\n",
        "for j, t in enumerate(col_titles):\n",
        "    axes[0, j].set_title(t, fontsize=10, fontweight='bold')\n",
        "\n",
        "for i, idx in enumerate(sel):\n",
        "    img = all_imgs[idx:idx+1].to(DEVICE)\n",
        "    mask = all_masks[idx].squeeze().numpy()\n",
        "    with torch.no_grad():\n",
        "        sr, _ = sae(img)\n",
        "        dr, _ = dae(img)\n",
        "    inp = all_imgs[idx].squeeze().numpy()\n",
        "    sr_np = sr.squeeze().cpu().numpy()\n",
        "    dr_np = dr.squeeze().cpu().numpy()\n",
        "    se = np.abs(inp - sr_np)\n",
        "    de = np.abs(inp - dr_np)\n",
        "    overlay = create_overlay(inp, se, alpha=0.55)\n",
        "\n",
        "    panels = [\n",
        "        (inp,     'gray', 1.0,  False),\n",
        "        (mask,    'Reds', 1.0,  False),\n",
        "        (sr_np,   'gray', 1.0,  False),\n",
        "        (dr_np,   'gray', 1.0,  False),\n",
        "        (se,      INSPECTION_CMAP, None, True),\n",
        "        (de,      INSPECTION_CMAP, None, True),\n",
        "        (overlay, None,   None, False),\n",
        "    ]\n",
        "    for j, (p, cm, vmax_f, add_cbar) in enumerate(panels):\n",
        "        ax = axes[i, j]\n",
        "        if cm is None:\n",
        "            ax.imshow(p)\n",
        "        elif vmax_f is not None:\n",
        "            ax.imshow(p, cmap=cm, vmin=0, vmax=vmax_f)\n",
        "        else:\n",
        "            vmax = max(p.max(), 0.001)\n",
        "            im = ax.imshow(p, cmap=cm, vmin=0, vmax=vmax)\n",
        "            if add_cbar:\n",
        "                cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "                cbar.ax.tick_params(labelsize=6)\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.suptitle('ç•°å¸¸æ¤œçŸ¥ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æ¯”è¼ƒ', fontsize=15, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(SAVE_DIR / 'heatmap_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeZm1U9DOEyE"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ æ½œåœ¨ç©ºé–“ã®ã‚¹ãƒ‘ãƒ¼ã‚¹åº¦å¯è¦–åŒ– â”€â”€\n",
        "sample = all_imgs[:1].to(DEVICE)\n",
        "with torch.no_grad():\n",
        "    _, sz = sae(sample)\n",
        "    _, dz = dae(sample)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 3.5))\n",
        "\n",
        "szn = sz.cpu().numpy().flatten()\n",
        "dzn = dz.cpu().numpy().flatten()\n",
        "\n",
        "ax1.bar(range(len(szn)), np.abs(szn), color='#22d3ee', alpha=0.8, width=1.0)\n",
        "ax1.set_title(f'SAE æ½œåœ¨è¡¨ç¾ (ã‚¹ãƒ‘ãƒ¼ã‚¹åº¦: {sparsity(sz):.1%})', fontweight='bold')\n",
        "ax1.set_xlabel('ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³Index'); ax1.set_ylabel('|æ´»æ€§åŒ–å€¤|')\n",
        "\n",
        "ax2.bar(range(len(dzn)), np.abs(dzn), color='#f97316', alpha=0.8, width=1.0)\n",
        "ax2.set_title(f'DAE æ½œåœ¨è¡¨ç¾ (ã‚¹ãƒ‘ãƒ¼ã‚¹åº¦: {sparsity(dz):.1%})', fontweight='bold')\n",
        "ax2.set_xlabel('ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³Index'); ax2.set_ylabel('|æ´»æ€§åŒ–å€¤|')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(SAVE_DIR / 'sparsity_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(f'ğŸ’¡ SAEã¯å°‘æ•°ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã ã‘ãŒå¼·ãæ´»æ€§åŒ– â†’ é‡è¦ãªç‰¹å¾´ã«é›†ä¸­')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-ANx5rMOEyE"
      },
      "source": [
        "## 8. ãƒ¢ãƒ‡ãƒ«ä¿å­˜ & ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJC9zQJiOEyE"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ â”€â”€\n",
        "torch.save(sae.state_dict(), SAVE_DIR / 'sparse_ae.pth')\n",
        "torch.save(dae.state_dict(), SAVE_DIR / 'deep_ae.pth')\n",
        "print(f'ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {SAVE_DIR}')\n",
        "\n",
        "# â”€â”€ ONNX ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆã‚¨ãƒƒã‚¸å±•é–‹ç”¨ï¼‰â”€â”€\n",
        "try:\n",
        "    dummy = torch.randn(1, 1, CONFIG['image_size'], CONFIG['image_size']).to('cpu')\n",
        "    sae_cpu = SparseAutoencoder(latent_dim=CONFIG['sae_latent_dim']).cpu()\n",
        "    sae_cpu.load_state_dict(sae.cpu().state_dict())\n",
        "    sae_cpu.eval()\n",
        "    torch.onnx.export(\n",
        "        sae_cpu, dummy,\n",
        "        str(SAVE_DIR / 'sparse_ae.onnx'),\n",
        "        input_names=['input'], output_names=['reconstruction', 'latent'],\n",
        "        dynamic_axes={'input': {0: 'batch'}, 'reconstruction': {0: 'batch'}},\n",
        "        opset_version=14,\n",
        "    )\n",
        "    onnx_size = os.path.getsize(SAVE_DIR / 'sparse_ae.onnx') / (1024*1024)\n",
        "    print(f'âœ… ONNX ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: sparse_ae.onnx ({onnx_size:.2f} MB)')\n",
        "    sae.to(DEVICE)  # GPUã«æˆ»ã™\n",
        "except Exception as e:\n",
        "    print(f'âš ï¸ ONNX ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¹ã‚­ãƒƒãƒ—: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV9QRjr0OEyE"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ è©•ä¾¡çµæœã‚’JSONã§ä¿å­˜ â”€â”€\n",
        "results = {\n",
        "    'config': CONFIG,\n",
        "    'device': str(DEVICE),\n",
        "    'sparse_ae': {\n",
        "        'params': count_params(sae),\n",
        "        'size_mb': round(model_size_mb(sae), 3),\n",
        "        'train_time_s': round(sae_train_time, 2),\n",
        "        'inference_ms': round(sae_inf, 3),\n",
        "        'metrics': {k: round(float(v), 5) for k, v in sae_m.items()},\n",
        "    },\n",
        "    'deep_ae': {\n",
        "        'params': count_params(dae),\n",
        "        'size_mb': round(model_size_mb(dae), 3),\n",
        "        'train_time_s': round(dae_train_time, 2),\n",
        "        'inference_ms': round(dae_inf, 3),\n",
        "        'metrics': {k: round(float(v), 5) for k, v in dae_m.items()},\n",
        "    },\n",
        "}\n",
        "\n",
        "with open(SAVE_DIR / 'benchmark_results.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f'ğŸ’¾ çµæœä¿å­˜: {SAVE_DIR}/benchmark_results.json')\n",
        "print('\\nğŸ“‚ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:')\n",
        "for f in sorted(SAVE_DIR.iterdir()):\n",
        "    sz = f.stat().st_size / 1024\n",
        "    print(f'  {f.name:<30} {sz:>8.1f} KB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr4Bou0NOEyF"
      },
      "source": [
        "## 9. å®Ÿãƒ‡ãƒ¼ã‚¿ã¸ã®åˆ‡ã‚Šæ›¿ãˆæ–¹æ³•\n",
        "\n",
        "åˆæˆãƒ‡ãƒ¼ã‚¿ã§å‹•ä½œç¢ºèªãŒã§ããŸã‚‰ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’ä½¿ã£ã¦å®Ÿãƒ‡ãƒ¼ã‚¿ã«å·®ã—æ›¿ãˆã‚‰ã‚Œã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5Hlk4fYOEyF"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# å®Ÿãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\n",
        "# Google Drive ã¾ãŸã¯ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ç”»åƒã‚’èª­ã¿è¾¼ã‚€\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# --- ã“ã®ã‚»ãƒ«ã¯å¿…è¦ãªæ™‚ã«ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦ä½¿ç”¨ ---\n",
        "\n",
        "# from torchvision import transforms\n",
        "# from PIL import Image\n",
        "# import glob\n",
        "#\n",
        "# class RealImageDataset(Dataset):\n",
        "#     \"\"\"å®Ÿç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\"\"\"\n",
        "#     def __init__(self, image_dir, label=0, image_size=128):\n",
        "#         self.paths = sorted(glob.glob(f'{image_dir}/*.png') +\n",
        "#                            glob.glob(f'{image_dir}/*.jpg') +\n",
        "#                            glob.glob(f'{image_dir}/*.bmp'))\n",
        "#         self.label = label\n",
        "#         self.transform = transforms.Compose([\n",
        "#             transforms.Resize((image_size, image_size)),\n",
        "#             transforms.Grayscale(num_output_channels=1),\n",
        "#             transforms.ToTensor(),\n",
        "#         ])\n",
        "#\n",
        "#     def __len__(self): return len(self.paths)\n",
        "#     def __getitem__(self, idx):\n",
        "#         img = Image.open(self.paths[idx]).convert('L')\n",
        "#         img_t = self.transform(img)\n",
        "#         mask = torch.zeros_like(img_t)\n",
        "#         return img_t, self.label, mask\n",
        "#\n",
        "# # ä½¿ã„æ–¹:\n",
        "# # Google Driveä¸Šã«ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ:\n",
        "# #   /content/drive/MyDrive/inspection_data/\n",
        "# #     â”œâ”€â”€ train/normal/     â† æ­£å¸¸å“ç”»åƒ\n",
        "# #     â””â”€â”€ test/\n",
        "# #         â”œâ”€â”€ normal/       â† ãƒ†ã‚¹ãƒˆæ­£å¸¸å“\n",
        "# #         â””â”€â”€ anomaly/      â† ãƒ†ã‚¹ãƒˆç•°å¸¸å“\n",
        "#\n",
        "# REAL_DATA_DIR = '/content/drive/MyDrive/inspection_data'\n",
        "#\n",
        "# train_real = RealImageDataset(f'{REAL_DATA_DIR}/train/normal', label=0)\n",
        "# test_normal = RealImageDataset(f'{REAL_DATA_DIR}/test/normal', label=0)\n",
        "# test_anomaly = RealImageDataset(f'{REAL_DATA_DIR}/test/anomaly', label=1)\n",
        "# test_real = torch.utils.data.ConcatDataset([test_normal, test_anomaly])\n",
        "#\n",
        "# train_loader = DataLoader(train_real, batch_size=16, shuffle=True)\n",
        "# test_loader = DataLoader(test_real, batch_size=16, shuffle=False)\n",
        "#\n",
        "# print(f'å®Ÿãƒ‡ãƒ¼ã‚¿: å­¦ç¿’{len(train_real)}æš, ãƒ†ã‚¹ãƒˆ{len(test_real)}æš')\n",
        "\n",
        "print('ğŸ’¡ å®Ÿãƒ‡ãƒ¼ã‚¿ä½¿ç”¨æ™‚ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„')\n",
        "print('   ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆ:')\n",
        "print('   inspection_data/')\n",
        "print('   â”œâ”€â”€ train/normal/     â† æ­£å¸¸å“ç”»åƒ')\n",
        "print('   â””â”€â”€ test/')\n",
        "print('       â”œâ”€â”€ normal/       â† ãƒ†ã‚¹ãƒˆæ­£å¸¸å“')\n",
        "print('       â””â”€â”€ anomaly/      â† ãƒ†ã‚¹ãƒˆç•°å¸¸å“')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9guCbOWOEyF"
      },
      "source": [
        "---\n",
        "## ğŸ“ è£œè¶³æƒ…å ±\n",
        "\n",
        "### Windows ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ–¹æ³•\n",
        "\n",
        "```bash\n",
        "# 1. ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "# 2. Jupyter Notebook/Lab ã§é–‹ã\n",
        "pip install jupyter torch torchvision scikit-learn matplotlib\n",
        "jupyter notebook inspection_ai_benchmark.ipynb\n",
        "\n",
        "# ã¾ãŸã¯ .py ã«å¤‰æ›ã—ã¦å®Ÿè¡Œ\n",
        "jupyter nbconvert --to script inspection_ai_benchmark.ipynb\n",
        "python inspection_ai_benchmark.py\n",
        "```\n",
        "\n",
        "### ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•å¯¾å¿œ\n",
        "| ç’°å¢ƒ | ãƒ‡ãƒã‚¤ã‚¹ | å‚™è€ƒ |\n",
        "|------|----------|------|\n",
        "| Google Colab | CUDA (T4) | æœ€é€Ÿã€‚ç„¡æ–™æ ã§åˆ©ç”¨å¯ |\n",
        "| Windows + NVIDIA GPU | CUDA | CUDAãƒ‰ãƒ©ã‚¤ãƒè¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« |\n",
        "| Windows (GPUãªã—) | CPU | å‹•ä½œã™ã‚‹ãŒå­¦ç¿’ã«æ™‚é–“ãŒã‹ã‹ã‚‹ |\n",
        "| MacBook (M5) | MPS | Apple SiliconåŠ é€Ÿ |\n",
        "\n",
        "### æ¨å¥¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´\n",
        "| ç›®çš„ | å¤‰æ›´ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ |\n",
        "|------|-------------------|\n",
        "| ç²¾åº¦å‘ä¸Š | `n_epochs` â†‘, `n_train` â†‘ |\n",
        "| SAEã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–å¼·åŒ– | `sae_l1_weight` â†‘ (5e-3 ~ 1e-2) |\n",
        "| DAEç²¾åº¦é‡è¦– | `dae_ssim_weight` â†‘, `dae_latent_dim` â†‘ |\n",
        "| é«˜é€Ÿæ¤œè¨¼ | `image_size=64`, `n_epochs=10` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWhdTvDNOEyF"
      },
      "source": [
        "## 10. ğŸ–¼ï¸ ãƒ†ã‚¹ãƒˆç”»åƒã®èª­ã¿è¾¼ã¿ã¨åˆ¤å®š\n",
        "\n",
        "å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«è‡ªåˆ†ã®ç”»åƒã‚’å…¥åŠ›ã—ã¦åˆ¤å®šçµæœã‚’ç¢ºèªã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8OapdzTOEyF"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ãƒ†ã‚¹ãƒˆç”»åƒã®èª­ã¿è¾¼ã¿ & æ¨è«–\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import torchvision.transforms as T_transforms\n",
        "from PIL import Image as PILImage\n",
        "import glob\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def preprocess_image(pil_img, target_size=128):\n",
        "    \"\"\"ç”»åƒã‚’ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ã«å¤‰æ›\"\"\"\n",
        "    transform = T_transforms.Compose([\n",
        "        T_transforms.Resize((target_size, target_size)),\n",
        "        T_transforms.Grayscale(num_output_channels=1),\n",
        "        T_transforms.ToTensor(),\n",
        "    ])\n",
        "    return transform(pil_img).unsqueeze(0)\n",
        "\n",
        "\n",
        "def run_inspection(image_paths_or_pils, sae_model, dae_model, device,\n",
        "                   image_size=128, sae_threshold=None, dae_threshold=None):\n",
        "    \"\"\"ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒãƒƒãƒæ¨è«–\"\"\"\n",
        "    sae_model.to(device).eval()\n",
        "    dae_model.to(device).eval()\n",
        "    results = []\n",
        "\n",
        "    for item in image_paths_or_pils:\n",
        "        if isinstance(item, str):\n",
        "            name = os.path.basename(item)\n",
        "            pil = PILImage.open(item).convert('RGB')\n",
        "        else:\n",
        "            name = getattr(item, 'filename', 'uploaded')\n",
        "            pil = item if isinstance(item, PILImage.Image) else PILImage.open(item).convert('RGB')\n",
        "\n",
        "        # å…ƒç”»åƒRGBï¼ˆãƒªã‚µã‚¤ã‚ºæ¸ˆã¿ï¼‰\n",
        "        original_rgb = np.array(pil.resize((image_size, image_size))).astype(np.float32) / 255.0\n",
        "\n",
        "        tensor = preprocess_image(pil, image_size).to(device)\n",
        "        with torch.no_grad():\n",
        "            sae_r, _ = sae_model(tensor)\n",
        "            dae_r, _ = dae_model(tensor)\n",
        "\n",
        "        sae_score = ((tensor - sae_r)**2).mean().item()\n",
        "        dae_score = ((tensor - dae_r)**2).mean().item()\n",
        "\n",
        "        results.append({\n",
        "            'name': name,\n",
        "            'pil': pil,\n",
        "            'original_rgb': original_rgb,\n",
        "            'input': tensor.squeeze().cpu().numpy(),\n",
        "            'sae_recon': sae_r.squeeze().cpu().numpy(),\n",
        "            'dae_recon': dae_r.squeeze().cpu().numpy(),\n",
        "            'sae_error': torch.abs(tensor - sae_r).squeeze().cpu().numpy(),\n",
        "            'dae_error': torch.abs(tensor - dae_r).squeeze().cpu().numpy(),\n",
        "            'sae_score': sae_score,\n",
        "            'dae_score': dae_score,\n",
        "            'sae_judge': 'ç•°å¸¸' if (sae_threshold and sae_score > sae_threshold) else 'æ­£å¸¸',\n",
        "            'dae_judge': 'ç•°å¸¸' if (dae_threshold and dae_score > dae_threshold) else 'æ­£å¸¸',\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def display_results(results):\n",
        "    \"\"\"çµæœã‚’è¡¨ã¨ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§è¡¨ç¤ºï¼ˆ7åˆ—: å…ƒç”»åƒ+ã‚¨ãƒ©ãƒ¼+ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼‰\"\"\"\n",
        "    # ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«\n",
        "    print('\\n' + 'â•'*75)\n",
        "    print('  ğŸ–¼ï¸ ãƒ†ã‚¹ãƒˆç”»åƒ åˆ¤å®šçµæœ')\n",
        "    print('â•'*75)\n",
        "    print(f'{\"ãƒ•ã‚¡ã‚¤ãƒ«\":<25} {\"SAEã‚¹ã‚³ã‚¢\":>12} {\"SAEåˆ¤å®š\":>8} {\"DAEã‚¹ã‚³ã‚¢\":>12} {\"DAEåˆ¤å®š\":>8}')\n",
        "    print('â”€'*75)\n",
        "    for r in results:\n",
        "        sae_icon = 'âŒ' if r['sae_judge']=='ç•°å¸¸' else 'âœ…'\n",
        "        dae_icon = 'âŒ' if r['dae_judge']=='ç•°å¸¸' else 'âœ…'\n",
        "        print(f'{r[\"name\"]:<25} {r[\"sae_score\"]:>12.6f} {sae_icon} {r[\"sae_judge\"]:>4}'\n",
        "              f' {r[\"dae_score\"]:>12.6f} {dae_icon} {r[\"dae_judge\"]:>4}')\n",
        "    print('â•'*75)\n",
        "\n",
        "    # ä¸ä¸€è‡´ãƒã‚§ãƒƒã‚¯\n",
        "    disagree = [r for r in results if r['sae_judge'] != r['dae_judge']]\n",
        "    if disagree:\n",
        "        print(f'\\nâš ï¸ {len(disagree)}æšã§åˆ¤å®šä¸ä¸€è‡´:')\n",
        "        for r in disagree:\n",
        "            print(f'  ğŸ“Œ {r[\"name\"]}: SAE={r[\"sae_judge\"]} / DAE={r[\"dae_judge\"]}')\n",
        "\n",
        "    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆ2è¡ŒÃ—4åˆ—ï¼‰\n",
        "    n = len(results)\n",
        "    fig, axes = plt.subplots(n * 2, 4, figsize=(18, n * 6))\n",
        "    if n == 1:\n",
        "        axes = axes.reshape(2, 4)\n",
        "\n",
        "    for i, r in enumerate(results):\n",
        "        row_top = i * 2\n",
        "        row_bot = i * 2 + 1\n",
        "\n",
        "        # ä¸Šæ®µ: å…ƒç”»åƒ, å…¥åŠ›(ã‚°ãƒ¬ãƒ¼), SAEå†æ§‹æˆ, DAEå†æ§‹æˆ\n",
        "        panels_top = [\n",
        "            (r['original_rgb'], 'å…ƒç”»åƒ', None),\n",
        "            (r['input'], 'å…¥åŠ›(ã‚°ãƒ¬ãƒ¼)', 'gray'),\n",
        "            (r['sae_recon'], 'SAEå†æ§‹æˆ', 'gray'),\n",
        "            (r['dae_recon'], 'DAEå†æ§‹æˆ', 'gray'),\n",
        "        ]\n",
        "        for j, (p, t, cm) in enumerate(panels_top):\n",
        "            ax = axes[row_top, j] if n > 1 else axes[0, j]\n",
        "            if cm: ax.imshow(p, cmap=cm, vmin=0, vmax=1)\n",
        "            else:  ax.imshow(p)\n",
        "            if i == 0: ax.set_title(t, fontsize=10, fontweight='bold')\n",
        "            ax.axis('off')\n",
        "            if j == 0:\n",
        "                icon = 'ğŸ”´' if 'ç•°å¸¸' in r['sae_judge'] or 'ç•°å¸¸' in r['dae_judge'] else 'ğŸŸ¢'\n",
        "                ax.set_ylabel(f'{icon}{r[\"name\"][:12]}', fontsize=8, rotation=0, labelpad=70, va='center')\n",
        "\n",
        "        # ä¸‹æ®µ: SAEã‚¨ãƒ©ãƒ¼, DAEã‚¨ãƒ©ãƒ¼, SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤, DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤\n",
        "        sae_ov = create_overlay(r['input'], r['sae_error'], alpha=0.55)\n",
        "        dae_ov = create_overlay(r['input'], r['dae_error'], alpha=0.55)\n",
        "        panels_bot = [\n",
        "            (r['sae_error'], 'SAEã‚¨ãƒ©ãƒ¼', True),\n",
        "            (r['dae_error'], 'DAEã‚¨ãƒ©ãƒ¼', True),\n",
        "            (sae_ov, 'SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', False),\n",
        "            (dae_ov, 'DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', False),\n",
        "        ]\n",
        "        bot_titles = ['SAEã‚¨ãƒ©ãƒ¼', 'DAEã‚¨ãƒ©ãƒ¼', 'SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', 'DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤']\n",
        "        for j, (p, t, use_cmap) in enumerate(panels_bot):\n",
        "            ax = axes[row_bot, j] if n > 1 else axes[1, j]\n",
        "            if use_cmap:\n",
        "                vmax = max(p.max(), 0.001)\n",
        "                im = ax.imshow(p, cmap=INSPECTION_CMAP, vmin=0, vmax=vmax)\n",
        "                cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "                cbar.ax.tick_params(labelsize=6)\n",
        "            else:\n",
        "                ax.imshow(p)\n",
        "            if i == 0: ax.set_title(t, fontsize=10, fontweight='bold')\n",
        "            ax.axis('off')\n",
        "\n",
        "    plt.suptitle('ãƒ†ã‚¹ãƒˆç”»åƒ ç•°å¸¸æ¤œçŸ¥çµæœ', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(SAVE_DIR / 'test_image_results.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "plt.close()\n",
        "\n",
        "\n",
        "print('âœ… ãƒ†ã‚¹ãƒˆç”»åƒæ¨è«–é–¢æ•° å®šç¾©å®Œäº†')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v1RrfpuOEyF"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# æ–¹æ³•A: åˆæˆãƒ†ã‚¹ãƒˆç”»åƒã§å‹•ä½œç¢ºèª\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# 3Ïƒé–¾å€¤ã‚’è¨ˆç®—\n",
        "sae_threshold = sae_m.get('normal_mean', 0) + 3 * sae_m.get('normal_std', 0.001)\n",
        "dae_threshold = dae_m.get('normal_mean', 0) + 3 * dae_m.get('normal_std', 0.001)\n",
        "print(f'é–¾å€¤: SAE={sae_threshold:.6f}, DAE={dae_threshold:.6f}')\n",
        "\n",
        "# åˆæˆãƒ†ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆ\n",
        "test_pils = []\n",
        "for i in range(3):\n",
        "    arr = generate_normal_image(CONFIG['image_size'], seed=8000+i)\n",
        "    pil = PILImage.fromarray((arr*255).astype(np.uint8), mode='L').convert('RGB')\n",
        "    pil.filename = f'normal_{i+1}.png'\n",
        "    test_pils.append(pil)\n",
        "\n",
        "for i, dt in enumerate(['scratch', 'stain', 'missing', 'discolor']):\n",
        "    base = generate_normal_image(CONFIG['image_size'], seed=9000+i)\n",
        "    defect, _ = add_defect(base, dt, seed=9100+i)\n",
        "    pil = PILImage.fromarray((defect*255).astype(np.uint8), mode='L').convert('RGB')\n",
        "    pil.filename = f'defect_{dt}.png'\n",
        "    test_pils.append(pil)\n",
        "\n",
        "# æ¨è«–å®Ÿè¡Œ\n",
        "results = run_inspection(\n",
        "    test_pils, sae, dae, DEVICE,\n",
        "    image_size=CONFIG['image_size'],\n",
        "    sae_threshold=sae_threshold,\n",
        "    dae_threshold=dae_threshold,\n",
        ")\n",
        "display_results(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy7xUs1QOEyF"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# æ–¹æ³•B: Colabã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ¤å®š\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# --- Colabã®å ´åˆ: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ€ã‚¤ã‚¢ãƒ­ã‚° ---\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print('ğŸ“ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰')\n",
        "    print('   å¯¾å¿œå½¢å¼: PNG, JPG, BMP, TIFF')\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        upload_pils = []\n",
        "        for fname, content in uploaded.items():\n",
        "            pil = PILImage.open(io.BytesIO(content)).convert('RGB')\n",
        "            pil.filename = fname\n",
        "            upload_pils.append(pil)\n",
        "            print(f'  âœ… {fname} ({pil.size[0]}x{pil.size[1]})')\n",
        "\n",
        "        results_upload = run_inspection(\n",
        "            upload_pils, sae, dae, DEVICE,\n",
        "            image_size=CONFIG['image_size'],\n",
        "            sae_threshold=sae_threshold,\n",
        "            dae_threshold=dae_threshold,\n",
        "        )\n",
        "        display_results(results_upload)\n",
        "\n",
        "except ImportError:\n",
        "    print('ğŸ’¡ Colabä»¥å¤–ã®ç’°å¢ƒã§ã™ã€‚æ–¹æ³•Cã§ãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®šã—ã¦ãã ã•ã„ã€‚')\n",
        "    print('   ã¾ãŸã¯ä¸Šã®åˆæˆç”»åƒãƒ†ã‚¹ãƒˆï¼ˆæ–¹æ³•Aï¼‰ã‚’ãŠä½¿ã„ãã ã•ã„ã€‚')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrnbOTQcOEyF"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# æ–¹æ³•C: ãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®šã§ä¸€æ‹¬åˆ¤å®š\n",
        "# Windows / Mac / Colab(Drive) å…±é€š\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# --- ãƒ‘ã‚¹ã‚’å¤‰æ›´ã—ã¦ä½¿ç”¨ ---\n",
        "# TEST_IMAGE_DIR = r'C:\\Users\\your_name\\test_images'        # Windows\n",
        "# TEST_IMAGE_DIR = '/Users/your_name/test_images'            # Mac\n",
        "# TEST_IMAGE_DIR = '/content/drive/MyDrive/test_images'      # Colab + Drive\n",
        "\n",
        "TEST_IMAGE_DIR = ''  # â† ã“ã“ã«ãƒ‘ã‚¹ã‚’å…¥åŠ›\n",
        "\n",
        "if TEST_IMAGE_DIR and os.path.isdir(TEST_IMAGE_DIR):\n",
        "    extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tif', '*.tiff']\n",
        "    image_paths = []\n",
        "    for ext in extensions:\n",
        "        image_paths.extend(glob.glob(os.path.join(TEST_IMAGE_DIR, ext)))\n",
        "        image_paths.extend(glob.glob(os.path.join(TEST_IMAGE_DIR, ext.upper())))\n",
        "    image_paths = sorted(set(image_paths))\n",
        "\n",
        "    if image_paths:\n",
        "        print(f'ğŸ“‚ {len(image_paths)}æšã®ç”»åƒã‚’æ¤œå‡º: {TEST_IMAGE_DIR}')\n",
        "        for p in image_paths[:5]:\n",
        "            print(f'  ğŸ“„ {os.path.basename(p)}')\n",
        "        if len(image_paths) > 5:\n",
        "            print(f'  ... ä»–{len(image_paths)-5}æš')\n",
        "\n",
        "        results_folder = run_inspection(\n",
        "            image_paths, sae, dae, DEVICE,\n",
        "            image_size=CONFIG['image_size'],\n",
        "            sae_threshold=sae_threshold,\n",
        "            dae_threshold=dae_threshold,\n",
        "        )\n",
        "        display_results(results_folder)\n",
        "    else:\n",
        "        print(f'âš ï¸ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {TEST_IMAGE_DIR}')\n",
        "else:\n",
        "    print('ğŸ’¡ TEST_IMAGE_DIR ã«ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„')\n",
        "    print('   ä¾‹:')\n",
        "    print('   Windows:  r\"C:\\\\Users\\\\user\\\\test_images\"')\n",
        "    print('   Mac:      \"/Users/user/test_images\"')\n",
        "    print('   Colab:    \"/content/drive/MyDrive/test_images\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzUPILJrOEyF"
      },
      "source": [
        "## 11. ğŸ›ï¸ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–GUIï¼ˆColabå¯¾å¿œï¼‰\n",
        "\n",
        "ãƒœã‚¿ãƒ³æ“ä½œã ã‘ã§ **ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ æ¨è«– â†’ çµæœãƒ¬ãƒ“ãƒ¥ãƒ¼** ã‚’è¡Œãˆã‚‹GUIã§ã™ã€‚\n",
        "\n",
        "> **æ“ä½œæ–¹æ³•**: ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã¨GUIãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si63LMIXOEyL"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# GUI ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆipywidgetsï¼‰\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import io as _io\n",
        "import base64\n",
        "from PIL import Image as PILImage\n",
        "import torchvision.transforms as T_transforms\n",
        "\n",
        "# â”€â”€ çŠ¶æ…‹ç®¡ç† â”€â”€\n",
        "gui_state = {\n",
        "    'images': [],       # [(name, PIL.Image), ...]\n",
        "    'results': [],      # run_inspection ã®å‡ºåŠ›\n",
        "    'current_idx': 0,   # ç¾åœ¨è¡¨ç¤ºä¸­ã®ç”»åƒindex\n",
        "}\n",
        "\n",
        "# â”€â”€ ã‚¹ã‚¿ã‚¤ãƒ«å®šç¾© â”€â”€\n",
        "CSS = HTML('''\n",
        "<style>\n",
        ".gui-header { background: linear-gradient(135deg, #1e3a5f, #0f2027);\n",
        "  color: white; padding: 16px 24px; border-radius: 12px;\n",
        "  font-size: 18px; font-weight: bold; margin-bottom: 12px; }\n",
        ".gui-card { background: #f8f9fa; border: 1px solid #e0e0e0;\n",
        "  border-radius: 8px; padding: 12px; margin: 6px 0; }\n",
        ".gui-ok { color: #10b981; font-weight: bold; font-size: 16px; }\n",
        ".gui-ng { color: #ef4444; font-weight: bold; font-size: 16px; }\n",
        ".gui-warn { color: #f59e0b; font-weight: bold; }\n",
        ".gui-stat { display: inline-block; background: #e2e8f0;\n",
        "  border-radius: 6px; padding: 6px 14px; margin: 4px;\n",
        "  font-family: monospace; font-size: 13px; }\n",
        "</style>\n",
        "''')\n",
        "display(CSS)\n",
        "\n",
        "print('âœ… GUI ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿å®Œäº†')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_77o3vROEyL"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# GUI ãƒ¡ã‚¤ãƒ³\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# â”€â”€ å‡ºåŠ›ã‚¨ãƒªã‚¢ â”€â”€\n",
        "out_upload_status = widgets.Output()\n",
        "out_summary = widgets.Output()\n",
        "out_detail = widgets.Output()\n",
        "out_heatmap = widgets.Output()\n",
        "\n",
        "# â”€â”€ é–¾å€¤ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ â”€â”€\n",
        "sae_thr_default = sae_m.get('normal_mean', 0) + 3 * sae_m.get('normal_std', 0.001)\n",
        "dae_thr_default = dae_m.get('normal_mean', 0) + 3 * dae_m.get('normal_std', 0.001)\n",
        "\n",
        "sae_thr_slider = widgets.FloatSlider(\n",
        "    value=sae_thr_default, min=0.0, max=max(sae_thr_default*5, 0.05),\n",
        "    step=0.0001, description='SAE é–¾å€¤:', readout_format='.5f',\n",
        "    style={'description_width': '80px'}, layout=widgets.Layout(width='450px'),\n",
        ")\n",
        "dae_thr_slider = widgets.FloatSlider(\n",
        "    value=dae_thr_default, min=0.0, max=max(dae_thr_default*5, 0.05),\n",
        "    step=0.0001, description='DAE é–¾å€¤:', readout_format='.5f',\n",
        "    style={'description_width': '80px'}, layout=widgets.Layout(width='450px'),\n",
        ")\n",
        "\n",
        "# â”€â”€ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ â”€â”€\n",
        "file_uploader = widgets.FileUpload(\n",
        "    accept='.png,.jpg,.jpeg,.bmp,.tif,.tiff',\n",
        "    multiple=True,\n",
        "    description='ğŸ“ ç”»åƒã‚’é¸æŠ',\n",
        "    layout=widgets.Layout(width='300px'),\n",
        ")\n",
        "\n",
        "# â”€â”€ ãƒœã‚¿ãƒ³ â”€â”€\n",
        "btn_run = widgets.Button(\n",
        "    description='â–¶ æ¨è«–å®Ÿè¡Œ', icon='play',\n",
        "    button_style='primary',\n",
        "    layout=widgets.Layout(width='160px', height='40px'),\n",
        ")\n",
        "btn_synthetic = widgets.Button(\n",
        "    description='ğŸ² åˆæˆãƒ†ã‚¹ãƒˆ', icon='random',\n",
        "    button_style='info',\n",
        "    layout=widgets.Layout(width='160px', height='40px'),\n",
        ")\n",
        "btn_prev = widgets.Button(\n",
        "    description='â—€ å‰ã¸', layout=widgets.Layout(width='100px'),\n",
        ")\n",
        "btn_next = widgets.Button(\n",
        "    description='æ¬¡ã¸ â–¶', layout=widgets.Layout(width='100px'),\n",
        ")\n",
        "btn_export = widgets.Button(\n",
        "    description='ğŸ’¾ CSVä¿å­˜', icon='download',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='160px', height='40px'),\n",
        ")\n",
        "label_nav = widgets.HTML(value='<b>â”€</b>')\n",
        "\n",
        "# â”€â”€ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ â”€â”€\n",
        "filter_dropdown = widgets.Dropdown(\n",
        "    options=['ã™ã¹ã¦', 'ç•°å¸¸ã®ã¿', 'æ­£å¸¸ã®ã¿', 'åˆ¤å®šä¸ä¸€è‡´ã®ã¿'],\n",
        "    value='ã™ã¹ã¦', description='è¡¨ç¤º:',\n",
        "    style={'description_width': '50px'},\n",
        "    layout=widgets.Layout(width='220px'),\n",
        ")\n",
        "\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "\n",
        "def load_uploaded_files(change=None):\n",
        "    \"\"\"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆipywidgetsæ–°æ—§ä¸¡å¯¾å¿œï¼‰\"\"\"\n",
        "    gui_state['images'] = []\n",
        "    with out_upload_status:\n",
        "        clear_output()\n",
        "        if not file_uploader.value:\n",
        "            print('ğŸ“ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„')\n",
        "            return\n",
        "\n",
        "        uploaded = file_uploader.value\n",
        "\n",
        "        # ipywidgets >= 8: tuple of FileUploadContent objects\n",
        "        # ipywidgets <  8: dict {filename: {content: bytes, ...}}\n",
        "        if isinstance(uploaded, dict):\n",
        "            items = [(fname, meta['content']) for fname, meta in uploaded.items()]\n",
        "        elif isinstance(uploaded, (list, tuple)):\n",
        "            items = []\n",
        "            for item in uploaded:\n",
        "                if hasattr(item, 'name') and hasattr(item, 'content'):\n",
        "                    items.append((item.name, item.content))\n",
        "                elif isinstance(item, dict):\n",
        "                    items.append((item.get('name', 'unknown'), item.get('content', b'')))\n",
        "                else:\n",
        "                    continue\n",
        "        else:\n",
        "            print(f'âš ï¸ æœªå¯¾å¿œã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å½¢å¼: {type(uploaded)}')\n",
        "            return\n",
        "\n",
        "        for name, content in items:\n",
        "            try:\n",
        "                pil = PILImage.open(_io.BytesIO(content)).convert('RGB')\n",
        "                pil.filename = name\n",
        "                gui_state['images'].append((name, pil))\n",
        "            except Exception as e:\n",
        "                print(f'  âš ï¸ {name}: èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({e})')\n",
        "        print(f'âœ… {len(gui_state[\"images\"])}æšã®ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ')\n",
        "        for n, p in gui_state['images']:\n",
        "            print(f'  ğŸ“„ {n} ({p.size[0]}Ã—{p.size[1]})')\n",
        "\n",
        "file_uploader.observe(load_uploaded_files, names='value')\n",
        "\n",
        "\n",
        "def on_synthetic_click(btn):\n",
        "    \"\"\"åˆæˆãƒ†ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆ\"\"\"\n",
        "    gui_state['images'] = []\n",
        "    with out_upload_status:\n",
        "        clear_output()\n",
        "        print('ğŸ² åˆæˆãƒ†ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆä¸­...')\n",
        "        for i in range(3):\n",
        "            arr = generate_normal_image(CONFIG['image_size'], seed=8000+i)\n",
        "            pil = PILImage.fromarray((arr*255).astype(np.uint8), mode='L').convert('RGB')\n",
        "            pil.filename = f'normal_{i+1}.png'\n",
        "            gui_state['images'].append((f'normal_{i+1}.png', pil))\n",
        "        for i, dt in enumerate(['scratch', 'stain', 'missing', 'discolor']):\n",
        "            base = generate_normal_image(CONFIG['image_size'], seed=9000+i)\n",
        "            defect, _ = add_defect(base, dt, seed=9100+i)\n",
        "            pil = PILImage.fromarray((defect*255).astype(np.uint8), mode='L').convert('RGB')\n",
        "            pil.filename = f'defect_{dt}.png'\n",
        "            gui_state['images'].append((f'defect_{dt}.png', pil))\n",
        "        print(f'âœ… {len(gui_state[\"images\"])}æšç”Ÿæˆï¼ˆæ­£å¸¸3æš + ç•°å¸¸4æšï¼‰')\n",
        "\n",
        "btn_synthetic.on_click(on_synthetic_click)\n",
        "\n",
        "\n",
        "def on_run_click(btn):\n",
        "    \"\"\"æ¨è«–å®Ÿè¡Œ\"\"\"\n",
        "    if not gui_state['images']:\n",
        "        with out_summary:\n",
        "            clear_output()\n",
        "            print('âš ï¸ ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯åˆæˆãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚')\n",
        "        return\n",
        "\n",
        "    # ãƒ¢ãƒ‡ãƒ«ã‚’DEVICEã«åŒæœŸï¼ˆCPU/CUDAä¸ä¸€è‡´é˜²æ­¢ï¼‰\n",
        "    sae.to(DEVICE).eval()\n",
        "    dae.to(DEVICE).eval()\n",
        "\n",
        "    pils = [p for _, p in gui_state['images']]\n",
        "    gui_state['results'] = run_inspection(\n",
        "        pils, sae, dae, DEVICE,\n",
        "        image_size=CONFIG['image_size'],\n",
        "        sae_threshold=sae_thr_slider.value,\n",
        "        dae_threshold=dae_thr_slider.value,\n",
        "    )\n",
        "    gui_state['current_idx'] = 0\n",
        "    update_summary()\n",
        "    update_detail_view()\n",
        "\n",
        "btn_run.on_click(on_run_click)\n",
        "\n",
        "\n",
        "def get_filtered_results():\n",
        "    \"\"\"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨\"\"\"\n",
        "    results = gui_state['results']\n",
        "    f = filter_dropdown.value\n",
        "    if f == 'ç•°å¸¸ã®ã¿':\n",
        "        return [(i,r) for i,r in enumerate(results) if 'ç•°å¸¸' in r['sae_judge'] or 'ç•°å¸¸' in r['dae_judge']]\n",
        "    elif f == 'æ­£å¸¸ã®ã¿':\n",
        "        return [(i,r) for i,r in enumerate(results) if r['sae_judge']=='æ­£å¸¸' and r['dae_judge']=='æ­£å¸¸']\n",
        "    elif f == 'åˆ¤å®šä¸ä¸€è‡´ã®ã¿':\n",
        "        return [(i,r) for i,r in enumerate(results) if r['sae_judge'] != r['dae_judge']]\n",
        "    return list(enumerate(results))\n",
        "\n",
        "\n",
        "def update_summary():\n",
        "    \"\"\"ã‚µãƒãƒªãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–°\"\"\"\n",
        "    with out_summary:\n",
        "        clear_output(wait=True)\n",
        "        results = gui_state['results']\n",
        "        if not results:\n",
        "            return\n",
        "        n = len(results)\n",
        "        n_sae_ng = sum(1 for r in results if 'ç•°å¸¸' in r['sae_judge'])\n",
        "        n_dae_ng = sum(1 for r in results if 'ç•°å¸¸' in r['dae_judge'])\n",
        "        n_disagree = sum(1 for r in results if r['sae_judge'] != r['dae_judge'])\n",
        "\n",
        "        html = '<div class=\"gui-card\">'\n",
        "        html += '<b>ğŸ“Š åˆ¤å®šã‚µãƒãƒªãƒ¼</b><br><br>'\n",
        "        html += f'<span class=\"gui-stat\">æ¤œæŸ»æ•°: <b>{n}</b>æš</span>'\n",
        "        html += f'<span class=\"gui-stat\">SAEç•°å¸¸: <b class=\"gui-ng\">{n_sae_ng}</b>/{n}</span>'\n",
        "        html += f'<span class=\"gui-stat\">DAEç•°å¸¸: <b class=\"gui-ng\">{n_dae_ng}</b>/{n}</span>'\n",
        "        if n_disagree:\n",
        "            html += f'<br><br><span class=\"gui-warn\">âš ï¸ {n_disagree}æšã§åˆ¤å®šä¸ä¸€è‡´</span>'\n",
        "        html += '</div>'\n",
        "\n",
        "        # ãƒ†ãƒ¼ãƒ–ãƒ«\n",
        "        html += '<table style=\"width:100%; border-collapse:collapse; font-size:13px; margin-top:8px;\">'\n",
        "        html += '<tr style=\"background:#334155; color:white;\">'\n",
        "        html += '<th style=\"padding:6px 8px; text-align:left;\">ãƒ•ã‚¡ã‚¤ãƒ«</th>'\n",
        "        html += '<th>SAEã‚¹ã‚³ã‚¢</th><th>SAE</th>'\n",
        "        html += '<th>DAEã‚¹ã‚³ã‚¢</th><th>DAE</th><th></th></tr>'\n",
        "        for i, r in enumerate(results):\n",
        "            bg = '#fff5f5' if ('ç•°å¸¸' in r['sae_judge'] or 'ç•°å¸¸' in r['dae_judge']) else '#f0fdf4'\n",
        "            sae_cls = 'gui-ng' if 'ç•°å¸¸' in r['sae_judge'] else 'gui-ok'\n",
        "            dae_cls = 'gui-ng' if 'ç•°å¸¸' in r['dae_judge'] else 'gui-ok'\n",
        "            warn = ' âš ï¸' if r['sae_judge'] != r['dae_judge'] else ''\n",
        "            html += f'<tr style=\"background:{bg}; border-bottom:1px solid #e2e8f0;\">'\n",
        "            html += f'<td style=\"padding:5px 8px;\">{r[\"name\"]}</td>'\n",
        "            html += f'<td style=\"text-align:center; font-family:monospace;\">{r[\"sae_score\"]:.6f}</td>'\n",
        "            html += f'<td style=\"text-align:center;\"><span class=\"{sae_cls}\">{r[\"sae_judge\"]}</span></td>'\n",
        "            html += f'<td style=\"text-align:center; font-family:monospace;\">{r[\"dae_score\"]:.6f}</td>'\n",
        "            html += f'<td style=\"text-align:center;\"><span class=\"{dae_cls}\">{r[\"dae_judge\"]}</span>{warn}</td>'\n",
        "            html += f'<td style=\"text-align:center;\">#{i+1}</td></tr>'\n",
        "        html += '</table>'\n",
        "        display(HTML(html))\n",
        "\n",
        "\n",
        "def update_detail_view():\n",
        "    \"\"\"å€‹åˆ¥ç”»åƒã®è©³ç´°ãƒ“ãƒ¥ãƒ¼æ›´æ–°\"\"\"\n",
        "    filtered = get_filtered_results()\n",
        "    if not filtered:\n",
        "        with out_detail:\n",
        "            clear_output()\n",
        "            print('è©²å½“ã™ã‚‹ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“')\n",
        "        return\n",
        "\n",
        "    idx = gui_state['current_idx'] % len(filtered)\n",
        "    orig_i, r = filtered[idx]\n",
        "    label_nav.value = f'<b>{idx+1} / {len(filtered)}</b>'\n",
        "\n",
        "    with out_detail:\n",
        "        clear_output(wait=True)\n",
        "        sae_cls = 'gui-ng' if 'ç•°å¸¸' in r['sae_judge'] else 'gui-ok'\n",
        "        dae_cls = 'gui-ng' if 'ç•°å¸¸' in r['dae_judge'] else 'gui-ok'\n",
        "        html = f'<div class=\"gui-card\">'\n",
        "        html += f'<b>ğŸ“„ {r[\"name\"]}</b> (#{orig_i+1})<br><br>'\n",
        "        html += f'<span class=\"gui-stat\">SAE: <span class=\"{sae_cls}\">{r[\"sae_judge\"]}</span> ({r[\"sae_score\"]:.6f})</span> '\n",
        "        html += f'<span class=\"gui-stat\">DAE: <span class=\"{dae_cls}\">{r[\"dae_judge\"]}</span> ({r[\"dae_score\"]:.6f})</span>'\n",
        "        if r['sae_judge'] != r['dae_judge']:\n",
        "            html += '<br><span class=\"gui-warn\">âš ï¸ ãƒ¢ãƒ‡ãƒ«é–“ã§åˆ¤å®šä¸ä¸€è‡´</span>'\n",
        "        html += '</div>'\n",
        "        display(HTML(html))\n",
        "\n",
        "    with out_heatmap:\n",
        "        clear_output(wait=True)\n",
        "        # Replaced by 2x4 layout below\n",
        "        # ä¸Šæ®µ: å…ƒç”»åƒ, å…¥åŠ›, SAEå†æ§‹æˆ, DAEå†æ§‹æˆ\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(18, 7))\n",
        "        top_panels = [\n",
        "            (r.get('original_rgb', r['input']), 'å…ƒç”»åƒ', None),\n",
        "            (r['input'], 'å…¥åŠ›(ã‚°ãƒ¬ãƒ¼)', 'gray'),\n",
        "            (r['sae_recon'], 'SAEå†æ§‹æˆ', 'gray'),\n",
        "            (r['dae_recon'], 'DAEå†æ§‹æˆ', 'gray'),\n",
        "        ]\n",
        "        for j, (p, t, cm) in enumerate(top_panels):\n",
        "            ax = axes[0, j]\n",
        "            if cm: ax.imshow(p, cmap=cm, vmin=0, vmax=1)\n",
        "            else:  ax.imshow(p)\n",
        "            ax.set_title(t, fontsize=10, fontweight='bold')\n",
        "            ax.axis('off')\n",
        "\n",
        "        # ä¸‹æ®µ: SAEã‚¨ãƒ©ãƒ¼, DAEã‚¨ãƒ©ãƒ¼, SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤, DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤\n",
        "        sae_ov = create_overlay(r['input'], r['sae_error'], alpha=0.55)\n",
        "        dae_ov = create_overlay(r['input'], r['dae_error'], alpha=0.55)\n",
        "        bot_panels = [\n",
        "            (r['sae_error'], 'SAEã‚¨ãƒ©ãƒ¼', True),\n",
        "            (r['dae_error'], 'DAEã‚¨ãƒ©ãƒ¼', True),\n",
        "            (sae_ov, 'SAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', False),\n",
        "            (dae_ov, 'DAEã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤', False),\n",
        "        ]\n",
        "        for j, (p, t, use_cmap) in enumerate(bot_panels):\n",
        "            ax = axes[1, j]\n",
        "            if use_cmap:\n",
        "                vmax = max(p.max(), 0.001)\n",
        "                im = ax.imshow(p, cmap=INSPECTION_CMAP, vmin=0, vmax=vmax)\n",
        "                cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "                cbar.ax.tick_params(labelsize=6)\n",
        "            else:\n",
        "                ax.imshow(p)\n",
        "            ax.set_title(t, fontsize=10, fontweight='bold')\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "def on_prev(btn):\n",
        "    filtered = get_filtered_results()\n",
        "    if filtered:\n",
        "        gui_state['current_idx'] = (gui_state['current_idx'] - 1) % len(filtered)\n",
        "        update_detail_view()\n",
        "\n",
        "def on_next(btn):\n",
        "    filtered = get_filtered_results()\n",
        "    if filtered:\n",
        "        gui_state['current_idx'] = (gui_state['current_idx'] + 1) % len(filtered)\n",
        "        update_detail_view()\n",
        "\n",
        "btn_prev.on_click(on_prev)\n",
        "btn_next.on_click(on_next)\n",
        "\n",
        "\n",
        "def on_filter_change(change):\n",
        "    gui_state['current_idx'] = 0\n",
        "    update_detail_view()\n",
        "\n",
        "filter_dropdown.observe(on_filter_change, names='value')\n",
        "\n",
        "\n",
        "def on_export_csv(btn):\n",
        "    \"\"\"çµæœã‚’CSVã§ä¿å­˜\"\"\"\n",
        "    if not gui_state['results']:\n",
        "        return\n",
        "    import csv\n",
        "    csv_path = SAVE_DIR / 'test_results.csv'\n",
        "    with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow(['ãƒ•ã‚¡ã‚¤ãƒ«å','SAEã‚¹ã‚³ã‚¢','SAEåˆ¤å®š','DAEã‚¹ã‚³ã‚¢','DAEåˆ¤å®š','ä¸ä¸€è‡´'])\n",
        "        for r in gui_state['results']:\n",
        "            w.writerow([\n",
        "                r['name'], f'{r[\"sae_score\"]:.6f}', r['sae_judge'],\n",
        "                f'{r[\"dae_score\"]:.6f}', r['dae_judge'],\n",
        "                'âš ' if r['sae_judge']!=r['dae_judge'] else '',\n",
        "            ])\n",
        "    with out_upload_status:\n",
        "        print(f'\\nğŸ’¾ CSVä¿å­˜å®Œäº†: {csv_path}')\n",
        "    # Colabè‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "    try:\n",
        "        from google.colab import files as colab_files\n",
        "        colab_files.download(str(csv_path))\n",
        "    except ImportError:\n",
        "        pass\n",
        "\n",
        "btn_export.on_click(on_export_csv)\n",
        "\n",
        "\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "# GUIãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆçµ„ã¿ç«‹ã¦\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "header = widgets.HTML('<div class=\"gui-header\">ğŸ”¬ å¤–è¦³æ¤œæŸ»AI â€” ãƒ†ã‚¹ãƒˆç”»åƒãƒ¬ãƒ“ãƒ¥ãƒ¼</div>')\n",
        "\n",
        "upload_section = widgets.VBox([\n",
        "    widgets.HTML('<b>â‘  ç”»åƒã‚’æº–å‚™</b>'),\n",
        "    widgets.HBox([file_uploader, btn_synthetic]),\n",
        "    out_upload_status,\n",
        "])\n",
        "\n",
        "threshold_section = widgets.VBox([\n",
        "    widgets.HTML('<b>â‘¡ é–¾å€¤è¨­å®š</b>'),\n",
        "    sae_thr_slider,\n",
        "    dae_thr_slider,\n",
        "    widgets.HBox([btn_run, btn_export]),\n",
        "])\n",
        "\n",
        "nav_section = widgets.HBox(\n",
        "    [btn_prev, label_nav, btn_next, filter_dropdown],\n",
        "    layout=widgets.Layout(align_items='center', gap='12px'),\n",
        ")\n",
        "\n",
        "review_section = widgets.VBox([\n",
        "    widgets.HTML('<b>â‘¢ çµæœãƒ¬ãƒ“ãƒ¥ãƒ¼</b>'),\n",
        "    out_summary,\n",
        "    widgets.HTML('<hr>'),\n",
        "    widgets.HTML('<b>â‘£ å€‹åˆ¥ç”»åƒè©³ç´°</b>'),\n",
        "    nav_section,\n",
        "    out_detail,\n",
        "    out_heatmap,\n",
        "])\n",
        "\n",
        "gui = widgets.VBox([\n",
        "    header,\n",
        "    upload_section,\n",
        "    widgets.HTML('<hr>'),\n",
        "    threshold_section,\n",
        "    widgets.HTML('<hr>'),\n",
        "    review_section,\n",
        "], layout=widgets.Layout(max_width='900px'))\n",
        "\n",
        "display(gui)\n",
        "print('\\nğŸ’¡ æ“ä½œæ‰‹é †: â‘ ç”»åƒã‚’é¸æŠ â†’ â‘¡é–¾å€¤ã‚’èª¿æ•´ â†’ â–¶æ¨è«–å®Ÿè¡Œ â†’ â‘¢çµæœã‚’ç¢ºèª â†’ â—€â–¶ã§ç”»åƒã‚’åˆ‡æ›¿')"
      ]
    }
  ]
}